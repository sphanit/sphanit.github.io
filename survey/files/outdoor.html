<!DOCTYPE html>
<html><head>
		<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
		<title>Zotero Report</title>
		<link rel="stylesheet" type="text/css" href="data:text/css;base64,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">
		<link rel="stylesheet" type="text/css" media="screen,projection" href="data:text/css;base64,LyogR2VuZXJpYyBzdHlsZXMgKi8KYm9keSB7Cglmb250OiA2Mi41JSBHZW9yZ2lhLCBUaW1lcywgc2VyaWY7Cgl3aWR0aDogNzgwcHg7CgltYXJnaW46IDAgYXV0bzsKfQoKaDIgewoJZm9udC1zaXplOiAxLjVlbTsKCWxpbmUtaGVpZ2h0OiAxLjVlbTsKCWZvbnQtZmFtaWx5OiBHZW9yZ2lhLCBUaW1lcywgc2VyaWY7Cn0KCnAgewoJbGluZS1oZWlnaHQ6IDEuNWVtOwp9CgphOmxpbmssIGE6dmlzaXRlZCB7Cgljb2xvcjogIzkwMDsKfQoKYTpob3ZlciwgYTphY3RpdmUgewoJY29sb3I6ICM3Nzc7Cn0KCgp1bC5yZXBvcnQgewoJZm9udC1zaXplOiAxLjRlbTsKCXdpZHRoOiA2ODBweDsKCW1hcmdpbjogMCBhdXRvOwoJcGFkZGluZzogMjBweCAyMHB4Owp9CgovKiBNZXRhZGF0YSB0YWJsZSAqLwp0YWJsZSB7Cglib3JkZXI6IDFweCAjY2NjIHNvbGlkOwoJb3ZlcmZsb3c6IGF1dG87Cgl3aWR0aDogMTAwJTsKCW1hcmdpbjogLjFlbSBhdXRvIC43NWVtOwoJcGFkZGluZzogMC41ZW07Cn0K">
		<link rel="stylesheet" type="text/css" media="print" href="data:text/css;base64,Ym9keSB7Cglmb250OiAxMnB0ICJUaW1lcyBOZXcgUm9tYW4iLCBUaW1lcywgR2VvcmdpYSwgc2VyaWY7CgltYXJnaW46IDA7Cgl3aWR0aDogYXV0bzsKCWNvbG9yOiBibGFjazsKfQoKLyogUGFnZSBCcmVha3MgKHBhZ2UtYnJlYWstaW5zaWRlIG9ubHkgcmVjb2duaXplZCBieSBPcGVyYSkgKi8KaDEsIGgyLCBoMywgaDQsIGg1LCBoNiB7CglwYWdlLWJyZWFrLWFmdGVyOiBhdm9pZDsKCXBhZ2UtYnJlYWstaW5zaWRlOiBhdm9pZDsKfQoKdWwsIG9sLCBkbCB7CglwYWdlLWJyZWFrLWluc2lkZTogYXZvaWQ7Cgljb2xvci1hZGp1c3Q6IGV4YWN0Owp9CgpoMiB7Cglmb250LXNpemU6IDEuM2VtOwoJbGluZS1oZWlnaHQ6IDEuM2VtOwp9CgphIHsKCWNvbG9yOiAjMDAwOwoJdGV4dC1kZWNvcmF0aW9uOiBub25lOwp9Cg==">
	</head>
	<body>
		<ul class="report combineChildItems">
			<li id="item_ZA2IKRDM" class="item journalArticle">
			<h2>A POMDP Treatment of Vehicle-Pedestrian Interaction: Implicit Coordination Via Uncertainty-Aware Planning</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Journal Article</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Ya-Chuan Hsu</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Swaminathan Gopalswamy</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Srikanth Saripalli</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Dylan Shell</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>8</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>Zotero</td>
					</tr>
					<tr>
					<th>Language</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>Drivers and other road users often encounter situations (e.g.,
 arriving at an intersection simultaneously) where priority is ambiguous
 or unclear but must be resolved via communication to reach agreement. 
This poses a challenge for autonomous vehicles, for which no direct 
means for expressing intent and acknowledgment has yet been established.
 This paper contributes a minimal model to manage ambiguity and produce 
actions that are expressive and encode aspects of intent. Speciﬁcally, 
intent is treated as a latent variable, communicated implicitly through a
 partially observable Markov decision process (POMDP). We validate the 
model in a simple setting: a simulation of a prototypical crossing with a
 vehicle and one pedestrian at an unsignalized intersection. We further 
report use of our self-driving Ford Lincoln MKZ platform, through which 
we conducted experimental trials of the method involving real-time 
interaction. The experiment shows the method achieves safe and efﬁcient 
navigation.</td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>1/14/2021, 11:52:31 AM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>1/14/2021, 11:52:31 AM</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_T9EA3NDN">Hsu et al. - A POMDP Treatment of Vehicle-Pedestrian Interactio.pdf					</li>
				</ul>
			</li>


			<li id="item_U5FL98VZ" class="item conferencePaper">
			<h2>A Transient-Goal Driven Communication-Aware Navigation Strategy for Large Human-Populated Environments</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Conference Paper</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Vishnu K. Narayanan</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Takahiro Miyashita</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Yukiko Horikawa</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Norihiro Hagita</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>1-9</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>October 2018</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>ISSN: 2153-0866, 2153-0858</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.1109/IROS.2018.8593827">10.1109/IROS.2018.8593827</a></td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>IEEE Xplore</td>
					</tr>
					<tr>
					<th>Conference Name</th>
						<td>2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>Robots deployed in large human-populated indoor environments 
such as shopping malls, airports etc., inadvertently communicate via 
wireless networks for enhanced perception and decision making 
capabilities. Owing to highly dynamic signal attenuation characteristics
 in such environments, connectivity issues may arise during robotic 
navigation, leading to disruption in information flow causing potential 
danger. Exact modeling of signal propagation for estimating spatial 
signal variation is usually challenging. Moreover, the presence of 
dynamic humans also add a layer of temporal signal variation 
complexities. Thus, this paper introduces a generative approach for 
embedding radio signal strength constraints within networked 
service/social robot navigation in large human-populated environments. 
Initially, we propose a Gaussian Process based online spatio-temporal 
signal strength prediction model that, as opposed to the current state 
of the art, also aims to take into account the temporal fading arising 
due to the presence of human crowds. We then devise a transient-goal 
driven navigation strategy to realize a sub-optimal path towards a goal,
 that is aimed at resolving both communication-aware and human-aware 
planning constraints. Evaluations of the proposed signal prediction 
model demonstrate the advantages of our approach with respect to the 
current state of the art. The efficacy of the navigation strategy in 
also demonstrated simulations and using hardware experiments conducted 
on a robotic wheelchair operating in a large shopping mall.</td>
					</tr>
					<tr>
					<th>Proceedings Title</th>
						<td>2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>11/12/2019, 4:52:56 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>11/12/2019, 4:52:56 PM</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Tags:</h3>
				<ul class="tags">
					<li>communication-aware planning constraints</li>
					<li>connectivity issues</li>
					<li>decision making</li>
					<li>decision making capabilities</li>
					<li>Fading channels</li>
					<li>Gaussian Process</li>
					<li>Gaussian processes</li>
					<li>human-aware planning constraints</li>
					<li>human-populated indoor environments</li>
					<li>indoor navigation</li>
					<li>mobile robots</li>
					<li>Mobile robots</li>
					<li>Navigation</li>
					<li>networked service</li>
					<li>path planning</li>
					<li>radio signal strength constraints</li>
					<li>Robot sensing systems</li>
					<li>robotic wheelchair operation</li>
					<li>shopping mall</li>
					<li>signal processing</li>
					<li>social robot navigation</li>
					<li>sub-optimal path</li>
					<li>Transient analysis</li>
					<li>transient-goal driven communication-aware navigation strategy</li>
					<li>Wireless communication</li>
					<li>wireless networks</li>
					<li>wireless sensor networks</li>
				</ul>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_X5PLTMWZ">IEEE Xplore Abstract Record					</li>
					<li id="item_NVJT7EIS">Narayanan et al. - 2018 - A Transient-Goal Driven Communication-Aware Naviga.pdf					</li>
				</ul>
			</li>


			<li id="item_XWT8PCQ3" class="item conferencePaper">
			<h2>Bayes Estimator Human Intention Classifier Human Trajectory 
Regression Bayes Estimator Human Intention Classifier Human Trajectory 
Regression Bayes Estimator Human Intention Classifier Human Trajectory 
Regression</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Conference Paper</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Chonhyon Park</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Jan Ondrej</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Max Gilbert</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Kyle Freeman</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Carol O’Sullivan</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2016</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>Semantic Scholar</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>We present an algorithmic framework for the early 
classification of human intentions, and use it to accurately predict 
future human motions when planning the path of a robot in an environment
 that is shared with humans. During an off-line learning phase, a 
classifier that can recognize when a human intends to interact with the 
robot is trained. At runtime, this trained classifier allows us to 
recognize humans who intend to interact with, or obstruct, the robot in 
some way. We validate our approach using both recorded and simulated 
data in an environment in which some humans intentionally obstruct the 
robot. Our classifier identifies these potential blockers, thus allowing
 the robot to safely and efficiently navigate the environment by 
minimizing the chances of being blocked.</td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>11/25/2019, 10:58:07 AM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>11/25/2019, 10:58:07 AM</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Tags:</h3>
				<ul class="tags">
					<li>Automated planning and scheduling</li>
					<li>Behavior</li>
					<li>Benchmark (computing)</li>
					<li>Blocking (computing)</li>
					<li>Intentionally blank page</li>
					<li>Linear classifier</li>
					<li>Motion</li>
					<li>Non-blocking algorithm</li>
					<li>Online and offline</li>
				</ul>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_5NW2CFY5">Full Text PDF					</li>
					<li id="item_4DZCKVQV">Semantic Scholar Link					</li>
				</ul>
			</li>


			<li id="item_NC3L3XFY" class="item conferencePaper">
			<h2>Formalizing a Transient-Goal Driven Approach for Pedestrian-Aware Robot Navigation</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Conference Paper</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Vishnu K. Narayanan</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Takahiro Miyashita</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Norihiro Hagita</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>862-867</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>August 2018</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>ISSN: 1944-9437, 1944-9445</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.1109/ROMAN.2018.8525624">10.1109/ROMAN.2018.8525624</a></td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>IEEE Xplore</td>
					</tr>
					<tr>
					<th>Conference Name</th>
						<td>2018 27th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN)</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>In this paper, we lay the algorithmic foundations of a 
unifying strategy for pedestrian-aware navigation that is aimed at 
service/social robots deployed in large human-crowded environments. In 
order to accommodate both modeled and learned social navigation 
behaviors, we formalize an approach within which the robot traverses to a
 specific goal (or sub-goal) via a trajectory of optimal transient-goals
 or optimal short-term way-points. We then evaluate an implementation of
 the navigation strategy, by utilizing an augmented Risk-based Rapidly 
Exploring Random Trees (RRT) planner, and demonstrate its efficacy for 
real-world deployment using discriminative simulations and by providing 
avenues for future work.</td>
					</tr>
					<tr>
					<th>Proceedings Title</th>
						<td>2018 27th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN)</td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>11/12/2019, 4:52:56 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>11/12/2019, 4:52:56 PM</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Tags:</h3>
				<ul class="tags">
					<li>algorithmic foundations</li>
					<li>Cost function</li>
					<li>human-crowded environments</li>
					<li>mobile robots</li>
					<li>Mobile robots</li>
					<li>navigation</li>
					<li>Navigation</li>
					<li>navigation behaviors</li>
					<li>navigation strategy</li>
					<li>optimal transient-goals</li>
					<li>path planning</li>
					<li>pedestrian-aware navigation</li>
					<li>pedestrian-aware robot navigation</li>
					<li>pedestrians</li>
					<li>Planning</li>
					<li>Prediction algorithms</li>
					<li>real-world deployment</li>
					<li>robot traverses</li>
					<li>service robots</li>
					<li>service/social robots</li>
					<li>short-term way-points</li>
					<li>social navigation behaviors</li>
					<li>Transient analysis</li>
					<li>transient-goal driven approach</li>
					<li>trees (mathematics)</li>
					<li>unifying strategy</li>
				</ul>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_GMESMWZY">IEEE Xplore Abstract Record					</li>
					<li id="item_SB55P493">Narayanan et al. - 2018 - Formalizing a Transient-Goal Driven Approach for P.pdf					</li>
				</ul>
			</li>


			<li id="item_6IZR5J2N" class="item conferencePaper">
			<h2>HI Robot: Human intention-aware robot planning for safe and efficient navigation in crowds</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Conference Paper</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Chonhyon Park</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Jan Ondřej</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Max Gilbert</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Kyle Freeman</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Carol O'Sullivan</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>3320-3326</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>October 2016</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>ISSN: 2153-0866</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.1109/IROS.2016.7759511">10.1109/IROS.2016.7759511</a></td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>IEEE Xplore</td>
					</tr>
					<tr>
					<th>Conference Name</th>
						<td>2016 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>We present an algorithmic framework for the early 
classification of human intentions, and use it to accurately predict 
future human motions when planning the path of a robot in an environment
 that is shared with humans. During an off-line learning phase, a 
classifier that can recognize when a human intends to interact with the 
robot is trained. At runtime, this trained classifier allows us to 
recognize humans who intend to interact with, or obstruct, the robot in 
some way. We validate our approach using both recorded and simulated 
data in an environment in which some humans intentionally obstruct the 
robot. Our classifier identifies these potential blockers, thus allowing
 the robot to safely and efficiently navigate the environment by 
minimizing the chances of being blocked.</td>
					</tr>
					<tr>
					<th>Proceedings Title</th>
						<td>2016 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</td>
					</tr>
					<tr>
					<th>Short Title</th>
						<td>HI Robot</td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>11/12/2019, 4:52:56 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>11/12/2019, 4:52:56 PM</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Tags:</h3>
				<ul class="tags">
					<li>Computational modeling</li>
					<li>HI robot</li>
					<li>human intention-aware robot planning</li>
					<li>mobile robots</li>
					<li>Navigation</li>
					<li>off-line learning phase</li>
					<li>path planning</li>
					<li>Planning</li>
					<li>Robot sensing systems</li>
					<li>Service robots</li>
					<li>Trajectory</li>
				</ul>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_LBEW4INL">IEEE Xplore Abstract Record					</li>
					<li id="item_F47YFVEI">Park et al. - 2016 - HI Robot Human intention-aware robot planning for.pdf					</li>
				</ul>
			</li>


			<li id="item_UM5FKJGQ" class="item journalArticle">
			<h2>IAN: Multi-Behavior Navigation Planning for Robots in Real, Crowded Environments</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Journal Article</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Daniel Dugas</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Juan Nieto</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Roland Siegwart</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Jen Jen Chung</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>8</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>Zotero</td>
					</tr>
					<tr>
					<th>Language</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>State-of-the-art approaches for robot navigation among humans 
are typically restricted to planar movement actions. This work addresses
 the question of whether it can be beneﬁcial to use interaction actions,
 such as saying, touching, and gesturing, for the sake of allowing 
robots to navigate in unstructured, crowded environments. To do so, we 
ﬁrst identify challenging scenarios to traditional motion planning 
methods. Based on the hypothesis that the variation in modality for 
these scenarios calls for signiﬁcantly different planning policies, we 
design speciﬁc navigation behaviors as interaction planners for 
actuated, mobile robots. We further propose a high level planning 
algorithm for multi-behavior navigation, named Interaction Actions for 
Navigation (IAN). Through both real-world and simulated experiments, we 
validate the selected behaviors and the high-level planning algorithm, 
and discuss the impact of our obtained results on our stated 
assumptions.</td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>1/14/2021, 11:50:50 AM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>1/14/2021, 11:50:50 AM</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_KEZDDWJB">Dugas et al. - IAN Multi-Behavior Navigation Planning for Robots.pdf					</li>
				</ul>
			</li>


			<li id="item_9XVL7E72" class="item conferencePaper">
			<h2>Inverse Reinforcement Learning algorithms and features for robot navigation in crowds: An experimental comparison</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Conference Paper</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>D. Vasquez</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>B. Okal</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>K. O. Arras</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>1341-1346</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>Sep. 2014</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.1109/IROS.2014.6942731">10.1109/IROS.2014.6942731</a></td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>IEEE Xplore</td>
					</tr>
					<tr>
					<th>Conference Name</th>
						<td>2014 IEEE/RSJ International Conference on Intelligent Robots and Systems</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>For mobile robots which operate in human populated 
environments, modeling social interactions is key to understand and 
reproduce people's behavior. A promising approach to this end is Inverse
 Reinforcement Learning (IRL) as it allows to model the factors that 
motivate people's actions instead of the actions themselves. A crucial 
design choice in IRL is the selection of features that encode the 
agent's context. In related work, features are typically chosen ad hoc 
without systematic evaluation of the alternatives and their actual 
impact on the robot's task. In this paper, we introduce a new software 
framework to systematically investigate the effect features and learning
 algorithms used in the literature. We also present results for the task
 of socially compliant robot navigation in crowds, evaluating two 
different IRL approaches and several feature sets in large-scale 
simulations. The results are benchmarked according to a proposed set of 
objective and subjective performance metrics.</td>
					</tr>
					<tr>
					<th>Proceedings Title</th>
						<td>2014 IEEE/RSJ International Conference on Intelligent Robots and Systems</td>
					</tr>
					<tr>
					<th>Short Title</th>
						<td>Inverse Reinforcement Learning algorithms and features for robot navigation in crowds</td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>11/12/2019, 4:52:56 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>11/12/2019, 4:52:56 PM</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Tags:</h3>
				<ul class="tags">
					<li>Airports</li>
					<li>control engineering computing</li>
					<li>inverse reinforcement learning algorithm</li>
					<li>IRL approach</li>
					<li>learning (artificial intelligence)</li>
					<li>mobile robots</li>
					<li>Navigation</li>
					<li>objective performance metrics</li>
					<li>path planning</li>
					<li>robot navigation</li>
					<li>Robots</li>
					<li>Silicon</li>
					<li>social interaction modeling</li>
					<li>software framework</li>
					<li>subjective performance metrics</li>
					<li>Tin</li>
					<li>Vectors</li>
					<li>Vehicles</li>
				</ul>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_B4BQIBLS">IEEE Xplore Abstract Record					</li>
					<li id="item_53UMJD3M">Submitted Version					</li>
				</ul>
			</li>


			<li id="item_8VJJP2GZ" class="item journalArticle">
			<h2>L2B: Learning to Balance the Safety-Efficiency Trade-Off in Interactive Crowd-Aware Robot Navigation</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Journal Article</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Mai Nishimura</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Ryo Yonetani</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>7</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>Zotero</td>
					</tr>
					<tr>
					<th>Language</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>This work presents a deep reinforcement learning framework for
 interactive navigation in a crowded place. Our proposed Learning to 
Balance (L2B) framework enables mobile robot agents to steer safely 
towards their destinations by avoiding collisions with a crowd, while 
actively clearing a path by asking nearby pedestrians to make room, if 
necessary, to keep their travel efﬁcient. We observe that the safety and
 efﬁciency requirements in crowd-aware navigation have a tradeoff in the
 presence of social dilemmas between the agent and the crowd. On the one
 hand, intervening in pedestrian paths too much to achieve instant 
efﬁciency will result in collapsing a natural crowd ﬂow and may 
eventually put everyone, including the self, at risk of collisions. On 
the other hand, keeping in silence to avoid every single collision will 
lead to the agent’s inefﬁcient travel. With this observation, our L2B 
framework augments the reward function used in learning an interactive 
navigation policy to penalize frequent active path clearing and passive 
collision avoidance, which substantially improves the balance of the 
safety-efﬁciency trade-off. We evaluate our L2B framework in a 
challenging crowd simulation and demonstrate its superiority, in terms 
of both navigation success and collision rate, over a state-of-the-art 
navigation approach.</td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>1/14/2021, 11:50:52 AM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>1/14/2021, 11:50:52 AM</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_KIEFKKLL">Nishimura and Yonetani - L2B Learning to Balance the Safety-Efficiency Tra.pdf					</li>
				</ul>
			</li>


			<li id="item_C5CI65HN" class="item bookSection">
			<h2>MPDM: Multi-policy Decision-Making from Autonomous Driving to Social Robot Navigation</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Book Section</td>
					</tr>
					<tr>
						<th class="editor">Editor</th>
						<td>Harald Waschl</td>
					</tr>
					<tr>
						<th class="editor">Editor</th>
						<td>Ilya Kolmanovsky</td>
					</tr>
					<tr>
						<th class="editor">Editor</th>
						<td>Frank Willems</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Alex G. Cunningham</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Enric Galceran</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Dhanvin Mehta</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Gonzalo Ferrer</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Ryan M. Eustice</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Edwin Olson</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="http://link.springer.com/10.1007/978-3-319-91569-2_10">http://link.springer.com/10.1007/978-3-319-91569-2_10</a></td>
					</tr>
					<tr>
					<th>Volume</th>
						<td>476</td>
					</tr>
					<tr>
					<th>Place</th>
						<td>Cham</td>
					</tr>
					<tr>
					<th>Publisher</th>
						<td>Springer International Publishing</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>201-223</td>
					</tr>
					<tr>
					<th>ISBN</th>
						<td>978-3-319-91568-5 978-3-319-91569-2</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2019</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>DOI: 10.1007/978-3-319-91569-2_10</td>
					</tr>
					<tr>
					<th>Accessed</th>
						<td>11/4/2019, 12:57:53 PM</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>DOI.org (Crossref)</td>
					</tr>
					<tr>
					<th>Language</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>This chapter presents Multi-Policy Decision-Making (MPDM): a 
novel approach to navigating in dynamic multi-agent environments. Rather
 than planning the trajectory of the robot explicitly, the planning 
process selects one of a set of closed-loop behaviors whose utility can 
be predicted through forward simulation that capture the complex 
interactions between the actions of these agents. These polices capture 
different high-level behavior and intentions, such as driving along a 
lane, turning at an intersection, or following pedestrians. We present 
two different scenarios where MPDM has been applied successfully: An 
autonomous driving environment that models vehicle behavior for both our
 vehicle and nearby vehicles and a social environment, where multiple 
agents or pedestrians conﬁgure a dynamic environment for autonomous 
robot navigation. We present extensive validation for MPDM on both 
scenarios, using simulated and real-world experiments.</td>
					</tr>
					<tr>
					<th>Book Title</th>
						<td>Control Strategies for Advanced Driver Assistance Systems and Autonomous Driving Functions</td>
					</tr>
					<tr>
					<th>Short Title</th>
						<td>MPDM</td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>11/12/2019, 4:52:56 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>11/12/2019, 4:52:56 PM</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_NW4AQYES">Cunningham et al. - 2019 - MPDM Multi-policy Decision-Making from Autonomous.pdf					</li>
				</ul>
			</li>


			<li id="item_NIHSQCHE" class="item journalArticle">
			<h2>Relational Graph Learning for Crowd Navigation</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Journal Article</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Changan Chen</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Sha Hu</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Payam Nikdel</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Greg Mori</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Manolis Savva</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>7</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>Zotero</td>
					</tr>
					<tr>
					<th>Language</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>We present a relational graph learning approach for robotic 
crowd navigation using model-based deep reinforcement learning that 
plans actions by looking into the future. Our approach reasons about the
 relations between all agents based on their latent features and uses a 
Graph Convolutional Network to encode higher-order interactions in each 
agent’s state representation, which is subsequently leveraged for state 
prediction and value estimation. The ability to predict human motion 
allows us to perform multi-step lookahead planning, taking into account 
the temporal evolution of human crowds. We evaluate our approach against
 a state-of-the-art baseline for crowd navigation and ablations of our 
model to demonstrate that navigation with our approach is more efﬁcient,
 results in fewer collisions, and avoids failure cases involving 
oscillatory and freezing behaviors.</td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>1/14/2021, 11:51:02 AM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>1/14/2021, 11:51:02 AM</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_JXKACWZW">Chen et al. - Relational Graph Learning for Crowd Navigation.pdf					</li>
				</ul>
			</li>


			<li id="item_489YRU8Z" class="item conferencePaper">
			<h2>Robot companion: A social-force based approach with human awareness-navigation in crowded environments</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Conference Paper</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>G. Ferrer</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>A. Garrell</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>A. Sanfeliu</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>1688-1694</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>November 2013</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.1109/IROS.2013.6696576">10.1109/IROS.2013.6696576</a></td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>IEEE Xplore</td>
					</tr>
					<tr>
					<th>Conference Name</th>
						<td>2013 IEEE/RSJ International Conference on Intelligent Robots and Systems</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>Robots accompanying humans is one of the core capacities every
 service robot deployed in urban settings should have. We present a 
novel robot companion approach based on the so-called Social Force Model
 (SFM). A new model of robot-person interaction is obtained using the 
SFM which is suited for our robots Tibi and Dabo. Additionally, we 
propose an interactive scheme for robot's human-awareness navigation 
using the SFM and prediction information. Moreover, we present a new 
metric to evaluate the robot companion performance based on vital spaces
 and comfortableness criteria. Also, a multimodal human feedback is 
proposed to enhance the behavior of the system. The validation of the 
model is accomplished throughout an extensive set of simulations and 
real-life experiments.</td>
					</tr>
					<tr>
					<th>Proceedings Title</th>
						<td>2013 IEEE/RSJ International Conference on Intelligent Robots and Systems</td>
					</tr>
					<tr>
					<th>Short Title</th>
						<td>Robot companion</td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>11/12/2019, 4:52:56 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>11/12/2019, 4:52:56 PM</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Tags:</h3>
				<ul class="tags">
					<li>comfortableness criteria</li>
					<li>control engineering computing</li>
					<li>crowded environments</li>
					<li>Dabo</li>
					<li>Force</li>
					<li>human awareness-navigation</li>
					<li>human-robot interaction</li>
					<li>interactive scheme</li>
					<li>Mathematical model</li>
					<li>Measurement</li>
					<li>multimodal human feedback</li>
					<li>Navigation</li>
					<li>prediction information</li>
					<li>robot companion approach</li>
					<li>robot companion performance</li>
					<li>robot human-awareness navigation</li>
					<li>Robot sensing systems</li>
					<li>robot-person interaction</li>
					<li>service robot</li>
					<li>service robots</li>
					<li>SFM</li>
					<li>social force model</li>
					<li>social-force based approach</li>
					<li>Tibi</li>
					<li>Trajectory</li>
					<li>vital spaces</li>
				</ul>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_EU78ZEDY">IEEE Xplore Abstract Record					</li>
					<li id="item_MFS78RWL">Submitted Version					</li>
				</ul>
			</li>


			<li id="item_87Y4LWH8" class="item conferencePaper">
			<h2>Robot local navigation with learned social cost functions</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Conference Paper</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Noé Pérez-Higueras</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Rafael Ramón-Vigo</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Fernando Caballero</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Luis Merino</td>
					</tr>
					<tr>
					<th>Volume</th>
						<td>02</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>618-625</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>Sep. 2014</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.5220/0005120806180625">10.5220/0005120806180625</a></td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>IEEE Xplore</td>
					</tr>
					<tr>
					<th>Conference Name</th>
						<td>2014 11th International Conference on Informatics in Control, Automation and Robotics (ICINCO)</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>Robot navigation in human environments is an active research 
area that poses serious challenges. Among them, human-awareness has gain
 lot of attention in the last years due to its important role in human 
safety and robot acceptance. The proposed robot navigation system 
extends state of the navigation schemes with some social skills in order
 to naturally integrate the robot motion in crowded areas. Learning has 
been proposed as a more principled way of estimating the insights of 
human social interactions. To do this, inverse reinforcement learning is
 used to derive social cost functions by observing persons walking 
through the streets. Our objective is to incorporate such costs into the
 robot navigation stack in order to “emulate” these human interactions. 
In order to alleviate the complexity, the system is focused on learning 
an adequate cost function to be applied at the local navigation level, 
thus providing direct low-level controls to the robot. The paper 
presents an analysis of the results in a robot navigating in challenging
 real scenarios, analyzing and comparing this approach with other 
algorithms.</td>
					</tr>
					<tr>
					<th>Proceedings Title</th>
						<td>2014 11th International Conference on Informatics in Control, Automation and Robotics (ICINCO)</td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>11/12/2019, 4:52:56 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>11/12/2019, 4:52:56 PM</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Tags:</h3>
				<ul class="tags">
					<li>Cost function</li>
					<li>Inverse Reinforcement Learning</li>
					<li>Lasers</li>
					<li>Learning from Demonstrations</li>
					<li>Navigation</li>
					<li>Planning</li>
					<li>Robot Navigation</li>
					<li>Robot sensing systems</li>
					<li>Social Robots</li>
					<li>Trajectory</li>
				</ul>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_C5KRPSPT">IEEE Xplore Abstract Record					</li>
					<li id="item_PJRGLUTU">Pérez-Higueras et al. - 2014 - Robot Local Navigation with Learned Social Cost Fu.pdf					</li>
				</ul>
			</li>


			<li id="item_T6MY53WK" class="item journalArticle">
			<h2>Robot Navigation in Crowded Environments Using Deep Reinforcement Learning</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Journal Article</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Lucia Liu</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Daniel Dugas</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Gianluca Cesari</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Roland Siegwart</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Renaud DubÃ</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>7</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>Zotero</td>
					</tr>
					<tr>
					<th>Language</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>Mobile robots operating in public environments require the 
ability to navigate among humans and other obstacles in a socially 
compliant and safe manner. This work presents a combined imitation 
learning and deep reinforcement learning approach for motion planning in
 such crowded and cluttered environments. By separately processing 
information related to static and dynamic objects, we enable our network
 to learn motion patterns that are tailored to real-world environments. 
Our model is also designed such that it can handle usual cases in which 
robots can be equipped with sensor suites that only offer limited ﬁeld 
of view. Our model outperforms current state-ofthe-art approaches, which
 is shown in simulated environments containing human-like agents and 
static obstacles. Additionally, we demonstrate the real-time performance
 and applicability of our model by successfully navigating a robotic 
platform through real-world environments.</td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>1/14/2021, 11:51:05 AM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>1/14/2021, 11:51:05 AM</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_5WGD2TIQ">Liu et al. - Robot Navigation in Crowded Environments Using Dee.pdf					</li>
				</ul>
			</li>


			<li id="item_HTK5NBAK" class="item journalArticle">
			<h2>Robot social-aware navigation framework to accompany people walking side-by-side</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Journal Article</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Gonzalo Ferrer</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Anaís Garrell Zulueta</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Fernando Herrero Cotarelo</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Alberto Sanfeliu</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://doi.org/10.1007/s10514-016-9584-y">https://doi.org/10.1007/s10514-016-9584-y</a></td>
					</tr>
					<tr>
					<th>Volume</th>
						<td>41</td>
					</tr>
					<tr>
					<th>Issue</th>
						<td>4</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>775-793</td>
					</tr>
					<tr>
					<th>Publication</th>
						<td>Autonomous Robots</td>
					</tr>
					<tr>
					<th>ISSN</th>
						<td>1573-7527</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2017-04-01</td>
					</tr>
					<tr>
					<th>Journal Abbr</th>
						<td>Auton Robot</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.1007/s10514-016-9584-y">10.1007/s10514-016-9584-y</a></td>
					</tr>
					<tr>
					<th>Accessed</th>
						<td>4/4/2019, 3:04:04 PM</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>Springer Link</td>
					</tr>
					<tr>
					<th>Language</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>We present a novel robot social-aware navigation framework to 
walk side-by-side with people in crowded urban areas in a safety and 
natural way. The new system includes the following key issues: to 
propose a new robot social-aware navigation model to accompany a person;
 to extend the Social Force Model, “Extended Social-Force Model”, to 
consider the person and robot’s interactions; to use a human predictor 
to estimate the destination of the person the robot is walking with; and
 to interactively learning the parameters of the social-aware navigation
 model using multimodal human feedback. Finally, a quantitative metric 
based on people’s personal spaces and comfortableness criteria, is 
introduced in order to evaluate quantitatively the performance of the 
robot’s task. The validation of the model is accomplished throughout an 
extensive set of simulations and real-life experiments. In addition, a 
volunteers’ survey is used to measure the acceptability of our robot 
companion’s behavior.</td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>11/12/2019, 4:52:56 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>11/12/2019, 4:52:56 PM</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Tags:</h3>
				<ul class="tags">
					<li>Human–robot interaction</li>
					<li>Robot companion</li>
					<li>Service robots</li>
					<li>Urban robot navigation</li>
				</ul>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_SF9WJIGQ">Submitted Version					</li>
				</ul>
			</li>


			<li id="item_7SPVMBMS" class="item conferencePaper">
			<h2>Social-aware robot navigation in urban environments</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Conference Paper</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>G. Ferrer</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>A. Garrell</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>A. Sanfeliu</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>331-336</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>Sep. 2013</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.1109/ECMR.2013.6698863">10.1109/ECMR.2013.6698863</a></td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>IEEE Xplore</td>
					</tr>
					<tr>
					<th>Conference Name</th>
						<td>2013 European Conference on Mobile Robots</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>In this paper we present a novel robot navigation approach 
based on the so-called Social Force Model (SFM). First, we construct a 
graph map with a set of destinations that completely describe the 
navigation environment. Second, we propose a robot navigation algorithm,
 called social-aware navigation, which is mainly driven by the 
social-forces centered at the robot. Third, we use a MCMC 
Metropolis-Hastings algorithm in order to learn the parameters values of
 the method. Finally, the validation of the model is accomplished 
throughout an extensive set of simulations and real-life experiments.</td>
					</tr>
					<tr>
					<th>Proceedings Title</th>
						<td>2013 European Conference on Mobile Robots</td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>11/12/2019, 4:52:56 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>11/12/2019, 4:52:56 PM</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Tags:</h3>
				<ul class="tags">
					<li>Collision avoidance</li>
					<li>Force</li>
					<li>graph map</li>
					<li>graph theory</li>
					<li>human-robot interaction</li>
					<li>MCMC Metropolis-Hastings algorithm</li>
					<li>mobile robots</li>
					<li>Navigation</li>
					<li>parameter value learning</li>
					<li>path planning</li>
					<li>Robot sensing systems</li>
					<li>Safety</li>
					<li>SFM</li>
					<li>social force model</li>
					<li>social-aware robot navigation</li>
					<li>Urban areas</li>
					<li>urban environments</li>
				</ul>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_DYBVRAAY">IEEE Xplore Abstract Record					</li>
					<li id="item_3I2RJ9BA">Submitted Version					</li>
				</ul>
			</li>


			<li id="item_F4UXTXQV" class="item journalArticle">
			<h2>Socially Aware Motion Planning with Deep Reinforcement Learning</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Journal Article</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Yu Fan Chen</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Michael Everett</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Miao Liu</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Jonathan P. How</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="http://arxiv.org/abs/1703.08862">http://arxiv.org/abs/1703.08862</a></td>
					</tr>
					<tr>
					<th>Publication</th>
						<td>arXiv:1703.08862 [cs]</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2017-03-26</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>arXiv: 1703.08862</td>
					</tr>
					<tr>
					<th>Accessed</th>
						<td>4/2/2019, 4:49:49 PM</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>arXiv.org</td>
					</tr>
					<tr>
					<th>Language</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>For robotic vehicles to navigate safely and efﬁciently in 
pedestrian-rich environments, it is important to model subtle human 
behaviors and navigation rules (e.g., passing on the right). However, 
while instinctive to humans, socially compliant navigation is still 
difﬁcult to quantify due to the stochasticity in people’s behaviors. 
Existing works are mostly focused on using feature-matching techniques 
to describe and imitate human paths, but often do not generalize well 
since the feature values can vary from person to person, and even run to
 run. This work notes that while it is challenging to directly specify 
the details of what to do (precise mechanisms of human navigation), it 
is straightforward to specify what not to do (violations of social 
norms). Speciﬁcally, using deep reinforcement learning, this work 
develops a time-efﬁcient navigation policy that respects common social 
norms. The proposed method is shown to enable fully autonomous 
navigation of a robotic vehicle moving at human walking speed in an 
environment with many pedestrians.</td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>11/12/2019, 4:52:56 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>11/12/2019, 4:52:56 PM</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Tags:</h3>
				<ul class="tags">
					<li>Computer Science - Artificial Intelligence</li>
					<li>Computer Science - Human-Computer Interaction</li>
					<li>Computer Science - Robotics</li>
				</ul>
				<h3 class="notes">Notes:</h3>
				<ul class="notes">
					<li id="item_SDXVSS4N">
<p class="plaintext">Comment: 8 pages</p>
					</li>
				</ul>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_L8CHNF37">Chen et al. - 2017 - Socially Aware Motion Planning with Deep Reinforce.pdf					</li>
				</ul>
			</li>


			<li id="item_H2R3WRBA" class="item conferencePaper">
			<h2>Socially-aware robot navigation: A learning approach</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Conference Paper</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>M. Luber</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>L. Spinello</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>J. Silva</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>K. O. Arras</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>902-907</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>October 2012</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.1109/IROS.2012.6385716">10.1109/IROS.2012.6385716</a></td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>IEEE Xplore</td>
					</tr>
					<tr>
					<th>Conference Name</th>
						<td>2012 IEEE/RSJ International Conference on Intelligent Robots and Systems</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>The ability to act in a socially-aware way is a key skill for 
robots that share a space with humans. In this paper we address the 
problem of socially-aware navigation among people that meets objective 
criteria such as travel time or path length as well as subjective 
criteria such as social comfort. Opposed to model-based approaches 
typically taken in related work, we pose the problem as an unsupervised 
learning problem. We learn a set of dynamic motion prototypes from 
observations of relative motion behavior of humans found in publicly 
available surveillance data sets. The learned motion prototypes are then
 used to compute dynamic cost maps for path planning using an any-angle 
A* algorithm. In the evaluation we demonstrate that the learned 
behaviors are better in reproducing human relative motion in both 
criteria than a Proxemics-based baseline method.</td>
					</tr>
					<tr>
					<th>Proceedings Title</th>
						<td>2012 IEEE/RSJ International Conference on Intelligent Robots and Systems</td>
					</tr>
					<tr>
					<th>Short Title</th>
						<td>Socially-aware robot navigation</td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>11/12/2019, 4:52:56 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>11/12/2019, 4:52:56 PM</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Tags:</h3>
				<ul class="tags">
					<li>any-angle A* algorithm</li>
					<li>Computational modeling</li>
					<li>Context</li>
					<li>dynamic motion prototypes</li>
					<li>Dynamics</li>
					<li>Heuristic algorithms</li>
					<li>Humans</li>
					<li>learning approach</li>
					<li>mobile robots</li>
					<li>path length</li>
					<li>Prototypes</li>
					<li>Proxemics-based baseline method</li>
					<li>Robots</li>
					<li>social sciences</li>
					<li>socially-aware robot navigation</li>
					<li>travel time</li>
					<li>unsupervised learning</li>
					<li>unsupervised learning problem</li>
				</ul>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_SQG45X52">IEEE Xplore Abstract Record					</li>
					<li id="item_MLN8YN5E">Submitted Version					</li>
				</ul>
			</li>

		</ul>
	
</body></html>