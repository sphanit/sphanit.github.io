<!DOCTYPE html>
<html><head>
		<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
		<title>Zotero Report</title>
		<link rel="stylesheet" type="text/css" href="data:text/css;base64,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">
		<link rel="stylesheet" type="text/css" media="screen,projection" href="data:text/css;base64,LyogR2VuZXJpYyBzdHlsZXMgKi8KYm9keSB7Cglmb250OiA2Mi41JSBHZW9yZ2lhLCBUaW1lcywgc2VyaWY7Cgl3aWR0aDogNzgwcHg7CgltYXJnaW46IDAgYXV0bzsKfQoKaDIgewoJZm9udC1zaXplOiAxLjVlbTsKCWxpbmUtaGVpZ2h0OiAxLjVlbTsKCWZvbnQtZmFtaWx5OiBHZW9yZ2lhLCBUaW1lcywgc2VyaWY7Cn0KCnAgewoJbGluZS1oZWlnaHQ6IDEuNWVtOwp9CgphOmxpbmssIGE6dmlzaXRlZCB7Cgljb2xvcjogIzkwMDsKfQoKYTpob3ZlciwgYTphY3RpdmUgewoJY29sb3I6ICM3Nzc7Cn0KCgp1bC5yZXBvcnQgewoJZm9udC1zaXplOiAxLjRlbTsKCXdpZHRoOiA2ODBweDsKCW1hcmdpbjogMCBhdXRvOwoJcGFkZGluZzogMjBweCAyMHB4Owp9CgovKiBNZXRhZGF0YSB0YWJsZSAqLwp0YWJsZSB7Cglib3JkZXI6IDFweCAjY2NjIHNvbGlkOwoJb3ZlcmZsb3c6IGF1dG87Cgl3aWR0aDogMTAwJTsKCW1hcmdpbjogLjFlbSBhdXRvIC43NWVtOwoJcGFkZGluZzogMC41ZW07Cn0K">
		<link rel="stylesheet" type="text/css" media="print" href="data:text/css;base64,Ym9keSB7Cglmb250OiAxMnB0ICJUaW1lcyBOZXcgUm9tYW4iLCBUaW1lcywgR2VvcmdpYSwgc2VyaWY7CgltYXJnaW46IDA7Cgl3aWR0aDogYXV0bzsKCWNvbG9yOiBibGFjazsKfQoKLyogUGFnZSBCcmVha3MgKHBhZ2UtYnJlYWstaW5zaWRlIG9ubHkgcmVjb2duaXplZCBieSBPcGVyYSkgKi8KaDEsIGgyLCBoMywgaDQsIGg1LCBoNiB7CglwYWdlLWJyZWFrLWFmdGVyOiBhdm9pZDsKCXBhZ2UtYnJlYWstaW5zaWRlOiBhdm9pZDsKfQoKdWwsIG9sLCBkbCB7CglwYWdlLWJyZWFrLWluc2lkZTogYXZvaWQ7Cgljb2xvci1hZGp1c3Q6IGV4YWN0Owp9CgpoMiB7Cglmb250LXNpemU6IDEuM2VtOwoJbGluZS1oZWlnaHQ6IDEuM2VtOwp9CgphIHsKCWNvbG9yOiAjMDAwOwoJdGV4dC1kZWNvcmF0aW9uOiBub25lOwp9Cg==">
	</head>
	<body>
		<ul class="report combineChildItems">
			<li id="item_NH42W2FE" class="item journalArticle">
			<h2>Learning Human Navigation Behavior Using Measured Human Trajectories in Crowded Spaces</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Journal Article</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Muhammad Fahad</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Guang Yang</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Yi Guo</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>As humans and mobile robots increasingly coexist in public 
spaces, their close proximity demands that robots navigate following 
navigation strategies similar to those exhibited by humans. This could 
be achieved by learning directly from human demonstration trajectories 
in a machine learning framework. In this paper, we present a method to 
learn human navigation behaviors using an imitation learning approach 
based on generative adversarial imitation learning (GAIL), which has the
 ability of directly extracting navigation policy. Speciﬁcally, we use a
 large open human trajectory dataset that was experimentally collected 
in a crowded public space. We then recreate these human trajectories in a
 3D robotic simulator, and generate demonstration data using a LIDAR 
sensor onboard a robot with the robot following the measured human 
trajectories. We then propose a GAIL based algorithm, which uses 
occupancy maps generated using LIDAR data as the input, and outputs the 
navigation policy for robot navigation. Simulation experiments are 
conducted, and performance evaluation shows that the learned navigation 
policy generates trajectories qualitatively and quantitatively similar 
to human trajectories. Compared with existing works using analytical 
models (such as social force model) to generate human demonstration 
trajectories, our method learns directly from intrinsic human 
trajectories, thus exhibits more humanlike navigation behaviors.</td>
					</tr>
					<tr>
					<th>Language</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>Zotero</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>7</td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_EWAUG2R3">Fahad et al. - Learning Human Navigation Behavior Using Measured .pdf					</li>
				</ul>
			</li>


			<li id="item_VD5PI8IM" class="item journalArticle">
			<h2>Learning Local Planners for Human-Aware Navigation in Indoor Environments</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Journal Article</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Ronja Gã</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>Established indoor robot navigation frameworks build on the 
separation between global and local planners. Whereas global planners 
rely on traditional graph search algorithms, local planners are expected
 to handle driving dynamics and resolve minor conﬂicts. We present a 
system to train neuralnetwork policies for such a local planner 
component, explicitly accounting for humans navigating the space. 
DRL-agents are trained in randomized virtual 2D environments with 
simulated human interaction. The trained agents can be deployed as a 
drop-in replacement for other local planners and signiﬁcantly improve on
 traditional implementations. Performance is demonstrated on a MiR-100 
transport robot.</td>
					</tr>
					<tr>
					<th>Language</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>Zotero</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>8</td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_MCRENSHT">Gã - Learning Local Planners for Human-Aware Navigation.pdf					</li>
				</ul>
			</li>


			<li id="item_BRFTQUW4" class="item journalArticle">
			<h2>A Data-Driven Framework for Proactive Intention-Aware Motion Planning of a Robot in a Human Environment</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Journal Article</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Rahul Peddi</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Carmelo Di Franco</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>SHIJIE Gao</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Nicola Bezzo</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>For safe and efﬁcient human-robot interaction, a robot needs 
to predict and understand the intentions of humans who share the same 
space. Mobile robots are traditionally built to be reactive, moving in 
unnatural ways without following social protocol, hence forcing people 
to behave very differently from human-human interaction rules, which can
 be overcome if robots instead were proactive. In this paper, we build 
an intention-aware proactive motion planning strategy for mobile robots 
that coexist with multiple humans. We propose a framework that uses 
Hidden Markov Model (HMM) theory with a history of observations to: i) 
predict future states and estimate the likelihood that humans will cross
 the path of a robot, and ii) concurrently learn, update, and improve 
the predictive model with new observations at run-time. Stochastic 
reachability analysis is proposed to identify multiple possibilities of 
future states and a control scheme that leverages temporal virtual 
physics inspired by spring-mass systems is proposed to enable safe 
proactive motion planning. The proposed approach is validated with 
simulations and experiments involving an unmanned ground vehicle (UGV) 
performing go-to-goal operations in the presence of multiple humans, 
demonstrating improved performance and effectiveness of online learning 
when compared to reactive obstacle avoidance approaches.</td>
					</tr>
					<tr>
					<th>Language</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>Zotero</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>7</td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_2SXWVVEG">Peddi et al. - A Data-Driven Framework for Proactive Intention-Aw.pdf					</li>
				</ul>
			</li>


			<li id="item_4JPVLRQC" class="item journalArticle">
			<h2>An Integrative Approach of Social Dynamic Long Short-Term Memory 
and Deep Reinforcement Learning for Socially Aware Robot Navigation</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Journal Article</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Xuan Tung Truong</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Trung Dung Ngo</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>In this study, we propose an integrative approach of Long 
short-term memory (LSTM) networks and a deep reinforcement learning 
(DRL) technique for socially aware robot navigation in crowded and 
dynamic environments. The proposed system is an integration of two main 
stages: (1) socio-spatio-temporal characteristics of the humans are 
encoded by using the LSTM networks, and (2) the encoded social dynamic 
characteristics are then fed into the DRL algorithm in order to generate
 motion control commands for a mobile robot. We integrated the developed
 system onto the conventional mobile robot navigation system and veriﬁed
 it in a simulated environment. The simulation results show that the 
proposed socially aware robot navigation system enables the mobile robot
 to behave in socially acceptable manners.</td>
					</tr>
					<tr>
					<th>Language</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>Zotero</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>2</td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_NPPBDZWQ">Truong and Ngo - An Integrative Approach of Social Dynamic Long Sho.pdf					</li>
				</ul>
			</li>


			<li id="item_3XFUZT9B" class="item journalArticle">
			<h2>Human-Aware Robot Navigation by Long-Term Movement Prediction</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Journal Article</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Lilli Bruckschen</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Kira Bungert</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Nils Dengler</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Maren Bennewitz</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>Foresighted, human-aware navigation is a prerequisite for 
service robots acting in indoor environments. In this paper, we present a
 novel human-aware navigation approach that relies on long-term 
prediction of human movements. In particular, we consider the problem of
 ﬁnding a path from the robot’s current position to the initially 
unknown navigation goal of a moving user to provide timely assistance 
there. The navigation strategy has to minimize the robot’s arrival time 
and at the same time comply with the user’s comfort during the movement.
 Our solution predicts the user’s navigation goal based on the robot’s 
observations and prior knowledge about typical human transitions between
 objects. Based on the motion prediction, we then compute a 
time-dependent cost map that encodes the belief about the user’s 
positions at future time steps. Using this map, we solve the 
time-dependent shortest path problem to ﬁnd an efﬁcient path for the 
robot, which still abides by the rules of human comfort. To identify 
robot navigation actions that are perceived as uncomfortable by humans, 
we performed user surveys and deﬁned the corresponding constraints. We 
thoroughly evaluated our navigation system in simulation as well as in 
real-world experiments. As the results show, our system outperforms 
existing approaches in terms of human comfort, while still minimizing 
arrival times of the robot.</td>
					</tr>
					<tr>
					<th>Language</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>Zotero</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>6</td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_DGJQQA9G">Bruckschen et al. - Human-Aware Robot Navigation by Long-Term Movement.pdf					</li>
				</ul>
			</li>


			<li id="item_LHRN9ES2" class="item journalArticle">
			<h2>Risk-Sensitive Sequential Action Control with Multi-Modal Human Trajectory Forecasting for Safe Crowd-Robot Interaction</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Journal Article</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Haruki Nishimura</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Boris Ivanovic</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Adrien Gaidon</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Marco Pavone</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Mac Schwager</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>This paper presents a novel online framework for safe 
crowd-robot interaction based on risk-sensitive stochastic optimal 
control, wherein the risk is modeled by the entropic risk measure. The 
sampling-based model predictive control relies on mode insertion 
gradient optimization for this risk measure as well as Trajectron++, a 
state-of-the-art generative model that produces multimodal probabilistic
 trajectory forecasts for multiple interacting agents. Our modular 
approach decouples the crowd-robot interaction into learning-based 
prediction and model-based control, which is advantageous compared to 
endto-end policy learning methods in that it allows the robot’s desired 
behavior to be speciﬁed at run time. In particular, we show that the 
robot exhibits diverse interaction behavior by varying the risk 
sensitivity parameter. A simulation study and a real-world experiment 
show that the proposed online framework can accomplish safe and efﬁcient
 navigation while avoiding collisions with more than 50 humans in the 
scene.</td>
					</tr>
					<tr>
					<th>Language</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>Zotero</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>8</td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_7RMVXMC8">Nishimura et al. - Risk-Sensitive Sequential Action Control with Mult.pdf					</li>
				</ul>
			</li>


			<li id="item_DY9RBAYP" class="item journalArticle">
			<h2>Forecasting Trajectory and Behavior of Road-Agents Using Spectral Clustering in Graph-LSTMs</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Journal Article</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Rohan Chandra</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Tianrui Guan</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Srujan Panuganti</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Trisha Mittal</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Uttaran Bhattacharya</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Aniket Bera</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Dinesh Manocha</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>We present a novel approach for trafﬁc forecasting in urban 
trafﬁc scenarios using a combination of spectral graph analysis and deep
 learning. We predict both the lowlevel information (future 
trajectories) as well as the high-level information (road-agent 
behavior) from the extracted trajectory of each road-agent. Our 
formulation represents the proximity between the road agents using a 
weighted dynamic geometric graph (DGG). We use a two-stream graph-LSTM 
network to perform trafﬁc forecasting using these weighted DGGs. The 
ﬁrst stream predicts the spatial coordinates of road-agents, while the 
second stream predicts whether a road-agent is going to exhibit 
overspeeding, underspeeding, or neutral behavior by modeling spatial 
interactions between road-agents. Additionally, we propose a new 
regularization algorithm based on spectral clustering to reduce the 
error margin in long-term prediction (3-5 seconds) and improve the 
accuracy of the predicted trajectories. Moreover, we prove a theoretical
 upper bound on the regularized prediction error. We evaluate our 
approach on the Argoverse, Lyft, Apolloscape, and NGSIM datasets and 
highlight the beneﬁts over prior trajectory prediction methods. In 
practice, our approach reduces the average prediction error by 
approximately 75% over prior algorithms and achieves a weighted average 
accuracy of 91.2% for behavior prediction. Additionally, our spectral 
regularization improves long-term prediction by up to 70%.</td>
					</tr>
					<tr>
					<th>Language</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>Zotero</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>8</td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_EP9U5LZ2">Chandra et al. - Forecasting Trajectory and Behavior of Road-Agents.pdf					</li>
				</ul>
			</li>


			<li id="item_R5LJL8SR" class="item journalArticle">
			<h2>Robust Pedestrian Tracking in Crowd Scenarios Using an Adaptive GMM-Based Framework</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Journal Article</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Shuyang Zhang</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Di Wang</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Fulong Ma</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Chao Qin</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Zhengyong Chen</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Ming Liu</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>In this paper, we address the issue of pedestrian tracking in 
crowd scenarios. People in close social relationships tend to act as a 
group which is a great challenge to individually discriminate and track 
pedestrians on a LiDAR system. In this paper, we integrally model groups
 of people and track them in a recursive framework based on Gaussian 
Mixture Model (GMM). The model is optimized by an extended 
ExpectationMaximization (EM) algorithm which can adaptively vary the 
number of mixture components over scans. Experimental results both 
qualitatively and quantitatively indicate the reliability and accuracy 
of our tracker in populated scenarios.</td>
					</tr>
					<tr>
					<th>Language</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>Zotero</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>7</td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_VSBBW874">Zhang et al. - Robust Pedestrian Tracking in Crowd Scenarios Usin.pdf					</li>
				</ul>
			</li>


			<li id="item_V2QYB766" class="item journalArticle">
			<h2>Social and Scene-Aware Trajectory Prediction in Crowded Spaces</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Journal Article</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Matteo Lisotto</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Pasquale Coscia</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Lamberto Ballan</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>Mimicking human ability to forecast future positions or 
interpret complex interactions in urban scenarios, such as streets, 
shopping malls or squares, is essential to develop socially compliant 
robots or self-driving cars. Autonomous systems may gain advantage on 
anticipating human motion to avoid collisions or to naturally behave 
alongside people. To foresee plausible trajectories, we construct an 
LSTM (long short-term memory)-based model considering three fundamental 
factors: people interactions, past observations in terms of previously 
crossed areas and semantics of surrounding space. Our model encompasses 
several pooling mechanisms to join the above elements deﬁning multiple 
tensors, namely social, navigation and semantic tensors. The network is 
tested in unstructured environments where complex paths emerge according
 to both internal (intentions) and external (other people, not 
accessible areas) motivations. As demonstrated, modeling paths unaware 
of social interactions or context information, is insufﬁcient to 
correctly predict future positions. Experimental results corroborate the
 effectiveness of the proposed framework in comparison to LSTM-based 
models for human path prediction.</td>
					</tr>
					<tr>
					<th>Language</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>Zotero</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>8</td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_YTH9NDY6">Lisotto et al. - Social and Scene-Aware Trajectory Prediction in Cr.pdf					</li>
				</ul>
			</li>


			<li id="item_5R8DSSJ7" class="item webpage">
			<h2>Recent trends in social aware robot navigation: A survey - ScienceDirect</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Web Page</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://www.sciencedirect.com/science/article/pii/S0921889016302287">https://www.sciencedirect.com/science/article/pii/S0921889016302287</a></td>
					</tr>
					<tr>
					<th>Accessed</th>
						<td>4/4/2019, 10:45:24 AM</td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_FA9D9V8A">Recent trends in social aware robot navigation A .pdf					</li>
					<li id="item_ARMSGLXC">Recent trends in social aware robot navigation: A survey - ScienceDirect					</li>
				</ul>
			</li>


			<li id="item_Z7BHZL87" class="item journalArticle">
			<h2>Comfort-oriented social force model and learned lessons</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Journal Article</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Vidal Carretero</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>In this paper, we propose a new Social Force Model (SFM), 
called COSFM (Comfort-Oriented Social Force Model), that maximizes the 
comfort of people when robots navigate around them. We describe a 
navigation system that allows robots to reach their target in small 
human environments like a ﬂat or small corridors in a safe and 
comfortable manner. More precisely, the proposed approach is tested with
 a 3D version of the Social Force Model (SFM) for aerial robots with 
some restrictions in order to maximize the comfort of nearby humans. To 
accomplish this commitment, we include a navigation scheme that predicts
 the humans motion and intention so the robot can safely avoid people. 
Moreover, to avoid surprises, robots will never go faster than human 
motion velocity. This contrasts with other conventional works where the 
environment is neither so tight or close with people and walls. This 
work is based on previous works of SFM [1] applied to robots that come 
from an older framework for understanding human movements in crowds [2].
 However, we must advise that even if the ﬁrst results are quite good 
there is still much work to do to obtain a fully comfortable model. The 
current model shows great potential to solve difﬁcult decisions, even 
scale on many elements in close environments.Finally, the results are 
good enough to think it is an appropriate model for indoor human close 
environments with applications such as delivering goods or reaching 
people for help in buildings.</td>
					</tr>
					<tr>
					<th>Language</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>Zotero</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>8</td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_CJTGG7DG">Carretero - Comfort-oriented social force model and learned le.pdf					</li>
				</ul>
			</li>


			<li id="item_BUAWSERM" class="item conferencePaper">
			<h2>Mixed Reality for robotics</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Conference Paper</td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_ZX9ZTEEE">2015_IROS_Hoenig.pdf					</li>
				</ul>
			</li>


			<li id="item_83HMHRWN" class="item journalArticle">
			<h2>Early Prototyping and Human Evaluation of Social Robot Navigation via Online Interactive Simulations</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Journal Article</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Nathan Tsoi</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Marynel Vazquez</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>We recently created the open-source SEAN experimental platform
 (SEAN-EP). Leveraging the Social Environment for Autonomous Navigation 
(SEAN) simulator, we enable roboticists to collect human feedback for 
social robot navigation at scale. Our platform leverages modern web 
technologies to allow researchers to efﬁciently collect human feedback 
for social robot navigation tasks through interactive web forms. Remote 
users are able to control the motion of a human avatar via their web 
browser and interact with a virtual robot. Computation is delegated to 
cloud servers so users do not need specialized hardware to interact with
 the simulation environment. We provide an evaluation toolkit to allow 
fair comparison between robot navigation methods using common metrics. 
Usability was evaluated through an interactive online survey. Though 
there are many opportunities and challenges for this type of system, 
this is a promising step forward for evaluation of social navigation 
algorithms. We hope the community will beneﬁt from our open source 
platform.</td>
					</tr>
					<tr>
					<th>Language</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>Zotero</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>6</td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_TXRQVTUV">Tsoi and Vazquez - Early Prototyping and Human Evaluation of Social R.pdf					</li>
				</ul>
			</li>


			<li id="item_4V7JUIPP" class="item journalArticle">
			<h2>IAN: Multi-Behavior Navigation Planning for Robots in Real, Crowded Environments</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Journal Article</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Daniel Dugas</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Juan Nieto</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Roland Siegwart</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Jen Jen Chung</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>State-of-the-art approaches for robot navigation among humans 
are typically restricted to planar movement actions. This work addresses
 the question of whether it can be beneﬁcial to use interaction actions,
 such as saying, touching, and gesturing, for the sake of allowing 
robots to navigate in unstructured, crowded environments. To do so, we 
ﬁrst identify challenging scenarios to traditional motion planning 
methods. Based on the hypothesis that the variation in modality for 
these scenarios calls for signiﬁcantly different planning policies, we 
design speciﬁc navigation behaviors as interaction planners for 
actuated, mobile robots. We further propose a high level planning 
algorithm for multi-behavior navigation, named Interaction Actions for 
Navigation (IAN). Through both real-world and simulated experiments, we 
validate the selected behaviors and the high-level planning algorithm, 
and discuss the impact of our obtained results on our stated 
assumptions.</td>
					</tr>
					<tr>
					<th>Language</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>Zotero</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>8</td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_M93SJRCY">Dugas et al. - IAN Multi-Behavior Navigation Planning for Robots.pdf					</li>
				</ul>
			</li>


			<li id="item_ID7CM5DX" class="item journalArticle">
			<h2>L2B: Learning to Balance the Safety-Efficiency Trade-Off in Interactive Crowd-Aware Robot Navigation</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Journal Article</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Mai Nishimura</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Ryo Yonetani</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>This work presents a deep reinforcement learning framework for
 interactive navigation in a crowded place. Our proposed Learning to 
Balance (L2B) framework enables mobile robot agents to steer safely 
towards their destinations by avoiding collisions with a crowd, while 
actively clearing a path by asking nearby pedestrians to make room, if 
necessary, to keep their travel efﬁcient. We observe that the safety and
 efﬁciency requirements in crowd-aware navigation have a tradeoff in the
 presence of social dilemmas between the agent and the crowd. On the one
 hand, intervening in pedestrian paths too much to achieve instant 
efﬁciency will result in collapsing a natural crowd ﬂow and may 
eventually put everyone, including the self, at risk of collisions. On 
the other hand, keeping in silence to avoid every single collision will 
lead to the agent’s inefﬁcient travel. With this observation, our L2B 
framework augments the reward function used in learning an interactive 
navigation policy to penalize frequent active path clearing and passive 
collision avoidance, which substantially improves the balance of the 
safety-efﬁciency trade-off. We evaluate our L2B framework in a 
challenging crowd simulation and demonstrate its superiority, in terms 
of both navigation success and collision rate, over a state-of-the-art 
navigation approach.</td>
					</tr>
					<tr>
					<th>Language</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>Zotero</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>7</td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_Y8E58XGZ">Nishimura and Yonetani - L2B Learning to Balance the Safety-Efficiency Tra.pdf					</li>
				</ul>
			</li>


			<li id="item_8DZCNMYQ" class="item journalArticle">
			<h2>Relational Graph Learning for Crowd Navigation</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Journal Article</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Changan Chen</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Sha Hu</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Payam Nikdel</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Greg Mori</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Manolis Savva</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>We present a relational graph learning approach for robotic 
crowd navigation using model-based deep reinforcement learning that 
plans actions by looking into the future. Our approach reasons about the
 relations between all agents based on their latent features and uses a 
Graph Convolutional Network to encode higher-order interactions in each 
agent’s state representation, which is subsequently leveraged for state 
prediction and value estimation. The ability to predict human motion 
allows us to perform multi-step lookahead planning, taking into account 
the temporal evolution of human crowds. We evaluate our approach against
 a state-of-the-art baseline for crowd navigation and ablations of our 
model to demonstrate that navigation with our approach is more efﬁcient,
 results in fewer collisions, and avoids failure cases involving 
oscillatory and freezing behaviors.</td>
					</tr>
					<tr>
					<th>Language</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>Zotero</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>7</td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_LHEE7TRT">Chen et al. - Relational Graph Learning for Crowd Navigation.pdf					</li>
				</ul>
			</li>


			<li id="item_XCPDS5C2" class="item journalArticle">
			<h2>A POMDP Treatment of Vehicle-Pedestrian Interaction: Implicit Coordination Via Uncertainty-Aware Planning</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Journal Article</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Ya-Chuan Hsu</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Swaminathan Gopalswamy</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Srikanth Saripalli</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Dylan Shell</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>Drivers and other road users often encounter situations (e.g.,
 arriving at an intersection simultaneously) where priority is ambiguous
 or unclear but must be resolved via communication to reach agreement. 
This poses a challenge for autonomous vehicles, for which no direct 
means for expressing intent and acknowledgment has yet been established.
 This paper contributes a minimal model to manage ambiguity and produce 
actions that are expressive and encode aspects of intent. Speciﬁcally, 
intent is treated as a latent variable, communicated implicitly through a
 partially observable Markov decision process (POMDP). We validate the 
model in a simple setting: a simulation of a prototypical crossing with a
 vehicle and one pedestrian at an unsignalized intersection. We further 
report use of our self-driving Ford Lincoln MKZ platform, through which 
we conducted experimental trials of the method involving real-time 
interaction. The experiment shows the method achieves safe and efﬁcient 
navigation.</td>
					</tr>
					<tr>
					<th>Language</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>Zotero</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>8</td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_CJFEP9MM">Hsu et al. - A POMDP Treatment of Vehicle-Pedestrian Interactio.pdf					</li>
				</ul>
			</li>


			<li id="item_XX3X5JPR" class="item journalArticle">
			<h2>Robot Navigation in Crowded Environments Using Deep Reinforcement Learning</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Journal Article</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Lucia Liu</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Daniel Dugas</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Gianluca Cesari</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Roland Siegwart</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Renaud DubÃ</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>Mobile robots operating in public environments require the 
ability to navigate among humans and other obstacles in a socially 
compliant and safe manner. This work presents a combined imitation 
learning and deep reinforcement learning approach for motion planning in
 such crowded and cluttered environments. By separately processing 
information related to static and dynamic objects, we enable our network
 to learn motion patterns that are tailored to real-world environments. 
Our model is also designed such that it can handle usual cases in which 
robots can be equipped with sensor suites that only offer limited ﬁeld 
of view. Our model outperforms current state-ofthe-art approaches, which
 is shown in simulated environments containing human-like agents and 
static obstacles. Additionally, we demonstrate the real-time performance
 and applicability of our model by successfully navigating a robotic 
platform through real-world environments.</td>
					</tr>
					<tr>
					<th>Language</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>Zotero</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>7</td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_2B43XQ3R">Liu et al. - Robot Navigation in Crowded Environments Using Dee.pdf					</li>
				</ul>
			</li>


			<li id="item_BCAE2UNA" class="item journalArticle">
			<h2>Modelling Social Interaction between Humans and Service Robots in Large Public Spaces</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Journal Article</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Bani Anvari</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Helge Arne Wurdemann</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>With the advent of service robots in public places (e.g., in 
airports and shopping malls), understanding sociopsychological 
interactions between humans and robots is of paramount importance. On 
the one hand, traditional robotic navigation systems consider humans and
 robots as moving obstacles and focus on the problem of real-time 
collision avoidance in Human-Robot Interaction (HRI) using mathematical 
models. On the other hand, the behavior of a robot has been determined 
with respect to a human. Parameters for human-human interaction have 
been assumed and applied to interactions involving robots. One major 
limitation is the lack of sufﬁcient data for calibration and validation 
procedures.</td>
					</tr>
					<tr>
					<th>Language</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>Zotero</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>8</td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_RGV6RWRS">Anvari and Wurdemann - Modelling Social Interaction between Humans and Se.pdf					</li>
				</ul>
			</li>


			<li id="item_8ID59A9B" class="item journalArticle">
			<h2>Social Path Planning: Generic Human-Robot Interaction Framework for Robotic Navigation Tasks</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Journal Article</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Javier V Gomez</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Nikolaos Mavridis</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Santiago Garrido</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>This paper formulates a generic framework for the social path 
planning problem. Previous works deal with very speciﬁc cases of 
socially-aware motion planning. Instead, here we propose a mathematical 
formulation that can be considered the preliminary steps towards a 
general theoretical setting, incorporating previous work as sub-cases. 
Social path planning is analyzed into 6 different subproblems. 
Furthermore, a review of the state of the art about the different 
aspects of the social path planning problem is included. Most 
importantly, an extended model for the O-space for groups of people 
engaged in a social interaction is proposed. Preliminary results for 
actual social path planning solutions under the proposed formulation are
 shown, proving the powerfulness of the approach and its generalization.
 Finally, a concrete discussion about future work is provided.</td>
					</tr>
					<tr>
					<th>Language</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>Zotero</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>7</td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_KFV6G5X7">Gomez et al. - Social Path Planning Generic Human-Robot Interact.pdf					</li>
				</ul>
			</li>


			<li id="item_M8LN8IEB" class="item journalArticle">
			<h2>Optimization-Based Path Planning for Person Following Using Following Field</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Journal Article</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Heechan Shin</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Sung-eui Yoon</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>Person following is an essential task for a robot to serve a 
person. In an indoor environment, however, the following task can be 
failed due to the occlusion of the target by structures, e.g., walls or 
pillars. To address this problem, we propose a method that helps the 
robot follow the target well and rapidly re-detect the target after 
missing. The proposed method is an optimization-based path planning 
which uses a Following Field that we propose in this paper. The 
following ﬁeld consists of two sub-ﬁelds: the repulsion ﬁeld getting the
 robot out of the occluded area, and the target attraction ﬁeld pushing 
the robot toward the target. We introduce how to construct the ﬁelds and
 how to integrate the ﬁeld into a path optimization process. We show 
that our method works properly for following the target well in a maze 
consisting of various in-door features.</td>
					</tr>
					<tr>
					<th>Language</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>Zotero</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>8</td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_GYLJ3TRV">Shin and Yoon - Optimization-Based Path Planning for Person Follow.pdf					</li>
				</ul>
			</li>


			<li id="item_PMMLENCY" class="item journalArticle">
			<h2>Learning Human-Aware Robot Navigation from Physical Interaction Via Inverse Reinforcement Learning</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Journal Article</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Marina Kollmitz</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Torsten Koller</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Joschka Boedecker</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Wolfram Burgard</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>Autonomous systems, such as delivery robots, are increasingly 
employed in indoor spaces to carry out activities alongside humans. This
 development poses the question of how robots can carry out their tasks 
while, at the same time, behaving in a socially compliant manner. 
Further, humans need to be able to communicate their preferences in a 
simple and intuitive way, and robots should adapt their behavior 
accordingly. This paper investigates force control as a natural means to
 interact with a mobile robot by pushing it along the desired 
trajectory. We employ inverse reinforcement learning (IRL) to learn from
 human interaction and adapt the robot behavior to its users’ 
preferences, thereby eliminating the need to program the desired 
behavior manually. We evaluate our approach in a real-world experiment 
where test subjects interact with an autonomously navigating robot in 
close proximity. The results suggest that force control presents an 
intuitive means to interact with a mobile robot and show that our robot 
can quickly adapt to the test subjects’ personal preferences.</td>
					</tr>
					<tr>
					<th>Language</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>Zotero</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>7</td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_Q8PA6GZF">Kollmitz et al. - Learning Human-Aware Robot Navigation from Physica.pdf					</li>
				</ul>
			</li>


			<li id="item_FSTFVS9Z" class="item journalArticle">
			<h2>Frozone: Freezing-Free, Pedestrian-Friendly Navigation in Human Crowds</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Journal Article</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Adarsh Jagan Sathyamoorthy</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Utsav Patel</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Tianrui Guan</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Dinesh Manocha</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>We present Frozone, a novel algorithm to deal with the 
Freezing Robot Problem (FRP) that arises when a robot navigates through 
dense scenarios and crowds. Our method senses and explicitly predicts 
the trajectories of pedestrians and constructs a Potential Freezing Zone
 (PFZ); a spatial zone where the robot could freeze or be obtrusive to 
humans. Our formulation computes a deviation velocity to avoid the PFZ, 
which also accounts for social constraints. Furthermore, Frozone is 
designed for robots equipped with sensors with a limited sensing range 
and ﬁeld of view. We ensure that the robot’s deviation is bounded, thus 
avoiding sudden angular motion which could lead to the loss of 
perception data of the surrounding obstacles. We have combined Frozone 
with a Deep Reinforcement Learning-based (DRL) collision avoidance 
method and use our hybrid approach to handle crowds of varying 
densities. Our overall approach results in smooth and collision-free 
navigation in dense environments. We have evaluated our method’s 
performance in simulation and on real differential drive robots in 
challenging indoor scenarios. We highlight the beneﬁts of our approach 
over prior methods in terms of success rates (upto 50 % increase), 
pedestrianfriendliness (100 % increase) and the rate of freezing ( &gt; 
80% decrease) in challenging scenarios.</td>
					</tr>
					<tr>
					<th>Language</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>Zotero</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>8</td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_SKXJUV9I">Sathyamoorthy et al. - Frozone Freezing-Free, Pedestrian-Friendly Naviga.pdf					</li>
				</ul>
			</li>


			<li id="item_82SLM4B3" class="item journalArticle">
			<h2>Human Perception-Optimized Planning for Comfortable VR Based Telepresence</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Journal Article</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Israel Becerra</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Markku Suomalainen</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Eliezer Lozano</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Katherine J Mimnaugh</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Rafael Murrieta-Cid</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Steven M LaValle</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>This paper introduces an emerging motion planning problem by 
considering a human that is immersed into the viewing perspective of a 
remote robot. The challenge is to make the experience both effective 
(such as delivering a sense of presence) and comfortable (such as 
avoiding adverse sickness symptoms, including nausea). We refer this 
challenging new area as human perception-optimized planning and propose a
 general multiobjective optimization framework that can be instantiated 
in many envisioned scenarios. We then consider a speciﬁc VR telepresence
 task as a case of human perceptionoptimized planning, in which we 
simulate a robot that sends 360 video to a remote user to be viewed 
through a headmounted display. In this particular task, we plan 
trajectories that minimize VR sickness (and thereby maximize comfort). 
An A* type method is used to create a Pareto-optimal collection of 
piecewise linear trajectories while taking into account criteria that 
improve comfort. We conducted a study with human subjects touring a 
virtual museum, in which paths computed by our algorithm are compared 
against a reference RRT-based trajectory. Generally, users suffered less
 from VR sickness and preferred the paths created by the presented 
algorithm.</td>
					</tr>
					<tr>
					<th>Language</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>Zotero</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>8</td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_TIGGJTXW">Becerra et al. - Human Perception-Optimized Planning for Comfortabl.pdf					</li>
				</ul>
			</li>


			<li id="item_7J9GXJK3" class="item journalArticle">
			<h2>Viewing Robot Navigation in Human Environment as a Cooperative Activity</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Journal Article</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Harmish Khambhaita</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Rachid Alami</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>We claim that navigation in human environments can be viewed 
as cooperative activity especially in constrained situations. Humans 
concurrently aid and comply with each other while moving in a shared 
space. Cooperation helps pedestrians to efﬁciently reach their own goals
 and respect conventions such as the personal space of others. To meet 
human comparable efﬁciency, a robot needs to predict the human 
trajectories and plan its own trajectory correspondingly in the same 
shared space. In this work, we present a navigation planner that is able
 to plan such cooperative trajectories, simultaneously enforcing the 
robot’s kinematic constraints and avoiding other non-human dynamic 
obstacles. Using robust social constraints of projected time to a 
possible future collision, compatibility of human-robot motion 
direction, and proxemics, our planner is able to replicate human-like 
navigation behavior not only in open spaces but also in conﬁned areas. 
Besides adapting the robot trajectory, the planner is also able to 
proactively propose co-navigation solutions by jointly computing human 
and robot trajectories within the same optimization framework. We 
demonstrate richness and performance of the cooperative planner with 
simulated and real world experiments on multiple interactive navigation 
scenarios.</td>
					</tr>
					<tr>
					<th>Language</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>Zotero</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>18</td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_54GALY8S">Khambhaita and Alami - Viewing Robot Navigation in Human Environment as a.pdf					</li>
				</ul>
			</li>


			<li id="item_N99MHBCE" class="item journalArticle">
			<h2>A new Strategy based on an Adaptive Spatial Density Function for Social Robot Navigation in Human-Populated Environments</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Journal Article</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Araceli Vega</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Luis M Fernandez-Arguellez</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Douglas G Macharet</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Pedro Nunez</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>With robots shifting towards human-populated environment, 
robot navigation is challenging because there are a lot of factors to 
take into account, such as social rules or the human intentions. While 
traditional robot navigation algorithms treat all sensor readings, 
including humans, as objects to be avoided, now it is important to 
provide robots with the capability to behave in a socially acceptable 
manner.</td>
					</tr>
					<tr>
					<th>Language</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>Zotero</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>14</td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="notes">Notes:</h3>
				<ul class="notes">
					<li id="item_WRSXB88E">
<div><p>Same as the one with adaptive and flexible social density</p></div>
					</li>
				</ul>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_ISM6W2FX">Vega et al. - A new Strategy based on an Adaptive Spatial Densit.pdf					</li>
				</ul>
			</li>


			<li id="item_DH2CYUDJ" class="item conferencePaper">
			<h2>Human-Aware Navigation Planner for Diverse Human-Robot Contexts</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Conference Paper</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Phani-Teja Singamaneni</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Anthony Favier</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Rachid Alami</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>As more robots are being deployed into human environments, a 
human-aware navigation planner needs to handle multiple contexts that 
occur in indoor and outdoor environments. In this paper, we propose a 
tunable human-aware robot navigation planner that can handle a variety 
of human-robot contexts. We present the architecture of the system and 
discuss the features along with some implementation details. Then we 
present a detailed analysis of various simulated human-robot contexts 
using the proposed planner. Further, we show that our system performs 
better when compared with an exiting human-aware planner in various 
contexts. Finally, we show the results in a real-world scenario after 
deploying our system on a real robot.</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2021-09</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>HAL Archives Ouvertes</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://hal.archives-ouvertes.fr/hal-03262888">https://hal.archives-ouvertes.fr/hal-03262888</a></td>
					</tr>
					<tr>
					<th>Accessed</th>
						<td>11/30/2021, 3:40:30 PM</td>
					</tr>
					<tr>
					<th>Place</th>
						<td>Prague (online), Czech Republic</td>
					</tr>
					<tr>
					<th>Proceedings Title</th>
						<td>2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_AIJWW5DM">HAL PDF Full Text					</li>
				</ul>
			</li>


			<li id="item_ZR3AQ2DB" class="item conferencePaper">
			<h2>Aerial Flight Paths for Communication: How Participants Perceive and Intend to Respond to Drone Movements</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Conference Paper</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Alisha Bevins</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Brittany A. Duncan</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>This work has developed an iteratively refined understanding 
of participants' natural perceptions and responses to unmanned aerial 
vehicle (UAV) flight paths, or gestures. This includes both what they 
believe the UAV is trying to communicate to them, in addition to how 
they expect to respond through physical action. Previous work in this 
area has focused on eliciting gestures from participants to communicate 
specific states, or leveraging gestures that are observed in the world 
rather than on understanding what the participants believe is being 
communicated and how they would respond. This work investigates previous
 gestures either created or categorized by participants to understand 
the perceived content of their communication or expected response, 
through categories created by participant free responses and confirmed 
through forced choice testing. The human-robot interaction community can
 leverage this work to better understand how people perceive UAV flight 
paths, inform future designs for non-anthropomorphic robot 
communications, and apply lessons learned to elicit informative labels 
from people who may or may not be operating the vehicle. We found that 
the Negative Attitudes towards Robots Scale (NARS) can be a good 
indicator of how we can expect a person to react to a robot. 
Recommendations are also provided to use motion approaching/retreating 
from a person to encourage following, perpendicular to their field of 
view for blocking, and to use either no motion or large altitude changes
 to encourage viewing.</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>March 8, 2021</td>
					</tr>
					<tr>
					<th>Short Title</th>
						<td>Aerial Flight Paths for Communication</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>ACM Digital Library</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://doi.org/10.1145/3434073.3444645">https://doi.org/10.1145/3434073.3444645</a></td>
					</tr>
					<tr>
					<th>Accessed</th>
						<td>11/30/2021, 1:00:00 AM</td>
					</tr>
					<tr>
					<th>Place</th>
						<td>New York, NY, USA</td>
					</tr>
					<tr>
					<th>Publisher</th>
						<td>Association for Computing Machinery</td>
					</tr>
					<tr>
					<th>ISBN</th>
						<td>978-1-4503-8289-2</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>16–23</td>
					</tr>
					<tr>
					<th>Series</th>
						<td>HRI '21</td>
					</tr>
					<tr>
					<th>Proceedings Title</th>
						<td>Proceedings of the 2021 ACM/IEEE International Conference on Human-Robot Interaction</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.1145/3434073.3444645">10.1145/3434073.3444645</a></td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Tags:</h3>
				<ul class="tags">
					<li>drones</li>
					<li>gestures</li>
					<li>motion</li>
					<li>uav</li>
				</ul>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_TZWCRB7Q">Full Text PDF					</li>
				</ul>
			</li>


			<li id="item_YA4ABNIY" class="item journalArticle">
			<h2>Probabilistic Crowd GAN: Multimodal Pedestrian Trajectory Prediction Using a Graph Vehicle-Pedestrian Attention Network</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Journal Article</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Stuart Eiffert</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Kunming Li</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Mao Shan</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Stewart Worrall</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Salah Sukkarieh</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Eduardo Nebot</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>Understanding and predicting the intention of pedestrians is 
essential to enable autonomous vehicles and mobile robots to navigate 
crowds. This problem becomes increasingly complex when we consider the 
uncertainty and multimodality of pedestrian motion, as well as the 
implicit interactions between members of a crowd, including any response
 to a vehicle. Our approach, Probabilistic Crowd GAN, extends recent 
work in trajectory prediction, combining Recurrent Neural Networks 
(RNNs) with Mixture Density Networks (MDNs) to output probabilistic 
multimodal predictions, from which likely modal paths are found and used
 for adversarial training. We also propose the use of Graph 
Vehicle-Pedestrian Attention Network (GVAT), which models social 
interactions and allows input of a shared vehicle feature, showing that 
inclusion of this module leads to improved trajectory prediction both 
with and without the presence of a vehicle. Through evaluation on 
various datasets, we demonstrate improvements on the existing state of 
the art methods for trajectory prediction and illustrate how the true 
multimodal and uncertain nature of crowd interactions can be directly 
modelled.</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>10/2020</td>
					</tr>
					<tr>
					<th>Language</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Short Title</th>
						<td>Probabilistic Crowd GAN</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>DOI.org (Crossref)</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://ieeexplore.ieee.org/document/9123560/">https://ieeexplore.ieee.org/document/9123560/</a></td>
					</tr>
					<tr>
					<th>Accessed</th>
						<td>1/14/2021, 11:53:00 AM</td>
					</tr>
					<tr>
					<th>Volume</th>
						<td>5</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>5026-5033</td>
					</tr>
					<tr>
					<th>Publication</th>
						<td>IEEE Robotics and Automation Letters</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.1109/LRA.2020.3004324">10.1109/LRA.2020.3004324</a></td>
					</tr>
					<tr>
					<th>Issue</th>
						<td>4</td>
					</tr>
					<tr>
					<th>Journal Abbr</th>
						<td>IEEE Robot. Autom. Lett.</td>
					</tr>
					<tr>
					<th>ISSN</th>
						<td>2377-3766, 2377-3774</td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_EEVK97F8">Eiffert et al. - 2020 - Probabilistic Crowd GAN Multimodal Pedestrian Tra.pdf					</li>
				</ul>
			</li>


			<li id="item_GERL2WV6" class="item conferencePaper">
			<h2>HATEB-2: Reactive Planning and Decision making in Human-Robot Co-navigation</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Conference Paper</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Phani Teja S.</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Rachid Alami</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>We propose a new framework combining decision making and 
planning in the human-robot co-navigation scenario. This new framework, 
called HATEB-2, introduces different modalities of planning and shift 
between them based on the situation at hand. These transitions are 
controlled by the decision making loop present on top of the planning. 
We also present the improvements made to human prediction and estimation
 along with the modiﬁcations to a few social constraints from our 
previous work, that are included in HATEB2. Finally, several experiments
 are performed in human-robot co-navigation scenarios and results are 
presented. One of the modalities of HATEB-2 is used in EU-funded MuMMER 
[1] project (http://mummer-project.eu/).</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>8/2020</td>
					</tr>
					<tr>
					<th>Language</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Short Title</th>
						<td>HATEB-2</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>DOI.org (Crossref)</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://ieeexplore.ieee.org/document/9223463/">https://ieeexplore.ieee.org/document/9223463/</a></td>
					</tr>
					<tr>
					<th>Accessed</th>
						<td>11/30/2021, 3:38:07 PM</td>
					</tr>
					<tr>
					<th>Place</th>
						<td>Naples, Italy</td>
					</tr>
					<tr>
					<th>Publisher</th>
						<td>IEEE</td>
					</tr>
					<tr>
					<th>ISBN</th>
						<td>978-1-72816-075-7</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>179-186</td>
					</tr>
					<tr>
					<th>Proceedings Title</th>
						<td>2020 29th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN)</td>
					</tr>
					<tr>
					<th>Conference Name</th>
						<td>2020 29th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN)</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.1109/RO-MAN47096.2020.9223463">10.1109/RO-MAN47096.2020.9223463</a></td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_AI6HMTRH">Teja S. and Alami - 2020 - HATEB-2 Reactive Planning and Decision making in .pdf					</li>
				</ul>
			</li>


			<li id="item_JGPRN8K5" class="item conferencePaper">
			<h2>Teaching a Drone to Accompany a Person from Demonstrations using Non-Linear ASFM</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Conference Paper</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Anais Garrell</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Carles Coll</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Rene Alquezar</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Alberto Sanfeliu</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>In this paper, we present a new method based on the Aerial 
Social Force Model (ASFM) to allow human-drone side-by-side social 
navigation in real environments. To tackle this problem, the present 
work proposes a new nonlinear-based approach using Neural Networks. To 
learn and test the rightness of the new approach, we built a new dataset
 with simulated environments and we recorded motion controls provided by
 a human expert tele-operating the drone. The recorded data is then used
 to train a neural network which maps interaction forces to acceleration
 commands. The system is also reinforced with a human path prediction 
module to improve the drone’s navigation, as well as, a collision 
detection module to completely avoid possible impacts. Moreover, a 
performance metric is deﬁned which allows us to numerically evaluate and
 compare the fulﬁllment of the different learned policies. The method 
was validated by a large set of simulations; we also conducted real-life
 experiments with an autonomous drone to verify the framework described 
for the navigation process. In addition, a user study has been realized 
to reveal the social acceptability of the method.</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>11/2019</td>
					</tr>
					<tr>
					<th>Language</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>DOI.org (Crossref)</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://ieeexplore.ieee.org/document/8967675/">https://ieeexplore.ieee.org/document/8967675/</a></td>
					</tr>
					<tr>
					<th>Accessed</th>
						<td>11/30/2021, 3:41:19 PM</td>
					</tr>
					<tr>
					<th>Place</th>
						<td>Macau, China</td>
					</tr>
					<tr>
					<th>Publisher</th>
						<td>IEEE</td>
					</tr>
					<tr>
					<th>ISBN</th>
						<td>978-1-72814-004-9</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>1985-1991</td>
					</tr>
					<tr>
					<th>Proceedings Title</th>
						<td>2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</td>
					</tr>
					<tr>
					<th>Conference Name</th>
						<td>2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.1109/IROS40897.2019.8967675">10.1109/IROS40897.2019.8967675</a></td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_G3949YTC">Garrell et al. - 2019 - Teaching a Drone to Accompany a Person from Demons.pdf					</li>
				</ul>
			</li>


			<li id="item_2VJ6QW8H" class="item journalArticle">
			<h2>Towards S-NAMO: Socially-aware Navigation Among Movable Obstacles</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Journal Article</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Benoit Renault</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Jacques Saraydaryan</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Olivier Simonin</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>In this paper, we present an in-depth analysis of Navigation 
Among Movable Obstacles (NAMO) literature, notably highlighting that 
social acceptability remains an unadressed problem in this robotics 
navigation domain. The objectives of a Socially-Aware NAMO are defined 
and a first set of algorithmic propositions is built upon existing work.
 We developed a simulator allowing to test our propositions of social 
movability evaluation for obstacle selection, and social placement of 
objects with a semantic map layer. Preliminary pushing tests are done 
with a Pepper robot, the standard platform for the Robocup@home Social 
Standard Platform League, in the context of our participation (LyonTech 
Team).</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2019-09-24</td>
					</tr>
					<tr>
					<th>Short Title</th>
						<td>Towards S-NAMO</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>arXiv.org</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="http://arxiv.org/abs/1909.10809">http://arxiv.org/abs/1909.10809</a></td>
					</tr>
					<tr>
					<th>Accessed</th>
						<td>11/4/2019, 1:00:57 PM</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>arXiv: 1909.10809</td>
					</tr>
					<tr>
					<th>Publication</th>
						<td>arXiv:1909.10809 [cs]</td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Tags:</h3>
				<ul class="tags">
					<li>Computer Science - Robotics</li>
				</ul>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_JPU8XLN6">arXiv.org Snapshot					</li>
					<li id="item_6I63D89H">arXiv Fulltext PDF					</li>
				</ul>
			</li>


			<li id="item_79HAW5W3" class="item journalArticle">
			<h2>Graph Neural Networks for Human-aware Social Navigation</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Journal Article</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Luis J. Manso</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Ronit R. Jorvekar</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Diego R. Faria</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Pablo Bustos</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Pilar Bachiller</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>Autonomous navigation is a key skill for assistive and service
 robots. To be successful, robots have to navigate avoiding going 
through the personal spaces of the people surrounding them. Complying 
with social rules such as not getting in the middle of human-to-human 
and human-to-object interactions is also important. This paper suggests 
using Graph Neural Networks to model how inconvenient the presence of a 
robot would be in a particular scenario according to learned human 
conventions so that it can be used by path planning algorithms. To do 
so, we propose two ways of modelling social interactions using graphs 
and benchmark them with different Graph Neural Networks using the 
SocNav1 dataset. We achieve close-to-human performance in the dataset 
and argue that, in addition to promising results, the main advantage of 
the approach is its scalability in terms of the number of social factors
 that can be considered and easily embedded in code, in comparison with 
model-based approaches. The code used to train and test the resulting 
graph neural network is available in a public repository.</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2019-09-19</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>arXiv.org</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="http://arxiv.org/abs/1909.09003">http://arxiv.org/abs/1909.09003</a></td>
					</tr>
					<tr>
					<th>Accessed</th>
						<td>11/4/2019, 11:32:17 AM</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>arXiv: 1909.09003</td>
					</tr>
					<tr>
					<th>Publication</th>
						<td>arXiv:1909.09003 [cs]</td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Tags:</h3>
				<ul class="tags">
					<li>Computer Science - Machine Learning</li>
					<li>Computer Science - Robotics</li>
				</ul>
				<h3 class="notes">Notes:</h3>
				<ul class="notes">
					<li id="item_TFWWFZXU">
<p class="plaintext">Comment: Submitted to RA-L / ICRA2020</p>
					</li>
				</ul>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_U84HYRWF">arXiv.org Snapshot					</li>
					<li id="item_5VF5RBWP">arXiv Fulltext PDF					</li>
				</ul>
			</li>


			<li id="item_3F3ISIYA" class="item journalArticle">
			<h2>Socially Aware Path Planning for a Flying Robot in Close Proximity of Humans</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Journal Article</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Hyung-Jin Yoon</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Christopher Widdowson</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Thiago Marinho</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Ranxiao Frances Wang</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Naira Hovakimyan</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>In this article, we present a preliminary motion planning 
framework for a cyber-physical system consisting of a human and a flying
 robot in vicinity. The motion planning of the flying robot takes into 
account the human’s safety perception. We aim to determine a parametric 
model for the human’s safety perception based on test data. We use 
virtual reality as a safe testing environment to collect safety 
perception data reflected on galvanic skin response (GSR) from the test 
subjects experiencing a flying robot in their vicinity. The GSR signal 
contains both meaningful information driven by the interaction with the 
robot and also disturbances from unknown factors. To address the issue, 
we use two parametric models to approximate the GSR data: (1) a function
 of the robot’s position and velocity and (2) a random distribution. 
Intuitively, we need to choose the more likely model given the data. 
When GSR is statistically independent of the flying robot, then the 
random distribution should be selected instead of the function of the 
robot’s position and velocity. We implement the intuitive idea under the
 framework of hidden Markov model (HMM) estimation. As a result, the 
proposed HMM-based model improves the likelihood compared to the 
Gaussian noise model, which does not make a distinction between relevant
 and irrelevant samples due to unknown factors. We also present a 
numerical optimal path planning method that considers the safety 
perception model while ensuring spatial separation from the obstacle 
despite the time discretization. Optimal paths generated using the 
proposed model result in a reasonably safe distance from the human. In 
contrast, the trajectories generated by the standard regression model 
with the Gaussian noise assumption, without consideration of unknown 
factors, have undesirable shapes.</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>September 4, 2019</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>October 2019</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://doi.org/10.1145/3341570">https://doi.org/10.1145/3341570</a></td>
					</tr>
					<tr>
					<th>Accessed</th>
						<td>11/30/2021, 3:39:01 PM</td>
					</tr>
					<tr>
					<th>Volume</th>
						<td>3</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>41:1–41:24</td>
					</tr>
					<tr>
					<th>Publication</th>
						<td>ACM Transactions on Cyber-Physical Systems</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.1145/3341570">10.1145/3341570</a></td>
					</tr>
					<tr>
					<th>Issue</th>
						<td>4</td>
					</tr>
					<tr>
					<th>Journal Abbr</th>
						<td>ACM Trans. Cyber-Phys. Syst.</td>
					</tr>
					<tr>
					<th>ISSN</th>
						<td>2378-962X</td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Tags:</h3>
				<ul class="tags">
					<li>Human-robot interaction</li>
					<li>hidden Markov model</li>
					<li>optimal path planning</li>
				</ul>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_TGSTDA44">Full Text PDF					</li>
				</ul>
			</li>


			<li id="item_ISX6BD8L" class="item journalArticle">
			<h2>Scene-LSTM: A Model for Human Trajectory Prediction</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Journal Article</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Huynh Manh</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Gita Alaghband</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>We develop a human movement trajectory prediction system that 
incorporates the scene information (Scene-LSTM) as well as human 
movement trajectories (Pedestrian movement LSTM) in the prediction 
process within static crowded scenes. We superimpose a two-level grid 
structure (scene is divided into grid cells each modeled by a 
scene-LSTM, which are further divided into smaller sub-grids for finer 
spatial granularity) and explore common human trajectories occurring in 
the grid cell (e.g., making a right or left turn onto sidewalks coming 
out of an alley; or standing still at bus/train stops). Two coupled LSTM
 networks, Pedestrian movement LSTMs (one per target) and the 
corresponding Scene-LSTMs (one per grid-cell) are trained simultaneously
 to predict the next movements. We show that such common path 
information greatly influences prediction of future movement. We further
 design a scene data filter that holds important non-linear movement 
information. The scene data filter allows us to select the relevant 
parts of the information from the grid cell's memory relative to a 
target's state. We evaluate and compare two versions of our method with 
the Linear and several existing LSTM-based methods on five crowded video
 sequences from the UCY [1] and ETH [2] datasets. The results show that 
our method reduces the location displacement errors compared to related 
methods and specifically about 80% reduction compared to social 
interaction methods.</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2019-04-15</td>
					</tr>
					<tr>
					<th>Short Title</th>
						<td>Scene-LSTM</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>arXiv.org</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="http://arxiv.org/abs/1808.04018">http://arxiv.org/abs/1808.04018</a></td>
					</tr>
					<tr>
					<th>Accessed</th>
						<td>10/29/2019, 2:16:25 PM</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>arXiv: 1808.04018</td>
					</tr>
					<tr>
					<th>Publication</th>
						<td>arXiv:1808.04018 [cs]</td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Tags:</h3>
				<ul class="tags">
					<li>Computer Science - Computer Vision and Pattern Recognition</li>
				</ul>
				<h3 class="notes">Notes:</h3>
				<ul class="notes">
					<li id="item_VAF9C454">
<div><p>Comment: 9 pages, 5 figures</p></div>
					</li>
				</ul>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_C9P5T8UK">arXiv.org Snapshot					</li>
					<li id="item_3NIHIC4Q">arXiv Fulltext PDF					</li>
				</ul>
			</li>


			<li id="item_6B9VJ776" class="item conferencePaper">
			<h2>Human-robot dialogue and Collaboration for social navigation in crowded environments</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Conference Paper</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>C. Lobato</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>A. Vega-Magro</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>P. Núñez</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>L.J. Manso</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>Robot navigation in human-populated environments is a subject 
of great interest among the international scientific community. In order
 to be accepted in these scenarios, it is important for robots to 
navigate respecting social rules. Avoid getting too close to a person, 
not interrupting conversations or asking for permission or collaboration
 when it is required by social conventions, are some of the behaviours 
that robots must exhibit. This paper presents a social navigation system
 that integrates different software agents within a cognitive 
architecture for robots and describes, as the main contribution, the 
corpus that allows to establish dialogues between robots and humans in 
real situations to improve the human-aware navigation system. The corpus
 has been experimentally evaluated by the simulation of different daily 
situations, where robots need to plan interactions with real people. The
 results are analysed qualitatively, according to the behaviour expected
 by the robot in the interaction performed. The results show how the 
corpus presented in this paper improves the robot navigation, making it 
more socially accepted.</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>April 2019</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>IEEE Xplore</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>1-6</td>
					</tr>
					<tr>
					<th>Proceedings Title</th>
						<td>2019 IEEE International Conference on Autonomous Robot Systems and Competitions (ICARSC)</td>
					</tr>
					<tr>
					<th>Conference Name</th>
						<td>2019 IEEE International Conference on Autonomous Robot Systems and Competitions (ICARSC)</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.1109/ICARSC.2019.8733641">10.1109/ICARSC.2019.8733641</a></td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Tags:</h3>
				<ul class="tags">
					<li>mobile robots</li>
					<li>Navigation</li>
					<li>path planning</li>
					<li>control engineering computing</li>
					<li>Robot kinematics</li>
					<li>human-robot interaction</li>
					<li>Planning</li>
					<li>navigation</li>
					<li>crowded environments</li>
					<li>collaboration</li>
					<li>Collaboration</li>
					<li>Computer architecture</li>
					<li>groupware</li>
					<li>human-aware navigation system</li>
					<li>human-populated environments</li>
					<li>human-robot dialogue</li>
					<li>Human-robot interaction</li>
					<li>robot navigation</li>
					<li>social conventions</li>
					<li>social navigation system</li>
					<li>software agents</li>
				</ul>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_YFI6A6P7">Lobato et al. - 2019 - Human-robot dialogue and Collaboration for social .pdf					</li>
					<li id="item_9AWMREKY">IEEE Xplore Abstract Record					</li>
				</ul>
			</li>


			<li id="item_YUCEXAV4" class="item journalArticle">
			<h2>The Emotionally Intelligent Robot: Improving Social Navigation in Crowded Environments</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Journal Article</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Aniket Bera</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Tanmay Randhavane</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Rohan Prinja</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Kyra Kapsaskis</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Austin Wang</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Kurt Gray</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Dinesh Manocha</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>We present a real-time algorithm for emotion-aware navigation 
of a robot among pedestrians. Our approach estimates time-varying 
emotional behaviors of pedestrians from their faces and trajectories 
using a combination of Bayesian-inference, CNN-based learning, and the 
PAD (Pleasure-Arousal-Dominance) model from psychology. These PAD 
characteristics are used for long-term path prediction and generating 
proxemic constraints for each pedestrian. We use a multi-channel model 
to classify pedestrian characteristics into four emotion categories 
(happy, sad, angry, neutral). In our validation results, we observe an 
emotion detection accuracy of 85.33%. We formulate emotion-based 
proxemic constraints to perform socially-aware robot navigation in low- 
to medium-density environments. We demonstrate the benefits of our 
algorithm in simulated environments with tens of pedestrians as well as 
in a real-world setting with Pepper, a social humanoid robot.</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2019-03-07</td>
					</tr>
					<tr>
					<th>Short Title</th>
						<td>The Emotionally Intelligent Robot</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>arXiv.org</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="http://arxiv.org/abs/1903.03217">http://arxiv.org/abs/1903.03217</a></td>
					</tr>
					<tr>
					<th>Accessed</th>
						<td>11/4/2019, 11:50:48 AM</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>arXiv: 1903.03217</td>
					</tr>
					<tr>
					<th>Publication</th>
						<td>arXiv:1903.03217 [cs]</td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Tags:</h3>
				<ul class="tags">
					<li>Computer Science - Robotics</li>
				</ul>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_MWJUHMNA">arXiv Fulltext PDF					</li>
					<li id="item_FCTKE5QH">arXiv.org Snapshot					</li>
				</ul>
			</li>


			<li id="item_EKV9475Q" class="item conferencePaper">
			<h2>Effects of Distinct Robot Navigation Strategies on Human Behavior in a Crowded Environment</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Conference Paper</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Christoforos Mavrogiannis</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Alena M. Hutchinson</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>John Macdonald</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Patricia Alves-Oliveira</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Ross A. Knepper</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>State-of-the-art social robot navigation algorithms often lack
 a thorough experimental validation in human environments: simulated 
evaluations are often conducted under unrealistically strong assumptions
 that prohibit deployment in real world environments; experimental 
demonstrations that are limited in sample size do not provide adequate 
evidence regarding the user experience and the robot behavior; ﬁeld 
studies may suffer from the noise imposed by uncontrollable factors from
 the environment; controlled lab experiments often fail to properly 
enforce challenging interaction settings. This paper contributes a ﬁrst 
step towards addressing the outlined gaps in the literature. We present 
an original experiment, designed to test the implicit interaction 
between a mobile robot and a group of navigating human participants, 
under challenging settings in a controlled lab environment. We conducted
 a large-scale, within-subjects design study with 105 participants, 
exposed to three different conditions, corresponding to three distinct 
navigation strategies, executed by a telepresence robot (two autonomous,
 one teleoperated). We analyzed observed human and robot trajectories, 
under close interaction settings and participants’ impressions regarding
 the robot’s behavior. Key ﬁndings, extracted from a comparative 
statistical analysis include: (1) evidence that human acceleration is 
lower when navigating around an autonomous robot compared to a 
teleoperated one; (2) the lack of evidence to support the conventional 
expectation that teleoperation would be humans’ preferred strategy. To 
the best of our knowledge, our study is unique in terms of goals, 
settings, thoroughness of evaluation and sample size.</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>3/2019</td>
					</tr>
					<tr>
					<th>Language</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>DOI.org (Crossref)</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://ieeexplore.ieee.org/document/8673115/">https://ieeexplore.ieee.org/document/8673115/</a></td>
					</tr>
					<tr>
					<th>Accessed</th>
						<td>11/4/2019, 11:47:06 AM</td>
					</tr>
					<tr>
					<th>Place</th>
						<td>Daegu, Korea (South)</td>
					</tr>
					<tr>
					<th>Publisher</th>
						<td>IEEE</td>
					</tr>
					<tr>
					<th>ISBN</th>
						<td>978-1-5386-8555-6</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>421-430</td>
					</tr>
					<tr>
					<th>Proceedings Title</th>
						<td>2019 14th ACM/IEEE International Conference on Human-Robot Interaction (HRI)</td>
					</tr>
					<tr>
					<th>Conference Name</th>
						<td>2019 14th ACM/IEEE International Conference on Human-Robot Interaction (HRI)</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.1109/HRI.2019.8673115">10.1109/HRI.2019.8673115</a></td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_S9TD9GJM">Mavrogiannis et al. - 2019 - Effects of Distinct Robot Navigation Strategies on.pdf					</li>
				</ul>
			</li>


			<li id="item_TZ2GZFUK" class="item journalArticle">
			<h2>Crowd-Robot Interaction: Crowd-aware Robot Navigation with Attention-based Deep Reinforcement Learning</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Journal Article</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Changan Chen</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Yuejiang Liu</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Sven Kreiss</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Alexandre Alahi</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>Mobility in an effective and socially-compliant manner is an 
essential yet challenging task for robots operating in crowded spaces. 
Recent works have shown the power of deep reinforcement learning 
techniques to learn socially cooperative policies. However, their 
cooperation ability deteriorates as the crowd grows since they typically
 relax the problem as a one-way Human-Robot interaction problem. In this
 work, we want to go beyond first-order Human-Robot interaction and more
 explicitly model Crowd-Robot Interaction (CRI). We propose to (i) 
rethink pairwise interactions with a self-attention mechanism, and (ii) 
jointly model Human-Robot as well as Human-Human interactions in the 
deep reinforcement learning framework. Our model captures the 
Human-Human interactions occurring in dense crowds that indirectly 
affects the robot's anticipation capability. Our proposed attentive 
pooling mechanism learns the collective importance of neighboring humans
 with respect to their future states. Various experiments demonstrate 
that our model can anticipate human dynamics and navigate in crowds with
 time efficiency, outperforming state-of-the-art methods.</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2019-02-19</td>
					</tr>
					<tr>
					<th>Short Title</th>
						<td>Crowd-Robot Interaction</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>arXiv.org</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="http://arxiv.org/abs/1809.08835">http://arxiv.org/abs/1809.08835</a></td>
					</tr>
					<tr>
					<th>Accessed</th>
						<td>11/4/2019, 11:09:15 AM</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>arXiv: 1809.08835</td>
					</tr>
					<tr>
					<th>Publication</th>
						<td>arXiv:1809.08835 [cs]</td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Tags:</h3>
				<ul class="tags">
					<li>Computer Science - Machine Learning</li>
					<li>Computer Science - Robotics</li>
				</ul>
				<h3 class="notes">Notes:</h3>
				<ul class="notes">
					<li id="item_377JZYWR">
<p class="plaintext">Comment: Accepted at ICRA2019. Copyright may be transferred without notice, after which this version may no longer be accessible</p>
					</li>
				</ul>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_9KCBRG47">arXiv Fulltext PDF					</li>
					<li id="item_3JC5TJ5L">arXiv.org Snapshot					</li>
				</ul>
			</li>


			<li id="item_73EIMW86" class="item journalArticle">
			<h2>Pedestrian Dominance Modeling for Socially-Aware Robot Navigation</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Journal Article</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Tanmay Randhavane</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Aniket Bera</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Emily Kubin</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Austin Wang</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Kurt Gray</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Dinesh Manocha</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>We present a Pedestrian Dominance Model (PDM) to identify the 
dominance characteristics of pedestrians for robot navigation. Through a
 perception study on a simulated dataset of pedestrians, PDM models the 
perceived dominance levels of pedestrians with varying motion behaviors 
corresponding to trajectory, speed, and personal space. At runtime, we 
use PDM to identify the dominance levels of pedestrians to facilitate 
socially-aware navigation for the robots. PDM can predict dominance 
levels from trajectories with ~85% accuracy. Prior studies in psychology
 literature indicate that when interacting with humans, people are more 
comfortable around people that exhibit complementary movement behaviors.
 Our algorithm leverages this by enabling the robots to exhibit 
complementing responses to pedestrian dominance. We also present an 
application of PDM for generating dominance-based collision-avoidance 
behaviors in the navigation of autonomous vehicles among pedestrians. We
 demonstrate the benefits of our algorithm for robots navigating among 
tens of pedestrians in simulated environments.</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2019-02-13</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>arXiv.org</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="http://arxiv.org/abs/1810.06613">http://arxiv.org/abs/1810.06613</a></td>
					</tr>
					<tr>
					<th>Accessed</th>
						<td>11/4/2019, 11:25:51 AM</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>arXiv: 1810.06613</td>
					</tr>
					<tr>
					<th>Publication</th>
						<td>arXiv:1810.06613 [cs]</td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Tags:</h3>
				<ul class="tags">
					<li>Computer Science - Robotics</li>
				</ul>
				<h3 class="notes">Notes:</h3>
				<ul class="notes">
					<li id="item_SPLVLRHI">
<p class="plaintext">Comment: To Appear in ICRA 2019</p>
					</li>
				</ul>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_GDRV5EWF">arXiv.org Snapshot					</li>
					<li id="item_BYTXTQE5">arXiv Fulltext PDF					</li>
				</ul>
			</li>


			<li id="item_L6TDSI5U" class="item journalArticle">
			<h2>Socially aware robot navigation system in human-populated and 
interactive environments based on an adaptive spatial density function 
and space affordances</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Journal Article</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Araceli Vega</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Luis J. Manso</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Douglas G. Macharet</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Pablo Bustos</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Pedro Núñez</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>Traditionally robots are mostly known by society due to the 
wide use of manipulators, which are generally placed in controlled 
environments such as factories. However, with the advances in the area 
of mobile robotics, they are increasingly inserted into social contexts,
 i.e., in the presence of people. The adoption of socially acceptable 
behaviours demands a trade-off between social comfort and other metrics 
of efficiency. For navigation tasks, for example, humans must be 
differentiated from other ordinary objects in the scene. In this work, 
we propose a novel human-aware navigation strategy built upon the use of
 an adaptive spatial density function that efficiently cluster groups of
 people according to their spatial arrangement. Space affordances are 
also used for defining potential activity spaces considering the objects
 in the scene. The proposed function defines regions where navigation is
 either discouraged or forbidden. To implement a socially acceptable 
navigation, the navigation architecture combines a probabilistic roadmap
 and rapidly-exploring random tree path planners, and an adaptation of 
the elastic band algorithm. Trials in real and simulated environments 
carried out demonstrate that the use of the clustering algorithm and 
social rules in the navigation architecture do not hinder the navigation
 performance.</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>February 1, 2019</td>
					</tr>
					<tr>
					<th>Language</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>ScienceDirect</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="http://www.sciencedirect.com/science/article/pii/S0167865518303052">http://www.sciencedirect.com/science/article/pii/S0167865518303052</a></td>
					</tr>
					<tr>
					<th>Accessed</th>
						<td>11/4/2019, 11:20:57 AM</td>
					</tr>
					<tr>
					<th>Volume</th>
						<td>118</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>72-84</td>
					</tr>
					<tr>
					<th>Publication</th>
						<td>Pattern Recognition Letters</td>
					</tr>
					<tr>
					<th>Series</th>
						<td>Cooperative and Social Robots: Understanding Human Activities and Intentions</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.1016/j.patrec.2018.07.015">10.1016/j.patrec.2018.07.015</a></td>
					</tr>
					<tr>
					<th>Journal Abbr</th>
						<td>Pattern Recognition Letters</td>
					</tr>
					<tr>
					<th>ISSN</th>
						<td>0167-8655</td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Tags:</h3>
				<ul class="tags">
					<li>Affordances</li>
					<li>Aware robot navigation</li>
					<li>Social navigation</li>
				</ul>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_K67YNHN5">ScienceDirect Full Text PDF					</li>
					<li id="item_IFLB44DI">ScienceDirect Snapshot					</li>
				</ul>
			</li>


			<li id="item_JJZS93S8" class="item bookSection">
			<h2>MPDM: Multi-policy Decision-Making from Autonomous Driving to Social Robot Navigation</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Book Section</td>
					</tr>
					<tr>
						<th class="editor">Editor</th>
						<td>Harald Waschl</td>
					</tr>
					<tr>
						<th class="editor">Editor</th>
						<td>Ilya Kolmanovsky</td>
					</tr>
					<tr>
						<th class="editor">Editor</th>
						<td>Frank Willems</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Alex G. Cunningham</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Enric Galceran</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Dhanvin Mehta</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Gonzalo Ferrer</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Ryan M. Eustice</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Edwin Olson</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>This chapter presents Multi-Policy Decision-Making (MPDM): a 
novel approach to navigating in dynamic multi-agent environments. Rather
 than planning the trajectory of the robot explicitly, the planning 
process selects one of a set of closed-loop behaviors whose utility can 
be predicted through forward simulation that capture the complex 
interactions between the actions of these agents. These polices capture 
different high-level behavior and intentions, such as driving along a 
lane, turning at an intersection, or following pedestrians. We present 
two different scenarios where MPDM has been applied successfully: An 
autonomous driving environment that models vehicle behavior for both our
 vehicle and nearby vehicles and a social environment, where multiple 
agents or pedestrians conﬁgure a dynamic environment for autonomous 
robot navigation. We present extensive validation for MPDM on both 
scenarios, using simulated and real-world experiments.</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2019</td>
					</tr>
					<tr>
					<th>Language</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Short Title</th>
						<td>MPDM</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>DOI.org (Crossref)</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="http://link.springer.com/10.1007/978-3-319-91569-2_10">http://link.springer.com/10.1007/978-3-319-91569-2_10</a></td>
					</tr>
					<tr>
					<th>Accessed</th>
						<td>11/4/2019, 12:57:53 PM</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>DOI: 10.1007/978-3-319-91569-2_10</td>
					</tr>
					<tr>
					<th>Volume</th>
						<td>476</td>
					</tr>
					<tr>
					<th>Place</th>
						<td>Cham</td>
					</tr>
					<tr>
					<th>Publisher</th>
						<td>Springer International Publishing</td>
					</tr>
					<tr>
					<th>ISBN</th>
						<td>978-3-319-91568-5 978-3-319-91569-2</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>201-223</td>
					</tr>
					<tr>
					<th>Book Title</th>
						<td>Control Strategies for Advanced Driver Assistance Systems and Autonomous Driving Functions</td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_BM8X82I3">Cunningham et al. - 2019 - MPDM Multi-policy Decision-Making from Autonomous.pdf					</li>
				</ul>
			</li>


			<li id="item_N5KHFSTU" class="item bookSection">
			<h2>Making the Case for Human-Aware Navigation in Warehouses</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Book Section</td>
					</tr>
					<tr>
						<th class="editor">Editor</th>
						<td>Kaspar Althoefer</td>
					</tr>
					<tr>
						<th class="editor">Editor</th>
						<td>Jelizaveta Konstantinova</td>
					</tr>
					<tr>
						<th class="editor">Editor</th>
						<td>Ketao Zhang</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Manuel Fernandez Carmona</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Tejas Parekh</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Marc Hanheide</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>This work addresses the performance of several local planners 
for navigation of autonomous pallet trucks in the presence of humans in a
 simulated warehouse as well as a complementary approach developed 
within the ILIAD project. Our focus is to stress the open problem of a 
safe manoeuvrability of pallet trucks in the presence of moving humans. 
We propose a variation of ROS navigation stack that includes in the 
planning process a model of the human robot interaction.</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2019</td>
					</tr>
					<tr>
					<th>Language</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>DOI.org (Crossref)</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="http://link.springer.com/10.1007/978-3-030-25332-5_38">http://link.springer.com/10.1007/978-3-030-25332-5_38</a></td>
					</tr>
					<tr>
					<th>Accessed</th>
						<td>11/4/2019, 11:28:01 AM</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>DOI: 10.1007/978-3-030-25332-5_38</td>
					</tr>
					<tr>
					<th>Volume</th>
						<td>11650</td>
					</tr>
					<tr>
					<th>Place</th>
						<td>Cham</td>
					</tr>
					<tr>
					<th>Publisher</th>
						<td>Springer International Publishing</td>
					</tr>
					<tr>
					<th>ISBN</th>
						<td>978-3-030-25331-8 978-3-030-25332-5</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>449-453</td>
					</tr>
					<tr>
					<th>Book Title</th>
						<td>Towards Autonomous Robotic Systems</td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_7SY5NUG6">Fernandez Carmona et al. - 2019 - Making the Case for Human-Aware Navigation in Ware.pdf					</li>
				</ul>
			</li>


			<li id="item_7BVHIAPB" class="item bookSection">
			<h2>Planning Human-Robot Interaction for Social Navigation in Crowded Environments</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Book Section</td>
					</tr>
					<tr>
						<th class="editor">Editor</th>
						<td>Raquel Fuentetaja Pizán</td>
					</tr>
					<tr>
						<th class="editor">Editor</th>
						<td>Ángel García Olaya</td>
					</tr>
					<tr>
						<th class="editor">Editor</th>
						<td>Maria Paz Sesmero Lorente</td>
					</tr>
					<tr>
						<th class="editor">Editor</th>
						<td>Jose Antonio Iglesias Martínez</td>
					</tr>
					<tr>
						<th class="editor">Editor</th>
						<td>Agapito Ledezma Espino</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Araceli Vega</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Luis J. Manso</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Ramón Cintas</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Pedro Núñez</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>Navigation is one of the crucial skills autonomous robots need
 to perform daily tasks, and many of the rest depend on it. In this 
paper, we argue that this dependence goes both ways in advanced social 
autonomous robots. Manipulation, perception, and most importantly 
human-robot interaction are some of the skills in which navigation might
 rely on. This paper is focused on the dependence on human-robot 
interaction and uses two particular scenarios of growing complexity as 
an example: asking for collaboration to enter a room and asking for 
permission to navigate between two people which are talking. In the ﬁrst
 scenario, the person physically blocks the path to the adjacent room, 
so it would be impossible for the robot to navigate to such room. Even 
though in the second scenario the people talking do not block the path 
to the other room, from a social point of view, interrupting an ongoing 
conversation without noticing is undesirable. In this paper we propose a
 navigation planning domain and a set of software agents which allow the
 robot to navigate in crowded environments in a socially acceptable way,
 asking for cooperation or permission when necessary. The paper provides
 quantitative experimental results including social navigation metrics 
and the results of a Likert-scale satisfaction questionnaire.</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2019</td>
					</tr>
					<tr>
					<th>Language</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>DOI.org (Crossref)</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="http://link.springer.com/10.1007/978-3-319-99885-5_14">http://link.springer.com/10.1007/978-3-319-99885-5_14</a></td>
					</tr>
					<tr>
					<th>Accessed</th>
						<td>11/4/2019, 11:18:36 AM</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>DOI: 10.1007/978-3-319-99885-5_14</td>
					</tr>
					<tr>
					<th>Volume</th>
						<td>855</td>
					</tr>
					<tr>
					<th>Place</th>
						<td>Cham</td>
					</tr>
					<tr>
					<th>Publisher</th>
						<td>Springer International Publishing</td>
					</tr>
					<tr>
					<th>ISBN</th>
						<td>978-3-319-99884-8 978-3-319-99885-5</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>195-208</td>
					</tr>
					<tr>
					<th>Book Title</th>
						<td>Advances in Physical Agents</td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_Q2EZASDH">Vega et al. - 2019 - Planning Human-Robot Interaction for Social Naviga.pdf					</li>
				</ul>
			</li>


			<li id="item_9GSIR6GT" class="item bookSection">
			<h2>Safe and Efficient Autonomous Navigation in the Presence of Humans at Control Level</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Book Section</td>
					</tr>
					<tr>
						<th class="editor">Editor</th>
						<td>Nikos A. Aspragathos</td>
					</tr>
					<tr>
						<th class="editor">Editor</th>
						<td>Panagiotis N. Koustoumpardis</td>
					</tr>
					<tr>
						<th class="editor">Editor</th>
						<td>Vassilis C. Moulianitis</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Klaus Buchegger</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>George Todoran</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Markus Bader</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>In order to enable mobile robots to navigate autonomously in 
an environment shared with humans, special considerations are necessary 
to ensure both safe and eﬃcient navigation. This work presents a 
predictive, human-aware motion controller, based on the Robot Operating 
System (ROS), which optimizes the vehicle trajectory at the control 
level with a high update rate. Predicting future positions of persons 
allows the system to optimize a trajectory around those predictions, 
yielding a sequence of motor controls for a smooth executed motion. The 
improvements were statistically evaluated using simulation runs in terms
 of travel duration, path length, and minimum distance to persons along 
the path. This way, we are able to show that our new motion controller 
performs signiﬁcantly better in the presence of humans than a controller
 without human-awareness.</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2019</td>
					</tr>
					<tr>
					<th>Language</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>DOI.org (Crossref)</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="http://link.springer.com/10.1007/978-3-030-00232-9_53">http://link.springer.com/10.1007/978-3-030-00232-9_53</a></td>
					</tr>
					<tr>
					<th>Accessed</th>
						<td>11/4/2019, 12:59:09 PM</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>DOI: 10.1007/978-3-030-00232-9_53</td>
					</tr>
					<tr>
					<th>Volume</th>
						<td>67</td>
					</tr>
					<tr>
					<th>Place</th>
						<td>Cham</td>
					</tr>
					<tr>
					<th>Publisher</th>
						<td>Springer International Publishing</td>
					</tr>
					<tr>
					<th>ISBN</th>
						<td>978-3-030-00231-2 978-3-030-00232-9</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>504-511</td>
					</tr>
					<tr>
					<th>Book Title</th>
						<td>Advances in Service and Industrial Robotics</td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_CKN88BVC">Buchegger et al. - 2019 - Safe and Efficient Autonomous Navigation in the Pr.pdf					</li>
				</ul>
			</li>


			<li id="item_T9W5UMJ8" class="item conferencePaper">
			<h2>Human-aware Robot Navigation in Logistics Warehouses:</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Conference Paper</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Mourad Kenk</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>M. Hassaballah</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Jean-François Brethé</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2019</td>
					</tr>
					<tr>
					<th>Language</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Short Title</th>
						<td>Human-aware Robot Navigation in Logistics Warehouses</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>DOI.org (Crossref)</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="http://www.scitepress.org/DigitalLibrary/Link.aspx?doi=10.5220/0007920903710378">http://www.scitepress.org/DigitalLibrary/Link.aspx?doi=10.5220/0007920903710378</a></td>
					</tr>
					<tr>
					<th>Accessed</th>
						<td>11/4/2019, 11:31:37 AM</td>
					</tr>
					<tr>
					<th>Place</th>
						<td>Prague, Czech Republic</td>
					</tr>
					<tr>
					<th>Publisher</th>
						<td>SCITEPRESS - Science and Technology Publications</td>
					</tr>
					<tr>
					<th>ISBN</th>
						<td>978-989-758-380-3</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>371-378</td>
					</tr>
					<tr>
					<th>Proceedings Title</th>
						<td>Proceedings of the 16th International Conference on Informatics in Control, Automation and Robotics</td>
					</tr>
					<tr>
					<th>Conference Name</th>
						<td>16th International Conference on Informatics in Control, Automation and Robotics</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.5220/0007920903710378">10.5220/0007920903710378</a></td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_GLVEJKM8">Kenk et al. - 2019 - Human-aware Robot Navigation in Logistics Warehous.pdf					</li>
				</ul>
			</li>


			<li id="item_EEI7SWP7" class="item conferencePaper">
			<h2>Deep Learning-based Multiple Objects Detection and Tracking System for Socially Aware Mobile Robot Navigation Framework</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Conference Paper</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Do Nam Thang</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Lan Anh Nguyen</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Pham Trung Dung</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Truong Dang Khoa</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Nguyen Huu Son</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Nguyen Tran Hiep</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Pham Van Nguyen</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Vu Duc Truong</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Dinh Hong Toan</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Nguyen Manh Hung</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Trung-Dung Ngo</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Xuan-Tung Truong</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>Multiple objects (including humans) detection and tracking 
system plays an essential role in socially aware mobile robot navigation
 framework. Because, it provides an important input for the remaining 
modules of the framework. In this paper, we propose an efficient 
multiple objects detection and tracking system for mobile service robots
 in dynamic social environments using deep learning techniques. The 
proposed system consists of two steps: (1) multiple objects detection, 
and (2) multiple objects tracking. In the first step, the RGB 
image-based multiple objects detection is made use of to detect objects 
in the mobile robot's vicinity using a convolutional neural network. In 
the second stage of system, the detected objects are tracked using a 
deep simple online and realtime tracking technique. The experimental 
results indicate that, the proposed system is capable of detecting and 
tracking multiple objects including humans, providing significant 
information for the socially aware mobile robot navigation framework.</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>November 2018</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>IEEE Xplore</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>436-441</td>
					</tr>
					<tr>
					<th>Proceedings Title</th>
						<td>2018 5th NAFOSTED Conference on Information and Computer Science (NICS)</td>
					</tr>
					<tr>
					<th>Conference Name</th>
						<td>2018 5th NAFOSTED Conference on Information and Computer Science (NICS)</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.1109/NICS.2018.8606878">10.1109/NICS.2018.8606878</a></td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Tags:</h3>
				<ul class="tags">
					<li>learning (artificial intelligence)</li>
					<li>mobile robots</li>
					<li>Navigation</li>
					<li>path planning</li>
					<li>control engineering computing</li>
					<li>Mobile robots</li>
					<li>image colour analysis</li>
					<li>object detection</li>
					<li>service robots</li>
					<li>Robot sensing systems</li>
					<li>Safety</li>
					<li>Service robots</li>
					<li>convolutional neural nets</li>
					<li>convolutional neural network</li>
					<li>deep learning techniques</li>
					<li>deep simple online tracking technique</li>
					<li>multiple objects tracking</li>
					<li>Object detection</li>
					<li>object tracking</li>
					<li>RGB image-based multiple objects detection</li>
					<li>socially aware mobile robot navigation framework</li>
				</ul>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_XPE4X5PM">IEEE Xplore Abstract Record					</li>
					<li id="item_U3UQB82A">Thang et al. - 2018 - Deep Learning-based Multiple Objects Detection and.pdf					</li>
				</ul>
			</li>


			<li id="item_LF6BW2L8" class="item conferencePaper">
			<h2>A Flexible and Adaptive Spatial Density Model for Context-Aware Social Mapping: Towards a More Realistic Social Navigation</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Conference Paper</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Araceli Vega-Magro</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Luis J. Manso</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Pablo Bustos</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Pedro Nunez</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>Social navigation is a topic with enormous interest in 
autonomous robotics. Robots are gradually being used in human 
environments, working individually or collaborating with humans in their
 daily tasks. Robots in these scenarios have to be able to behave in a 
socially acceptable way and, for this reason, the way in which robots 
move has to adapt to humans and context. Proxemics has been extensively 
studied with the aim of improving social navigation. However, these 
works do not take into account that, in several situations, the personal
 space of the humans depends on the context (e.g., this human space is 
not the same in a narrow corridor than in a wide room). This work 
proposes the deﬁnition of an adaptive and ﬂexible space density function
 that allows, on the one hand, to describe the comfort space of 
individuals during an interaction and, on the other hand, dynamically 
adapt its value in terms of the space that surrounds this interaction. 
In order to validate the performance, this article describes a set of 
simulated experiments where the robustness and improvements of the 
approach are tested in different environments.</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>11/2018</td>
					</tr>
					<tr>
					<th>Language</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Short Title</th>
						<td>A Flexible and Adaptive Spatial Density Model for Context-Aware Social Mapping</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>DOI.org (Crossref)</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://ieeexplore.ieee.org/document/8581304/">https://ieeexplore.ieee.org/document/8581304/</a></td>
					</tr>
					<tr>
					<th>Accessed</th>
						<td>11/4/2019, 11:42:40 AM</td>
					</tr>
					<tr>
					<th>Place</th>
						<td>Singapore</td>
					</tr>
					<tr>
					<th>Publisher</th>
						<td>IEEE</td>
					</tr>
					<tr>
					<th>ISBN</th>
						<td>978-1-5386-9582-1</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>1727-1732</td>
					</tr>
					<tr>
					<th>Proceedings Title</th>
						<td>2018 15th International Conference on Control, Automation, Robotics and Vision (ICARCV)</td>
					</tr>
					<tr>
					<th>Conference Name</th>
						<td>2018 15th International Conference on Control, Automation, Robotics and Vision (ICARCV)</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.1109/ICARCV.2018.8581304">10.1109/ICARCV.2018.8581304</a></td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_GRQWEZNR">Vega-Magro et al. - 2018 - A Flexible and Adaptive Spatial Density Model for .pdf					</li>
				</ul>
			</li>


			<li id="item_4YY2BRTI" class="item journalArticle">
			<h2>Towards a Unified Planner For Socially-Aware Navigation</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Journal Article</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Santosh Balajee Banisetty</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>David Feil-Seifer</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>This paper presents the framework for a novel Unified 
Socially-Aware Navigation (USAN) architecture and explains its need in 
Socially Assistive Robotics (SAR) applications. Our approach emphasizes 
interpersonal distance and how spatial communication can be used to 
build a unified planner for a human-robot collaborative environment. 
Socially-Aware Navigation (SAN) is vital for helping humans to feel 
comfortable and safe around robots; HRI studies have shown the 
importance of SAN transcends safety and comfort. SAN plays a crucial 
role in perceived intelligence, sociability and social capacity of the 
robot, thereby increasing the acceptance of the robots in public places.
 Human environments are very dynamic and pose serious social challenges 
to robots intended for interactions with people. For the robots to cope 
with the changing dynamics of a situation, there is a need to infer 
intent and detect changes in the interaction context. SAN has gained 
immense interest in the social robotics community; to the best of our 
knowledge, however, there is no planner that can adapt to different 
interaction contexts spontaneously after autonomously sensing the 
context. Most of the recent efforts involve social path planning for a 
single context. In this work, we propose a novel approach for a unified 
architecture to SAN that can plan and execute trajectories for an 
autonomously sensed interaction context that are human-friendly. Our 
approach augments the navigation stack of the Robot Operating System 
(ROS) utilizing machine learning and optimization tools. We modified the
 ROS navigation stack using a machine learning-based context classifier 
and a PaCcET based local planner for us to achieve the goals of USAN. We
 discuss our preliminary results and concrete plans on putting the 
pieces together in achieving USAN.</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2018-10-11</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>arXiv.org</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="http://arxiv.org/abs/1810.00966">http://arxiv.org/abs/1810.00966</a></td>
					</tr>
					<tr>
					<th>Accessed</th>
						<td>11/4/2019, 11:52:09 AM</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>arXiv: 1810.00966</td>
					</tr>
					<tr>
					<th>Publication</th>
						<td>arXiv:1810.00966 [cs]</td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Tags:</h3>
				<ul class="tags">
					<li>Computer Science - Robotics</li>
				</ul>
				<h3 class="notes">Notes:</h3>
				<ul class="notes">
					<li id="item_LLXR8JAI">
<p class="plaintext">Comment: Presented at AI-HRI AAAI-FSS, 2018 (arXiv:1809.06606)</p>
					</li>
				</ul>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_H65NAMHQ">arXiv.org Snapshot					</li>
					<li id="item_GXENR3GW">arXiv Fulltext PDF					</li>
				</ul>
			</li>


			<li id="item_Q2DWFG2T" class="item conferencePaper">
			<h2>A Transient-Goal Driven Communication-Aware Navigation Strategy for Large Human-Populated Environments</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Conference Paper</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Vishnu K. Narayanan</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Takahiro Miyashita</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Yukiko Horikawa</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Norihiro Hagita</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>Robots deployed in large human-populated indoor environments 
such as shopping malls, airports etc., inadvertently communicate via 
wireless networks for enhanced perception and decision making 
capabilities. Owing to highly dynamic signal attenuation characteristics
 in such environments, connectivity issues may arise during robotic 
navigation, leading to disruption in information flow causing potential 
danger. Exact modeling of signal propagation for estimating spatial 
signal variation is usually challenging. Moreover, the presence of 
dynamic humans also add a layer of temporal signal variation 
complexities. Thus, this paper introduces a generative approach for 
embedding radio signal strength constraints within networked 
service/social robot navigation in large human-populated environments. 
Initially, we propose a Gaussian Process based online spatio-temporal 
signal strength prediction model that, as opposed to the current state 
of the art, also aims to take into account the temporal fading arising 
due to the presence of human crowds. We then devise a transient-goal 
driven navigation strategy to realize a sub-optimal path towards a goal,
 that is aimed at resolving both communication-aware and human-aware 
planning constraints. Evaluations of the proposed signal prediction 
model demonstrate the advantages of our approach with respect to the 
current state of the art. The efficacy of the navigation strategy in 
also demonstrated simulations and using hardware experiments conducted 
on a robotic wheelchair operating in a large shopping mall.</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>October 2018</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>IEEE Xplore</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>ISSN: 2153-0866, 2153-0858</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>1-9</td>
					</tr>
					<tr>
					<th>Proceedings Title</th>
						<td>2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</td>
					</tr>
					<tr>
					<th>Conference Name</th>
						<td>2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.1109/IROS.2018.8593827">10.1109/IROS.2018.8593827</a></td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Tags:</h3>
				<ul class="tags">
					<li>mobile robots</li>
					<li>Navigation</li>
					<li>path planning</li>
					<li>Mobile robots</li>
					<li>indoor navigation</li>
					<li>social robot navigation</li>
					<li>Robot sensing systems</li>
					<li>communication-aware planning constraints</li>
					<li>connectivity issues</li>
					<li>decision making</li>
					<li>decision making capabilities</li>
					<li>Fading channels</li>
					<li>Gaussian Process</li>
					<li>Gaussian processes</li>
					<li>human-aware planning constraints</li>
					<li>human-populated indoor environments</li>
					<li>networked service</li>
					<li>radio signal strength constraints</li>
					<li>robotic wheelchair operation</li>
					<li>shopping mall</li>
					<li>signal processing</li>
					<li>sub-optimal path</li>
					<li>Transient analysis</li>
					<li>transient-goal driven communication-aware navigation strategy</li>
					<li>Wireless communication</li>
					<li>wireless networks</li>
					<li>wireless sensor networks</li>
				</ul>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_VHJJ6KVF">IEEE Xplore Abstract Record					</li>
					<li id="item_LZ379STW">Narayanan et al. - 2018 - A Transient-Goal Driven Communication-Aware Naviga.pdf					</li>
				</ul>
			</li>


			<li id="item_ZGQIUBNI" class="item conferencePaper">
			<h2>Socially-Aware Navigation Using Non-Linear Multi-Objective Optimization</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Conference Paper</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Scott Forer</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Santosh Balajee Banisetty</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Logan Yliniemi</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Monica Nicolescu</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>David Feil-Seifer</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>For socially assistive robots (SAR) to be accepted into 
complex and stochastic human environments, it is important to account 
for subtle social norms. In this paper, we propose a novel approach to 
socially-aware navigation (SAN) which garnered an immense interest in 
the Human-Robot Interaction (HRI) community. We use a multi-objective 
optimization tool called the Pareto Concavity Elimination Transformation
 (PaCcET) to capture the non-linear human navigation behavior, a novel 
contribution to the community. We use autonomously sensed distance-based
 features that captures the social norms and associated social costs for
 a given trajectory point towards the goal. Rather than use a 
ﬁnely-tuned linear combination of these costs, we use PaCcET to select 
an optimized future trajectory point, associated with a non-linear 
combination of the costs. Existing research in this domain concentrates 
on geometric reasoning, model-based, and learning approaches, which have
 their own pros and cons. This approach is distinct from prior work in 
this area. We showed in a simulation that the PaCcET based trajectory 
planner not only is able to avoid collisions and reach the intended 
destination in static and dynamic environments but also considers a 
human’s personal space in the trajectory selection process.</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>10/2018</td>
					</tr>
					<tr>
					<th>Language</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>DOI.org (Crossref)</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://ieeexplore.ieee.org/document/8593825/">https://ieeexplore.ieee.org/document/8593825/</a></td>
					</tr>
					<tr>
					<th>Accessed</th>
						<td>11/4/2019, 11:29:54 AM</td>
					</tr>
					<tr>
					<th>Place</th>
						<td>Madrid</td>
					</tr>
					<tr>
					<th>Publisher</th>
						<td>IEEE</td>
					</tr>
					<tr>
					<th>ISBN</th>
						<td>978-1-5386-8094-0</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>1-9</td>
					</tr>
					<tr>
					<th>Proceedings Title</th>
						<td>2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</td>
					</tr>
					<tr>
					<th>Conference Name</th>
						<td>2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.1109/IROS.2018.8593825">10.1109/IROS.2018.8593825</a></td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_VL8PRVE4">Forer et al. - 2018 - Socially-Aware Navigation Using Non-Linear Multi-O.pdf					</li>
				</ul>
			</li>


			<li id="item_FUZIVPD8" class="item conferencePaper">
			<h2>Intelligent Fuzzy Controller for Human-Aware Robot Navigation</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Conference Paper</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Takenori Obo</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>This paper presents a framework of mobile robot system for 
human-aware robot navigation. Recently, we have experienced advanced 
researches and developments on mobile service robots for cleaning and 
guide in public places. Autonomous robot navigation in dynamic 
environments where a robot is surrounded by a lot of pedestrians is one 
of the major challenges in intelligentrobot systems. In this study, we 
develop a fuzzy controller to realize a multi objective task planning in
 crowds. Furthermore, we show an experimental example and discuss the 
applicabilityof the proposed method from the experimental results.</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>Sep. 2018</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>IEEE Xplore</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>392-397</td>
					</tr>
					<tr>
					<th>Proceedings Title</th>
						<td>2018 12th France-Japan and 10th Europe-Asia Congress on Mechatronics</td>
					</tr>
					<tr>
					<th>Conference Name</th>
						<td>2018 12th France-Japan and 10th Europe-Asia Congress on Mechatronics</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.1109/MECATRONICS.2018.8495686">10.1109/MECATRONICS.2018.8495686</a></td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Tags:</h3>
				<ul class="tags">
					<li>Trajectory</li>
					<li>Collision avoidance</li>
					<li>mobile robots</li>
					<li>Navigation</li>
					<li>path planning</li>
					<li>Robot kinematics</li>
					<li>Mobile robots</li>
					<li>human-robot interaction</li>
					<li>service robots</li>
					<li>human-aware robot navigation</li>
					<li>navigation</li>
					<li>Robot sensing systems</li>
					<li>dynamic environments</li>
					<li>mobile service robots</li>
					<li>autonomous robot navigation</li>
					<li>cleaning</li>
					<li>crowds</li>
					<li>fuzzy control</li>
					<li>fuzzy controller</li>
					<li>guide</li>
					<li>intelligent fuzzy controller</li>
					<li>intelligent robot systems</li>
					<li>mobile robot system</li>
					<li>multiobjective task planning</li>
					<li>public places</li>
				</ul>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_VV84EE6V">Obo - 2018 - Intelligent Fuzzy Controller for Human-Aware Robot.pdf					</li>
					<li id="item_CPVYPBI8">IEEE Xplore Abstract Record					</li>
				</ul>
			</li>


			<li id="item_38B7AW7V" class="item journalArticle">
			<h2>“To Approach Humans?”: A Unified Framework for Approaching Pose Prediction and Socially Aware Robot Navigation</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Journal Article</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Xuan-Tung Truong</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Trung-Dung Ngo</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>We propose a unified framework for approaching pose 
prediction, and socially aware robot navigation, which enables a mobile 
service robot to safely and socially approach a dynamic human or human 
group in a social environment. The proposed framework is composed of 
four major functional blocks: 1) human detection and human features 
extraction to estimate the human states, and the social interaction 
information from the socio-spatio-temporal characteristics of a human 
and a group of humans; 2) a dynamic social zone (DSZ) consisting of an 
extended personal space and a social interaction space is modeled by the
 human states and social interaction information to represent space 
around the human and human group; 3) the approaching pose of the robot 
to a human or a human group is predicted using the DSZ and the 
environmental surroundings; and 4) the DSZ and the estimated approaching
 pose are incorporated into a motion planning system, comprising a local
 path planner and dynamic window approach technique, to generate the 
motion control commands for the mobile robot. We evaluate the developed 
framework through both simulation and real-world experiments under the 
newly proposed human safety and comfort indices, including the social 
individual index, social group index, and social direction index. The 
results show that the unified framework is fully capable of driving a 
mobile robot to approach both stationary and moving humans and human 
groups in a socially acceptable manner while guaranteeing human safety 
and comfort.</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>Sep. 2018</td>
					</tr>
					<tr>
					<th>Short Title</th>
						<td>“To Approach Humans?</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>IEEE Xplore</td>
					</tr>
					<tr>
					<th>Volume</th>
						<td>10</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>557-572</td>
					</tr>
					<tr>
					<th>Publication</th>
						<td>IEEE Transactions on Cognitive and Developmental Systems</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.1109/TCDS.2017.2751963">10.1109/TCDS.2017.2751963</a></td>
					</tr>
					<tr>
					<th>Issue</th>
						<td>3</td>
					</tr>
					<tr>
					<th>ISSN</th>
						<td>2379-8920, 2379-8939</td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Tags:</h3>
				<ul class="tags">
					<li>mobile robots</li>
					<li>Navigation</li>
					<li>path planning</li>
					<li>motion control</li>
					<li>Mobile robots</li>
					<li>human-robot interaction</li>
					<li>object detection</li>
					<li>robot vision</li>
					<li>service robots</li>
					<li>human safety</li>
					<li>human states</li>
					<li>Mobile communication</li>
					<li>mobile service robot</li>
					<li>motion planning system</li>
					<li>Safety</li>
					<li>Service robots</li>
					<li>social environment</li>
					<li>socially acceptable manner</li>
					<li>socially aware robot navigation</li>
					<li>Approaching humans</li>
					<li>DSZ</li>
					<li>dynamic human group</li>
					<li>dynamic social zone</li>
					<li>dynamic social zone (DSZ)</li>
					<li>dynamic window approach technique</li>
					<li>feature extraction</li>
					<li>human detection</li>
					<li>human features extraction</li>
					<li>human safety and comfort indices (HSCIs)</li>
					<li>Indexes</li>
					<li>motion control commands</li>
					<li>path planner</li>
					<li>personal space</li>
					<li>pose estimation</li>
					<li>pose prediction</li>
					<li>social direction index</li>
					<li>social group index</li>
					<li>social individual index</li>
					<li>social interaction information</li>
					<li>social interaction space</li>
					<li>social robot</li>
					<li>socio spatiotemporal characteristics</li>
					<li>stationary moving humans</li>
					<li>unified framework</li>
				</ul>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_WIHUHKI7">IEEE Xplore Abstract Record					</li>
					<li id="item_KQ5UJL3P">Truong and Ngo - 2018 - “To Approach Humans” A Unified Framework for App.pdf					</li>
				</ul>
			</li>


			<li id="item_QS3YRTI4" class="item conferencePaper">
			<h2>Context-Aware Trajectory Prediction</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Conference Paper</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Federico Bartoli</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Giuseppe Lisanti</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Lamberto Ballan</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Alberto Del Bimbo</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>Human motion and behaviour in crowded spaces is influenced by 
several factors, such as the dynamics of other moving agents in the 
scene, as well as the static elements that might be perceived as points 
of attraction or obstacles. In this work, we present a new model for 
human trajectory prediction which is able to take advantage of both 
human-human and human-space interactions. The future trajectory of 
humans, are generated by observing their past positions and interactions
 with the surroundings. To this end, we propose a “context-aware” 
recurrent neural network LSTM model, which can learn and predict human 
motion in crowded spaces such as a sidewalk, a museum or a shopping 
mall. We evaluate our model on a public pedestrian datasets, and we 
contribute a new challenging dataset that collects videos of humans that
 navigate in a (real) crowded space such as a big museum. Results show 
that our approach can predict human trajectories better when compared to
 previous state-of-the-art forecasting models.</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>August 2018</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>IEEE Xplore</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>ISSN: 1051-4651</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>1941-1946</td>
					</tr>
					<tr>
					<th>Proceedings Title</th>
						<td>2018 24th International Conference on Pattern Recognition (ICPR)</td>
					</tr>
					<tr>
					<th>Conference Name</th>
						<td>2018 24th International Conference on Pattern Recognition (ICPR)</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.1109/ICPR.2018.8545447">10.1109/ICPR.2018.8545447</a></td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Tags:</h3>
				<ul class="tags">
					<li>Cameras</li>
					<li>Context modeling</li>
					<li>context-aware recurrent neural network LSTM model</li>
					<li>context-aware trajectory prediction</li>
					<li>human motion learning</li>
					<li>human trajectory prediction</li>
					<li>human-human interactions</li>
					<li>human-space interactions</li>
					<li>image motion analysis</li>
					<li>learning (artificial intelligence)</li>
					<li>Legged locomotion</li>
					<li>Logic gates</li>
					<li>pedestrians</li>
					<li>prediction theory</li>
					<li>Predictive models</li>
					<li>public pedestrian datasets</li>
					<li>recurrent neural nets</li>
					<li>Training</li>
					<li>Trajectory</li>
					<li>ubiquitous computing</li>
					<li>video signal processing</li>
				</ul>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_T37P6UHM">1705.02503.pdf					</li>
					<li id="item_GKHH5F5P">1705.02503.pdf					</li>
				</ul>
			</li>


			<li id="item_MNS4QIUE" class="item conferencePaper">
			<h2>Formalizing a Transient-Goal Driven Approach for Pedestrian-Aware Robot Navigation</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Conference Paper</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Vishnu K. Narayanan</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Takahiro Miyashita</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Norihiro Hagita</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>In this paper, we lay the algorithmic foundations of a 
unifying strategy for pedestrian-aware navigation that is aimed at 
service/social robots deployed in large human-crowded environments. In 
order to accommodate both modeled and learned social navigation 
behaviors, we formalize an approach within which the robot traverses to a
 specific goal (or sub-goal) via a trajectory of optimal transient-goals
 or optimal short-term way-points. We then evaluate an implementation of
 the navigation strategy, by utilizing an augmented Risk-based Rapidly 
Exploring Random Trees (RRT) planner, and demonstrate its efficacy for 
real-world deployment using discriminative simulations and by providing 
avenues for future work.</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>August 2018</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>IEEE Xplore</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>ISSN: 1944-9437, 1944-9445</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>862-867</td>
					</tr>
					<tr>
					<th>Proceedings Title</th>
						<td>2018 27th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN)</td>
					</tr>
					<tr>
					<th>Conference Name</th>
						<td>2018 27th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN)</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.1109/ROMAN.2018.8525624">10.1109/ROMAN.2018.8525624</a></td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Tags:</h3>
				<ul class="tags">
					<li>pedestrians</li>
					<li>mobile robots</li>
					<li>Navigation</li>
					<li>path planning</li>
					<li>Mobile robots</li>
					<li>service robots</li>
					<li>Cost function</li>
					<li>Planning</li>
					<li>navigation</li>
					<li>Transient analysis</li>
					<li>algorithmic foundations</li>
					<li>human-crowded environments</li>
					<li>navigation behaviors</li>
					<li>navigation strategy</li>
					<li>optimal transient-goals</li>
					<li>pedestrian-aware navigation</li>
					<li>pedestrian-aware robot navigation</li>
					<li>Prediction algorithms</li>
					<li>real-world deployment</li>
					<li>robot traverses</li>
					<li>service/social robots</li>
					<li>short-term way-points</li>
					<li>social navigation behaviors</li>
					<li>transient-goal driven approach</li>
					<li>trees (mathematics)</li>
					<li>unifying strategy</li>
				</ul>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_WAEH89C3">IEEE Xplore Abstract Record					</li>
					<li id="item_A8VV5KJN">Narayanan et al. - 2018 - Formalizing a Transient-Goal Driven Approach for P.pdf					</li>
				</ul>
			</li>


			<li id="item_C5ARY9K4" class="item journalArticle">
			<h2>The Socially Invisible Robot: Navigation in the Social World using Robot Entitativity</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Journal Article</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Aniket Bera</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Tanmay Randhavane</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Emily Kubin</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Austin Wang</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Dinesh Manocha</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Kurt Gray</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>We present a real-time, data-driven algorithm to enhance the 
social-invisibility of robots within crowds. Our approach is based on 
prior psychological research, which reveals that people notice 
and--importantly--react negatively to groups of social actors when they 
have high entitativity, moving in a tight group with similar appearances
 and trajectories. In order to evaluate that behavior, we performed a 
user study to develop navigational algorithms that minimize 
entitativity. This study establishes a mapping between emotional 
reactions and multi-robot trajectories and appearances and further 
generalizes the finding across various environmental conditions. We 
demonstrate the applicability of our entitativity modeling for 
trajectory computation for active surveillance and dynamic intervention 
in simulated robot-human interaction scenarios. Our approach empirically
 shows that various levels of entitative robots can be used to both 
avoid and influence pedestrians while not eliciting strong emotional 
reactions, giving multi-robot systems socially-invisibility.</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2018-07-18</td>
					</tr>
					<tr>
					<th>Short Title</th>
						<td>The Socially Invisible Robot</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>arXiv.org</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="http://arxiv.org/abs/1805.05543">http://arxiv.org/abs/1805.05543</a></td>
					</tr>
					<tr>
					<th>Accessed</th>
						<td>11/4/2019, 11:43:20 AM</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>arXiv: 1805.05543</td>
					</tr>
					<tr>
					<th>Publication</th>
						<td>arXiv:1805.05543 [cs]</td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Tags:</h3>
				<ul class="tags">
					<li>Computer Science - Robotics</li>
					<li>Computer Science - Human-Computer Interaction</li>
				</ul>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_NFFM4Q85">arXiv Fulltext PDF					</li>
					<li id="item_APE8534F">arXiv.org Snapshot					</li>
				</ul>
			</li>


			<li id="item_K2LK2IKK" class="item conferencePaper">
			<h2>Social GAN: Socially Acceptable Trajectories with Generative Adversarial Networks</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Conference Paper</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Agrim Gupta</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Justin Johnson</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Li Fei-Fei</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Silvio Savarese</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Alexandre Alahi</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>Understanding human motion behavior is critical for autonomous
 moving platforms (like self-driving cars and social robots) if they are
 to navigate human-centric environments. This is challenging because 
human motion is inherently multimodal: given a history of human motion 
paths, there are many socially plausible ways that people could move in 
the future. We tackle this problem by combining tools from sequence 
prediction and generative adversarial networks: a recurrent 
sequence-to-sequence model observes motion histories and predicts future
 behavior, using a novel pooling mechanism to aggregate information 
across people. We predict socially plausible futures by training 
adversarially against a recurrent discriminator, and encourage diverse 
predictions with a novel variety loss. Through experiments on several 
datasets we demonstrate that our approach outperforms prior work in 
terms of accuracy, variety, collision avoidance, and computational 
complexity.</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>6/2018</td>
					</tr>
					<tr>
					<th>Language</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Short Title</th>
						<td>Social GAN</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>DOI.org (Crossref)</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://ieeexplore.ieee.org/document/8578338/">https://ieeexplore.ieee.org/document/8578338/</a></td>
					</tr>
					<tr>
					<th>Accessed</th>
						<td>10/29/2019, 2:12:32 PM</td>
					</tr>
					<tr>
					<th>Place</th>
						<td>Salt Lake City, UT</td>
					</tr>
					<tr>
					<th>Publisher</th>
						<td>IEEE</td>
					</tr>
					<tr>
					<th>ISBN</th>
						<td>978-1-5386-6420-9</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>2255-2264</td>
					</tr>
					<tr>
					<th>Proceedings Title</th>
						<td>2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition</td>
					</tr>
					<tr>
					<th>Conference Name</th>
						<td>2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.1109/CVPR.2018.00240">10.1109/CVPR.2018.00240</a></td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_XU66Z3PN">Gupta et al. - 2018 - Social GAN Socially Acceptable Trajectories with .pdf					</li>
				</ul>
			</li>


			<li id="item_TIKUQK44" class="item journalArticle">
			<h2>Probabilistically Safe Robot Planning with Confidence-Based Human Predictions</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Journal Article</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Jaime F. Fisac</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Andrea Bajcsy</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Sylvia L. Herbert</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>David Fridovich-Keil</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Steven Wang</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Claire J. Tomlin</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Anca D. Dragan</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>In order to safely operate around humans, robots can employ 
predictive models of human motion. Unfortunately, these models cannot 
capture the full complexity of human behavior and necessarily introduce 
simplifying assumptions. As a result, predictions may degrade whenever 
the observed human behavior departs from the assumed structure, which 
can have negative implications for safety. In this paper, we observe 
that how "rational" human actions appear under a particular model can be
 viewed as an indicator of that model's ability to describe the human's 
current motion. By reasoning about this model confidence in a real-time 
Bayesian framework, we show that the robot can very quickly modulate its
 predictions to become more uncertain when the model performs poorly. 
Building on recent work in provably-safe trajectory planning, we 
leverage these confidence-aware human motion predictions to generate 
assured autonomous robot motion. Our new analysis combines worst-case 
tracking error guarantees for the physical robot with probabilistic 
time-varying human predictions, yielding a quantitative, probabilistic 
safety certificate. We demonstrate our approach with a quadcopter 
navigating around a human.</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2018-05-31</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>arXiv.org</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="http://arxiv.org/abs/1806.00109">http://arxiv.org/abs/1806.00109</a></td>
					</tr>
					<tr>
					<th>Accessed</th>
						<td>11/4/2019, 1:10:57 PM</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>arXiv: 1806.00109</td>
					</tr>
					<tr>
					<th>Publication</th>
						<td>arXiv:1806.00109 [cs]</td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Tags:</h3>
				<ul class="tags">
					<li>Computer Science - Machine Learning</li>
					<li>Computer Science - Robotics</li>
				</ul>
				<h3 class="notes">Notes:</h3>
				<ul class="notes">
					<li id="item_BK6IUECG">
<p class="plaintext">Comment: Robotics Science and Systems (RSS) 2018</p>
					</li>
				</ul>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_I68KNFSL">arXiv.org Snapshot					</li>
					<li id="item_2UDI6VMZ">arXiv Fulltext PDF					</li>
				</ul>
			</li>


			<li id="item_IPJLHDCM" class="item conferencePaper">
			<h2>Social Attention: Modeling Attention in Human Crowds</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Conference Paper</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Anirudh Vemula</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Katharina Muelling</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Jean Oh</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>Robots that navigate through human crowds need to be able to 
plan safe, efficient, and human predictable trajectories. This is a 
particularly challenging problem as it requires the robot to predict 
future human trajectories within a crowd where everyone implicitly 
cooperates with each other to avoid collisions. Previous approaches to 
human trajectory prediction have modeled the interactions between humans
 as a function of proximity. However, that is not necessarily true as 
some people in our immediate vicinity moving in the same direction might
 not be as important as other people that are further away, but that 
might collide with us in the future. In this work, we propose Social 
Attention, a novel trajectory prediction model that captures the 
relative importance of each person when navigating in the crowd, 
irrespective of their proximity. We demonstrate the performance of our 
method against a state-of-the-art approach on two publicly available 
crowd datasets and analyze the trained attention model to gain a better 
understanding of which surrounding agents humans attend to, when 
navigating in a crowd.</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>May 2018</td>
					</tr>
					<tr>
					<th>Short Title</th>
						<td>Social Attention</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>IEEE Xplore</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>ISSN: 2577-087X</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>4601-4607</td>
					</tr>
					<tr>
					<th>Proceedings Title</th>
						<td>2018 IEEE International Conference on Robotics and Automation (ICRA)</td>
					</tr>
					<tr>
					<th>Conference Name</th>
						<td>2018 IEEE International Conference on Robotics and Automation (ICRA)</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.1109/ICRA.2018.8460504">10.1109/ICRA.2018.8460504</a></td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Tags:</h3>
				<ul class="tags">
					<li>human trajectory prediction</li>
					<li>learning (artificial intelligence)</li>
					<li>Predictive models</li>
					<li>Trajectory</li>
					<li>collision avoidance</li>
					<li>Collision avoidance</li>
					<li>Dynamics</li>
					<li>human crowds</li>
					<li>human predictable trajectories</li>
					<li>mobile robots</li>
					<li>Navigation</li>
					<li>path planning</li>
					<li>publicly available crowd datasets</li>
					<li>robots</li>
					<li>Robots</li>
					<li>Social Attention</li>
					<li>Task analysis</li>
					<li>trained attention model</li>
				</ul>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_MLNC42NQ">Submitted Version					</li>
					<li id="item_5FSQWP9J">IEEE Xplore Abstract Record					</li>
				</ul>
			</li>


			<li id="item_9CDKA79G" class="item conferencePaper">
			<h2>Understanding Human Behaviors in Crowds by Imitating the Decision-Making Process</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Conference Paper</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Haosheng Zou</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Hang Su</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Shihong Song</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Jun Zhu</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>Crowd behavior understanding is crucial yet challenging across
 a wide range of applications, since crowd behavior is inherently 
determined by a sequential decision-making process based on various 
factors, such as the pedestrians' own destinations, interaction with 
nearby pedestrians and anticipation of upcoming events. In this paper, 
we propose a novel framework of Social-Aware Generative Adversarial 
Imitation Learning (SA-GAIL) to mimic the underlying decision-making 
process of pedestrians in crowds. Specifically, we infer the latent 
factors of human decision-making process in an unsupervised manner by 
extending the Generative Adversarial Imitation Learning framework to 
anticipate future paths of pedestrians. Different factors of human 
decision making are disentangled with mutual information maximization, 
with the process modeled by collision avoidance regularization and 
Social-Aware LSTMs. Experimental results demonstrate the potential of 
our framework in disentangling the latent decision-making factors of 
pedestrians and stronger abilities in predicting future trajectories.</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2018/04/27</td>
					</tr>
					<tr>
					<th>Language</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>www.aaai.org</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/17012">https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/17012</a></td>
					</tr>
					<tr>
					<th>Accessed</th>
						<td>10/29/2019, 2:15:02 PM</td>
					</tr>
					<tr>
					<th>Rights</th>
						<td>Authors who publish a paper in this conference agree to the 
following terms:   Author(s) agree to transfer their copyrights in their
 article/paper to the Association for the Advancement of Artificial 
Intelligence (AAAI), in order to deal with future requests for reprints,
 translations, anthologies, reproductions, excerpts, and other 
publications. This grant will include, without limitation, the entire 
copyright in the article/paper in all countries of the world, including 
all renewals, extensions, and reversions thereof, whether such rights 
current exist or hereafter come into effect, and also the exclusive 
right to create electronic versions of the article/paper, to the extent 
that such right is not subsumed under copyright.  The author(s) warrants
 that they are the sole author and owner of the copyright in the above 
article/paper, except for those portions shown to be in quotations; that
 the article/paper is original throughout; and that the undersigned 
right to make the grants set forth above is complete and unencumbered.  
The author(s) agree that if anyone brings any claim or action alleging 
facts that, if true, constitute a breach of any of the foregoing 
warranties, the author(s) will hold harmless and indemnify AAAI, their 
grantees, their licensees, and their distributors against any liability,
 whether under judgment, decree, or compromise, and any legal fees and 
expenses arising out of that claim or actions, and the undersigned will 
cooperate fully in any defense AAAI may make to such claim or action. 
Moreover, the undersigned agrees to cooperate in any claim or other 
action seeking to protect or enforce any right the undersigned has 
granted to AAAI in the article/paper. If any such claim or action fails 
because of facts that constitute a breach of any of the foregoing 
warranties, the undersigned agrees to reimburse whomever brings such 
claim or action for expenses and attorneys’ fees incurred therein.  
Author(s) retain all proprietary rights other than copyright (such as 
patent rights).  Author(s) may make personal reuse of all or portions of
 the above article/paper in other works of their own authorship.  
Author(s) may reproduce, or have reproduced, their article/paper for the
 author’s personal use, or for company use provided that AAAI copyright 
and the source are indicated, and that the copies are not used in a way 
that implies AAAI endorsement of a product or service of an employer, 
and that the copies per se are not offered for sale. The foregoing right
 shall not permit the posting of the article/paper in electronic or 
digital form on any computer network, except by the author or the 
author’s employer, and then only on the author’s or the employer’s own 
web page or ftp site. Such web page or ftp site, in addition to the 
aforementioned requirements of this Paragraph, must provide an 
electronic reference or link back to the AAAI electronic server, and 
shall not post other AAAI copyrighted materials not of the author’s or 
the employer’s creation (including tables of contents with links to 
other papers) without AAAI’s written permission.  Author(s) may make 
limited distribution of all or portions of their article/paper prior to 
publication.  In the case of work performed under U.S. Government 
contract, AAAI grants the U.S. Government royalty-free permission to 
reproduce all or portions of the above article/paper, and to authorize 
others to do so, for U.S. Government purposes.  In the event the above 
article/paper is not accepted and published by AAAI, or is withdrawn by 
the author(s) before acceptance by AAAI, this agreement becomes null and
 void.</td>
					</tr>
					<tr>
					<th>Proceedings Title</th>
						<td>Thirty-Second AAAI Conference on Artificial Intelligence</td>
					</tr>
					<tr>
					<th>Conference Name</th>
						<td>Thirty-Second AAAI Conference on Artificial Intelligence</td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_IFIHEF9W">Snapshot					</li>
					<li id="item_7CGIAUPV">Full Text PDF					</li>
				</ul>
			</li>


			<li id="item_5V8XSNN9" class="item bookSection">
			<h2>Knowing You, Seeing Me: Investigating User Preferences in Drone-Human Acknowledgement</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Book Section</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Walther Jensen</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Simon Hansen</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Hendrik Knoche</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>In the past, human proxemics research has poorly predicted 
human robot interaction distances. This paper presents three studies on 
drone gestures to acknowledge human presence and clarify suitable 
acknowledging distances. We evaluated four drone gestures based on 
non-verbal human greetings. The gestures included orienting towards the 
counterpart and salutation gestures. We tested these individually and in
 combination to create a feeling of acknowledgement in people. Our users
 preferred being acknowledged from two meters away but gestures were 
also effective from four meters. Rotating the drone towards the user 
elicited a higher degree of acknowledgement than without. We conclude 
with a set design guidelines for drone gestures.</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>April 21, 2018</td>
					</tr>
					<tr>
					<th>Short Title</th>
						<td>Knowing You, Seeing Me</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>ACM Digital Library</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://doi.org/10.1145/3173574.3173939">https://doi.org/10.1145/3173574.3173939</a></td>
					</tr>
					<tr>
					<th>Accessed</th>
						<td>11/30/2021, 1:00:00 AM</td>
					</tr>
					<tr>
					<th>Place</th>
						<td>New York, NY, USA</td>
					</tr>
					<tr>
					<th>Publisher</th>
						<td>Association for Computing Machinery</td>
					</tr>
					<tr>
					<th>ISBN</th>
						<td>978-1-4503-5620-6</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>1–12</td>
					</tr>
					<tr>
					<th>Book Title</th>
						<td>Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems</td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Tags:</h3>
				<ul class="tags">
					<li>proxemics</li>
					<li>hri</li>
					<li>uav</li>
					<li>acknowledgement</li>
					<li>drone</li>
					<li>drone gesture</li>
					<li>hdi</li>
					<li>human-drone interaction</li>
					<li>quadcopter</li>
				</ul>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_GC7RJ9FI">Full Text PDF					</li>
				</ul>
			</li>


			<li id="item_GIYH3ILT" class="item conferencePaper">
			<h2>Group LSTM: Group Trajectory Prediction in Crowded Scenarios</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Conference Paper</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Niccolo Bisagno</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Bo Zhang</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Nicola Conci</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2018</td>
					</tr>
					<tr>
					<th>Short Title</th>
						<td>Group LSTM</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>openaccess.thecvf.com</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="http://openaccess.thecvf.com/content_eccv_2018_workshops/w15/html/Bisagno_Group_LSTM_Group_Trajectory_Prediction_in_Crowded_Scenarios_ECCVW_2018_paper.html">http://openaccess.thecvf.com/content_eccv_2018_workshops/w15/html/Bisagno_Group_LSTM_Group_Trajectory_Prediction_in_Crowded_Scenarios_ECCVW_2018_paper.html</a></td>
					</tr>
					<tr>
					<th>Accessed</th>
						<td>10/29/2019, 2:16:04 PM</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>0-0</td>
					</tr>
					<tr>
					<th>Conference Name</th>
						<td>Proceedings of the European Conference on Computer Vision (ECCV)</td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_8FUSA6V8">Snapshot					</li>
					<li id="item_7AEKQJC9">Full Text PDF					</li>
				</ul>
			</li>


			<li id="item_UC5AVFGC" class="item journalArticle">
			<h2>Human trajectory prediction for automatic guided vehicle with recurrent neural network</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Journal Article</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Chao Song</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Zhixian Chen</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Xiaozhi Qi</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Baoliang Zhao</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Ying Hu</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Shoubin Liu</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Jianwei Zhang</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>The accurate prediction of the pedestrian trajectory is 
necessary to endow automatic guided vehicle with the capabilities to 
adjust velocity and path dynamically for the navigation in real 
pedestrian scenes. For this purpose, this study presents a social 
conscious prediction model considering two main factors that affect the 
pedestrians’ walking in the crowd – relative distance and moving 
direction. To form an effective model, the authors’ conscious pooling 
layer is added to the Long Shot Term Memory network (LTSM) model to 
build the relationship between pedestrians, learning the current 
position m and movement trend. The experiments are conducted to compare 
the proposed model with the previous state-of-the-art model on several 
public datasets. The experimental results show that the proposed model 
predicts pedestrian trajectories more accurately.</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2018</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>IEEE Xplore</td>
					</tr>
					<tr>
					<th>Volume</th>
						<td>2018</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>1574-1578</td>
					</tr>
					<tr>
					<th>Publication</th>
						<td>The Journal of Engineering</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.1049/joe.2018.8264">10.1049/joe.2018.8264</a></td>
					</tr>
					<tr>
					<th>Issue</th>
						<td>16</td>
					</tr>
					<tr>
					<th>ISSN</th>
						<td>2051-3305</td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Tags:</h3>
				<ul class="tags">
					<li>human trajectory prediction</li>
					<li>learning (artificial intelligence)</li>
					<li>pedestrians</li>
					<li>recurrent neural nets</li>
					<li>automatic guided vehicle</li>
					<li>automatic guided vehicles</li>
					<li>control engineering computing</li>
					<li>LSTM model</li>
					<li>pedestrian scenes</li>
					<li>pedestrian trajectory</li>
					<li>recurrent neural network</li>
					<li>social conscious prediction model</li>
					<li>trajectory control</li>
				</ul>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_VBBUDPVU">IEEE Xplore Full Text PDF					</li>
					<li id="item_LRVDUXDV">IEEE Xplore Abstract Record					</li>
				</ul>
			</li>


			<li id="item_Z7KPQMJW" class="item conferencePaper">
			<h2>Classifying Group Emotions for Socially-Aware Autonomous Vehicle Navigation</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Conference Paper</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Aniket Bera</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Tanmay Randhavane</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Austin Wang</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Dinesh Manocha</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Emily Kubin</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Kurt Gray</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2018</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>openaccess.thecvf.com</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="http://openaccess.thecvf.com/content_cvpr_2018_workshops/w14/html/Bera_Classifying_Group_Emotions_CVPR_2018_paper.html">http://openaccess.thecvf.com/content_cvpr_2018_workshops/w14/html/Bera_Classifying_Group_Emotions_CVPR_2018_paper.html</a></td>
					</tr>
					<tr>
					<th>Accessed</th>
						<td>11/4/2019, 11:05:22 AM</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>1039-1047</td>
					</tr>
					<tr>
					<th>Conference Name</th>
						<td>Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops</td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_T7VSDIUV">Full Text PDF					</li>
					<li id="item_AABDLM84">Snapshot					</li>
				</ul>
			</li>


			<li id="item_BWGM8Q2L" class="item journalArticle">
			<h2>Socially Aware Robot Navigation Using the Collision Prediction Based Pedestrian Model</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Journal Article</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Hatice Kose</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Furkan Çakmak</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>Socially Aware Robot Navigation Using the Collision Prediction Based
Pedestrian Model</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2018</td>
					</tr>
					<tr>
					<th>Language</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>Zotero</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>5</td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_UUGT75ZS">Kose and Çakmak - 2018 - 10 PUBLICATIONS 54 CITATIONS SEE PROFILE.pdf					</li>
				</ul>
			</li>


			<li id="item_7DF8IGAE" class="item conferencePaper">
			<h2>Socially-Aware Navigation Using Topological Maps and Social Norm Learning</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Conference Paper</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Collin Johnson</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Benjamin Kuipers</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>We present socially-aware navigation for an intelligent robot 
wheelchair in an environment with many pedestrians. The robot learns 
social norms by observing the behaviors of human pedestrians, 
interpreting detected biases as social norms, and incorporating those 
norms into its motion planning. We compare our socially-aware motion 
planner with a baseline motion planner that produces safe, 
collision-free motion.</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2018</td>
					</tr>
					<tr>
					<th>Language</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>DOI.org (Crossref)</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="http://dl.acm.org/citation.cfm?doid=3278721.3278772">http://dl.acm.org/citation.cfm?doid=3278721.3278772</a></td>
					</tr>
					<tr>
					<th>Accessed</th>
						<td>11/4/2019, 11:15:20 AM</td>
					</tr>
					<tr>
					<th>Place</th>
						<td>New Orleans, LA, USA</td>
					</tr>
					<tr>
					<th>Publisher</th>
						<td>ACM Press</td>
					</tr>
					<tr>
					<th>ISBN</th>
						<td>978-1-4503-6012-8</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>151-157</td>
					</tr>
					<tr>
					<th>Proceedings Title</th>
						<td>Proceedings of the 2018 AAAI/ACM Conference on AI, Ethics, and Society  - AIES '18</td>
					</tr>
					<tr>
					<th>Conference Name</th>
						<td>the 2018 AAAI/ACM Conference</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.1145/3278721.3278772">10.1145/3278721.3278772</a></td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_BZCFCDIW">Johnson and Kuipers - 2018 - Socially-Aware Navigation Using Topological Maps a.pdf					</li>
				</ul>
			</li>


			<li id="item_DTYUIW3S" class="item conferencePaper">
			<h2>Social Momentum: A Framework for Legible Navigation in Dynamic Multi-Agent Environments</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Conference Paper</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Christoforos I. Mavrogiannis</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Wil B. Thomason</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Ross A. Knepper</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>Intent-expressive robot motion has been shown to result in 
increased efficiency and reduced planning efforts for copresent humans. 
Existing frameworks for generating intent-expressive robot behaviors 
have typically focused on applications in static or structured 
environments. Under such settings, emphasis is placed towards 
communicating the robot’s intended final configuration to other agents. 
However, in dynamic, unstructured and multiagent domains, such as 
pedestrian environments, knowledge of the robot’s final configuration is
 not sufficiently informative as it completely ignores the complex 
dynamics of interaction among agents. To address this problem, we design
 a planning framework that aims at generating motion that clearly 
communicates an agent’s intended collision avoidance strategy rather 
than its destination. Our framework estimates the most likely intended 
avoidance protocols of others based on their past behaviors, 
superimposes them, and generates an expressive and socially compliant 
robot action that reinforces the expectations of others regarding these 
avoidance protocols. This action facilitates inference and decision 
making for everyone, as illustrated in the simplified topological 
pattern of agents’ trajectories. Extensive simulations demonstrate that 
our framework consistently achieves significantly lower topological 
complexity, compared against common benchmark approaches in multi-agent 
collision avoidance. The significance of this result for real world 
applications is demonstrated by a user study that reveals statistical 
evidence suggesting that multi-agent trajectories of lower topological 
complexity tend to facilitate inference for observers.</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2018</td>
					</tr>
					<tr>
					<th>Language</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Short Title</th>
						<td>Social Momentum</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>DOI.org (Crossref)</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="http://dl.acm.org/citation.cfm?doid=3171221.3171255">http://dl.acm.org/citation.cfm?doid=3171221.3171255</a></td>
					</tr>
					<tr>
					<th>Accessed</th>
						<td>11/4/2019, 11:40:14 AM</td>
					</tr>
					<tr>
					<th>Place</th>
						<td>Chicago, IL, USA</td>
					</tr>
					<tr>
					<th>Publisher</th>
						<td>ACM Press</td>
					</tr>
					<tr>
					<th>ISBN</th>
						<td>978-1-4503-4953-6</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>361-369</td>
					</tr>
					<tr>
					<th>Proceedings Title</th>
						<td>Proceedings of the 2018 ACM/IEEE International Conference on Human-Robot Interaction - HRI '18</td>
					</tr>
					<tr>
					<th>Conference Name</th>
						<td>the 2018 ACM/IEEE International Conference</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.1145/3171221.3171255">10.1145/3171221.3171255</a></td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_4EADYVED">Mavrogiannis et al. - 2018 - Social Momentum A Framework for Legible Navigatio.pdf					</li>
				</ul>
			</li>


			<li id="item_4TURHWZD" class="item conferencePaper">
			<h2>Cloud-based multimodal human-robot interaction simulator utilizing ROS and unity frameworks</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Conference Paper</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Yoshiaki Mizuchi</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Tetsunari Inamura</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>A new software architecture for a simulator of human-robot 
interaction (HRI) in virtual reality (VR) environments is proposed. 
Since collecting and storing a massive amount of data concerning 
multimodal interaction experiences is an important task concerning 
research on HRI, a cloud-based VR platform, named “SIGVerse,” which 
reduces costs of developing real robots and interaction experiments in 
the real world, is proposed. The reusability of virtual robot software 
is restricted in a real environment due to difference between VR and 
real robot architectures; therefore, a new architecture utilizing the 
Unity and ROS frameworks is proposed. The proposed architecture provides
 functionalities for constructing scalable 3D environments, embodied and
 social interaction via the Internet, compatible robot software, 
highﬁdelity sensor feedback, and recording/playback of interaction. To 
demonstrate the feasibility of the proposed architecture, the 
performance of SIGVerse in terms of simulating of multimodal information
 in actual interaction applications was evaluated, and the latency 
between avatars synchronized via cloud computing was measured. 
Additionally, interactive behaviors of robots and avatars in a VR 
environment and a real environment were experimentally compared, and the
 comparison results conﬁrm that the VR behaviors of robots and avatars 
were almost the same as the behavior of a robot in a real environment.</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>12/2017</td>
					</tr>
					<tr>
					<th>Language</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>DOI.org (Crossref)</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="http://ieeexplore.ieee.org/document/8279345/">http://ieeexplore.ieee.org/document/8279345/</a></td>
					</tr>
					<tr>
					<th>Accessed</th>
						<td>1/11/2021, 10:54:31 AM</td>
					</tr>
					<tr>
					<th>Place</th>
						<td>Taipei</td>
					</tr>
					<tr>
					<th>Publisher</th>
						<td>IEEE</td>
					</tr>
					<tr>
					<th>ISBN</th>
						<td>978-1-5386-2263-6</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>948-955</td>
					</tr>
					<tr>
					<th>Proceedings Title</th>
						<td>2017 IEEE/SICE International Symposium on System Integration (SII)</td>
					</tr>
					<tr>
					<th>Conference Name</th>
						<td>2017 IEEE/SICE International Symposium on System Integration (SII)</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.1109/SII.2017.8279345">10.1109/SII.2017.8279345</a></td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_4KA3RSDE">Mizuchi and Inamura - 2017 - Cloud-based multimodal human-robot interaction sim.pdf					</li>
				</ul>
			</li>


			<li id="item_8MMMDIXW" class="item conferencePaper">
			<h2>Exploring Proxemics for Human-Drone Interaction</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Conference Paper</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Alexander Yeh</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Photchara Ratsamee</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Kiyoshi Kiyokawa</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Yuki Uranishi</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Tomohiro Mashita</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Haruo Takemura</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Morten Fjeld</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Mohammad Obaid</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>We present a human-centered designed social drone aiming to be
 used in a human crowd environment. Based on design studies and focus 
groups, we created a prototype of a social drone with a social shape, 
face and voice for human interaction. We used the prototype for a 
proxemic study, comparing the required distance from the drone humans 
could comfortably accept compared with what they would require for a 
nonsocial drone. The social shaped design with greeting voice added 
decreased the acceptable distance markedly, as did present or previous 
pet ownership, and maleness. We also explored the proximity sphere 
around humans with a social shaped drone based on a validation study 
with variation of lateral distance and heights. Both lateral distance 
and the higher height of 1.8 m compared to the lower height of 1.2 m 
decreased the required comfortable distance as it approached.</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2017-10-27</td>
					</tr>
					<tr>
					<th>Language</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>DOI.org (Crossref)</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://dl.acm.org/doi/10.1145/3125739.3125773">https://dl.acm.org/doi/10.1145/3125739.3125773</a></td>
					</tr>
					<tr>
					<th>Accessed</th>
						<td>11/30/2021, 3:34:52 PM</td>
					</tr>
					<tr>
					<th>Place</th>
						<td>Bielefeld Germany</td>
					</tr>
					<tr>
					<th>Publisher</th>
						<td>ACM</td>
					</tr>
					<tr>
					<th>ISBN</th>
						<td>978-1-4503-5113-3</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>81-88</td>
					</tr>
					<tr>
					<th>Proceedings Title</th>
						<td>Proceedings of the 5th International Conference on Human Agent Interaction</td>
					</tr>
					<tr>
					<th>Conference Name</th>
						<td>HAI '17: The Fifth International Conference on Human-Agent Interaction</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.1145/3125739.3125773">10.1145/3125739.3125773</a></td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_M35XS6KJ">Yeh et al. - 2017 - Exploring Proxemics for Human-Drone Interaction.pdf					</li>
				</ul>
			</li>


			<li id="item_2VZQMUME" class="item journalArticle">
			<h2>Socially aware robot navigation system in human interactive environments</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Journal Article</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Xuan-Tung Truong</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Voo Nyuk Yoong</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Trung-Dung Ngo</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>In social environments, humans mostly stay in social 
interactive groups with their daily activities. A mobile service robot 
must be aware of not only human individuals but also social interactive 
groups, and then behave safely and socially (politely and, respectively)
 in human interactive environments. In this paper, we propose a social 
reactive control (SRC) that enables a mobile service robot to navigate 
safely and socially in the human interactive environments. The SRC is 
derived by incorporating both states of individuals (position, 
orientation, motion, and human field of view) and social interactive 
groups (group’s types, group’s centre, group’s radius, and group’s 
velocity) into the conventional social force model . The SRC can be 
combined with a conventional path planning technique to generate a 
socially aware robot navigation system that is capable of controlling 
mobile service robots to traverse with socially acceptable behaviours. 
We validate the effectiveness of the proposed social reactive control 
through a series of real-world experiments.</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2017-10-01</td>
					</tr>
					<tr>
					<th>Language</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>Springer Link</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://doi.org/10.1007/s11370-017-0232-y">https://doi.org/10.1007/s11370-017-0232-y</a></td>
					</tr>
					<tr>
					<th>Accessed</th>
						<td>11/4/2019, 10:57:03 AM</td>
					</tr>
					<tr>
					<th>Volume</th>
						<td>10</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>287-295</td>
					</tr>
					<tr>
					<th>Publication</th>
						<td>Intelligent Service Robotics</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.1007/s11370-017-0232-y">10.1007/s11370-017-0232-y</a></td>
					</tr>
					<tr>
					<th>Issue</th>
						<td>4</td>
					</tr>
					<tr>
					<th>Journal Abbr</th>
						<td>Intel Serv Robotics</td>
					</tr>
					<tr>
					<th>ISSN</th>
						<td>1861-2784</td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Tags:</h3>
				<ul class="tags">
					<li>Socially aware robot navigation</li>
					<li>Human comfort and safety</li>
					<li>Social interactive environments</li>
					<li>Social reactive control</li>
					<li>Social service robot</li>
				</ul>
				<h3 class="notes">Notes:</h3>
				<ul class="notes">
					<li id="item_EHKL5GMA">
<div><p>Same as above</p></div>
					</li>
				</ul>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_Q76RVELX">Truong et al. - 2017 - Socially aware robot navigation system in human in.pdf					</li>
				</ul>
			</li>


			<li id="item_6K83GHIK" class="item journalArticle">
			<h2>Toward Socially Aware Robot Navigation in Dynamic and Crowded Environments: A Proactive Social Motion Model</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Journal Article</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Xuan-Tung Truong</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Trung Dung Ngo</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>Safe and social navigation is the key to deploying a mobile 
service robot in a human-centered environment. Widespread acceptability 
of mobile service robots in daily life is hindered by robot's inability 
to navigate in crowded and dynamic human environments in a socially 
acceptable way that would guarantee human safety and comfort. In this 
paper, we propose an effective proactive social motion model (PSMM) that
 enables a mobile service robot to navigate safely and socially in 
crowded and dynamic environments. The proposed method considers not only
 human states (position, orientation, motion, field of view, and hand 
poses) relative to the robot but also social interactive information 
about human-object and human group interactions. This allows development
 of the PSMM that consists of elements of an extended social force model
 and a hybrid reciprocal velocity obstacle technique. The PSMM is then 
combined with a path planning technique to generate a motion planning 
system that drives a mobile robot in a socially acceptable manner and 
produces respectful and polite behaviors akin to human movements. Note 
to Practitioners-In this paper, we validated the effectiveness and 
feasibility of the proposed proactive social motion model (PSMM) through
 both simulation and real-world experiments under the newly proposed 
human comfortable safety indices. To do that, we first implemented the 
entire navigation system using the open-source robot operating system. 
We then installed it in a simulated robot model and conducted 
experiments in a simulated shopping mall-like environment to verify its 
effectiveness. We also installed the proposed algorithm on our mobile 
robot platform and conducted experiments in our office-like laboratory 
environment. Our results show that the developed socially aware 
navigation framework allows a mobile robot to navigate safely, socially,
 and proactively while guaranteeing human safety and comfort in crowded 
and dynamic environments. In this paper, we examined the proposed PSMM 
with a set of predefined parameters selected based on our empirical 
experiences about the robot mechanism and selected social environment. 
However, in fact a mobile robot might need to adapt to various 
contextual and cultural situations in different social environments. 
Thus, it should be equipped with an online adaptive interactive learning
 mechanism allowing the robot to learn to auto-adjust their parameters 
according to such embedded environments. Using machine learning 
techniques, e.g., inverse reinforcement learning [1] to optimize the 
parameter set for the PSMM could be a promising research direction to 
improve adaptability of mobile service robots in different social 
environments. In the future, we will evaluate the proposed framework 
based on a wider variety of scenarios, particularly those with different
 social interaction situations and dynamic environments. Furthermore, 
various kinds of social cues and signals introduced in [2] and [3] will 
be applied to extend the proposed framework in more complicated social 
situations and contexts. Last but not least, we will investigate 
different machine learning techniques and incorporate them in the PSMM 
in order to allow the robot to automatically adapt to diverse social 
environments.</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>October 2017</td>
					</tr>
					<tr>
					<th>Short Title</th>
						<td>Toward Socially Aware Robot Navigation in Dynamic and Crowded Environments</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>IEEE Xplore</td>
					</tr>
					<tr>
					<th>Volume</th>
						<td>14</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>1743-1760</td>
					</tr>
					<tr>
					<th>Publication</th>
						<td>IEEE Transactions on Automation Science and Engineering</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.1109/TASE.2017.2731371">10.1109/TASE.2017.2731371</a></td>
					</tr>
					<tr>
					<th>Issue</th>
						<td>4</td>
					</tr>
					<tr>
					<th>ISSN</th>
						<td>1545-5955, 1558-3783</td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Tags:</h3>
				<ul class="tags">
					<li>learning (artificial intelligence)</li>
					<li>collision avoidance</li>
					<li>Collision avoidance</li>
					<li>mobile robots</li>
					<li>Navigation</li>
					<li>learning systems</li>
					<li>Mobile robots</li>
					<li>human-robot interaction</li>
					<li>service robots</li>
					<li>navigation</li>
					<li>crowded environments</li>
					<li>adaptive control</li>
					<li>complicated social situations</li>
					<li>developed socially aware navigation framework</li>
					<li>diverse social environments</li>
					<li>dynamic environments</li>
					<li>dynamic human environments</li>
					<li>extended social force model</li>
					<li>Human comfortable safety</li>
					<li>human comfortable safety indices</li>
					<li>human group interactions</li>
					<li>human movements</li>
					<li>human safety</li>
					<li>human states</li>
					<li>human-centered environment</li>
					<li>human-object interaction</li>
					<li>inverse reinforcement learning</li>
					<li>machine learning techniques</li>
					<li>Mobile communication</li>
					<li>mobile robot platform</li>
					<li>mobile service robot</li>
					<li>mobile service robots</li>
					<li>motion planning system</li>
					<li>navigation system</li>
					<li>office-like laboratory environment</li>
					<li>online adaptive interactive learning mechanism</li>
					<li>open-source robot operating system</li>
					<li>optimisation</li>
					<li>parameter autoadjustment</li>
					<li>parameter optimization</li>
					<li>path planning technique</li>
					<li>proactive social motion model</li>
					<li>proactive social motion model (PSMM)</li>
					<li>PSMM</li>
					<li>robot mechanism</li>
					<li>Safety</li>
					<li>self-adjusting systems</li>
					<li>Service robots</li>
					<li>simulated robot model</li>
					<li>simulated shopping mall-like environment</li>
					<li>social cues</li>
					<li>social environment</li>
					<li>social environments</li>
					<li>social interaction</li>
					<li>social interactive information</li>
					<li>social navigation</li>
					<li>social robots</li>
					<li>socially acceptable manner</li>
					<li>socially aware robot navigation</li>
				</ul>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_QLVEYDQW">IEEE Xplore Abstract Record					</li>
					<li id="item_MRLQTBJ3">Truong and Ngo - 2017 - Toward Socially Aware Robot Navigation in Dynamic .pdf					</li>
				</ul>
			</li>


			<li id="item_DF9LHQ7M" class="item conferencePaper">
			<h2>Aerial social force model: A new framework to accompany people using autonomous flying robots</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Conference Paper</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>A. Garrell</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Luis Garza-Elizondo</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>M. Villamizar</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>F. Herrero</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>A. Sanfeliu</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>In this paper, we propose a novel Aerial Social Force Model 
(ASFM) that allows autonomous ﬂying robots to accompany humans in urban 
environments in a safe and comfortable manner. To date, we are not aware
 of other stateof-the-art method that accomplish this task. The proposed
 approach is a 3D version of the Social Force Model (SFM) for the ﬁeld 
of aerial robots which includes an interactive human-robot navigation 
scheme capable of predicting human motions and intentions so as to 
safely accompany them to their ﬁnal destination. ASFM also introduces a 
new metric to ﬁnetune the parameters of the force model, and to evaluate
 the performance of the aerial robot companion based on comfort and 
distance between the robot and humans. The presented approach is 
extensively validated in diverse simulations and real experiments, and 
compared against other similar works in the literature. ASFM attains 
remarkable results and shows that it is a valuable framework for social 
robotics applications, such as guiding people or human-robot 
interaction.</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>9/2017</td>
					</tr>
					<tr>
					<th>Language</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Short Title</th>
						<td>Aerial social force model</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>DOI.org (Crossref)</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="http://ieeexplore.ieee.org/document/8206627/">http://ieeexplore.ieee.org/document/8206627/</a></td>
					</tr>
					<tr>
					<th>Accessed</th>
						<td>4/1/2021, 10:00:58 AM</td>
					</tr>
					<tr>
					<th>Place</th>
						<td>Vancouver, BC</td>
					</tr>
					<tr>
					<th>Publisher</th>
						<td>IEEE</td>
					</tr>
					<tr>
					<th>ISBN</th>
						<td>978-1-5386-2682-5</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>7011-7017</td>
					</tr>
					<tr>
					<th>Proceedings Title</th>
						<td>2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</td>
					</tr>
					<tr>
					<th>Conference Name</th>
						<td>2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.1109/IROS.2017.8206627">10.1109/IROS.2017.8206627</a></td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_UCTRMJG6">Garrell et al. - 2017 - Aerial social force model A new framework to acco.pdf					</li>
				</ul>
			</li>


			<li id="item_Z4BPWSZ6" class="item conferencePaper">
			<h2>Assessing the social criteria for human-robot collaborative navigation: A comparison of human-aware navigation planners</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Conference Paper</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Harmish Khambhaita</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Rachid Alami</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>This paper focuses on requirements for effective human robot 
collaboration in interactive navigation scenarios. We designed several 
use-cases where humans and robot had to move in the same environment 
that resemble canonical path-crossing situations. These use-cases 
include open as well as constrained spaces. Three different 
state-of-the-art humanaware navigation planners were used for planning 
the robot paths during all selected use-cases. We compare results of 
simulation experiments with these human-aware planners in terms of 
quality of generated trajectories together with discussion on 
capabilities and limitations of the planners. The results show that the 
human-robot collaborative planner [1] performs better in everyday 
path-crossing conﬁgurations. This suggests that the criteria used by the
 human-robot collaborative planner (safety, time-to-collision, 
directional-costs) are possible good measures for designing acceptable 
human-aware navigation planners. Consequently, we analyze the effects of
 these social criteria and draw perspectives on future evolution of 
human-aware navigation planning methods.</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>8/2017</td>
					</tr>
					<tr>
					<th>Language</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Short Title</th>
						<td>Assessing the social criteria for human-robot collaborative navigation</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>Crossref</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="http://ieeexplore.ieee.org/document/8172447/">http://ieeexplore.ieee.org/document/8172447/</a></td>
					</tr>
					<tr>
					<th>Accessed</th>
						<td>4/2/2019, 4:51:06 PM</td>
					</tr>
					<tr>
					<th>Place</th>
						<td>Lisbon</td>
					</tr>
					<tr>
					<th>Publisher</th>
						<td>IEEE</td>
					</tr>
					<tr>
					<th>ISBN</th>
						<td>978-1-5386-3518-6</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>1140-1145</td>
					</tr>
					<tr>
					<th>Proceedings Title</th>
						<td>2017 26th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN)</td>
					</tr>
					<tr>
					<th>Conference Name</th>
						<td>2017 26th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN)</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.1109/ROMAN.2017.8172447">10.1109/ROMAN.2017.8172447</a></td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_4KVPE424">Khambhaita and Alami - 2017 - Assessing the social criteria for human-robot coll.pdf					</li>
				</ul>
			</li>


			<li id="item_WVP5N37T" class="item conferencePaper">
			<h2>Socially acceptable robot navigation over groups of people</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Conference Paper</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Araceli Vega-Magro</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Luis Manso</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Pablo Bustos</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Pedro Nunez</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Douglas G. Macharet</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>Considering the widespread use of mobile robots in different 
parts of society, it is important to provide them with the capability to
 behave in a socially acceptable manner. Therefore, a research topic of 
great importance recently has been the study of Human-Robot Interaction.
 Autonomous navigation is a fundamental task in Robotics, and several 
different strategies that produce paths that are either length or time 
optimized can be found in the literature. However, considering the 
recent use of mobile robots in a more social context, the use of such 
classical techniques is restricted. Therefore, in this article we 
present a social navigation approach considering environments with 
groups of people. The proposal uses a density function to efﬁciently 
represent groups of people, and modify the navigation architecture in 
order to include the social behaviour of the robot during its motion. 
This architecture is based on the combined use of the Probabilistic Road
 Mapping (PRM) and the Rapidlyexploring Random Tree (RRT) path planners 
and an adaptation of the elastic band algorithm. Experimental evaluation
 was carried out in different simulated environments, providing insight 
on the performance of the proposed technique, which surpasses classical 
techniques with no proxemics awareness in terms of social impact.</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>8/2017</td>
					</tr>
					<tr>
					<th>Language</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>DOI.org (Crossref)</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="http://ieeexplore.ieee.org/document/8172454/">http://ieeexplore.ieee.org/document/8172454/</a></td>
					</tr>
					<tr>
					<th>Accessed</th>
						<td>11/4/2019, 11:53:10 AM</td>
					</tr>
					<tr>
					<th>Place</th>
						<td>Lisbon</td>
					</tr>
					<tr>
					<th>Publisher</th>
						<td>IEEE</td>
					</tr>
					<tr>
					<th>ISBN</th>
						<td>978-1-5386-3518-6</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>1182-1187</td>
					</tr>
					<tr>
					<th>Proceedings Title</th>
						<td>2017 26th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN)</td>
					</tr>
					<tr>
					<th>Conference Name</th>
						<td>2017 26th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN)</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.1109/ROMAN.2017.8172454">10.1109/ROMAN.2017.8172454</a></td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_KXKIBHL4">Vega-Magro et al. - 2017 - Socially acceptable robot navigation over groups o.pdf					</li>
				</ul>
			</li>


			<li id="item_B5XYZG55" class="item journalArticle">
			<h2>SocioSense: Robot Navigation Amongst Pedestrians with Social and Psychological Constraints</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Journal Article</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Aniket Bera</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Tanmay Randhavane</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Rohan Prinja</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Dinesh Manocha</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>We present a real-time algorithm, SocioSense, for 
socially-aware navigation of a robot amongst pedestrians. Our approach 
computes time-varying behaviors of each pedestrian using Bayesian 
learning and Personality Trait theory. These psychological 
characteristics are used for long-term path prediction and generating 
proximic characteristics for each pedestrian. We combine these 
psychological constraints with social constraints to perform human-aware
 robot navigation in low- to medium-density crowds. The estimation of 
time-varying behaviors and pedestrian personalities can improve the 
performance of long-term path prediction by 21%, as compared to prior 
interactive path prediction algorithms. We also demonstrate the benefits
 of our socially-aware navigation in simulated environments with tens of
 pedestrians.</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2017-06-04</td>
					</tr>
					<tr>
					<th>Short Title</th>
						<td>SocioSense</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>arXiv.org</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="http://arxiv.org/abs/1706.01102">http://arxiv.org/abs/1706.01102</a></td>
					</tr>
					<tr>
					<th>Accessed</th>
						<td>11/4/2019, 11:34:25 AM</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>arXiv: 1706.01102</td>
					</tr>
					<tr>
					<th>Publication</th>
						<td>arXiv:1706.01102 [cs]</td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Tags:</h3>
				<ul class="tags">
					<li>Computer Science - Robotics</li>
					<li>Computer Science - Multiagent Systems</li>
				</ul>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_P5L9D9E6">arXiv.org Snapshot					</li>
					<li id="item_BCBANPGQ">arXiv Fulltext PDF					</li>
				</ul>
			</li>


			<li id="item_GESYXGXG" class="item journalArticle">
			<h2>Autonomous human–robot proxemics: socially aware navigation based on interaction potential</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Journal Article</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Ross Mead</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Maja J. Matarić</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>To enable situated human–robot interaction (HRI), an 
autonomous robot must both understand and control proxemics—the social 
use of space—to employ natural communication mechanisms analogous to 
those used by humans. This work presents a computational framework of 
proxemics based on data-driven probabilistic models of how social 
signals (speech and gesture) are produced (by a human) and perceived (by
 a robot). The framework and models were implemented as autonomous 
proxemic behavior systems for sociable robots, including: (1) a 
sampling-based method for robot proxemic goal state estimation with 
respect to human–robot distance and orientation parameters, (2) a 
reactive proxemic controller for goal state realization, and (3) a 
cost-based trajectory planner for maximizing automated robot speech and 
gesture recognition rates along a path to the goal state. Evaluation 
results indicate that the goal state estimation and realization 
significantly improve upon past work in human–robot proxemics with 
respect to “interaction potential”—predicted automated speech and 
gesture recognition rates as the robot enters into and engages in 
face-to-face social encounters with a human user—illustrating their 
efficacy to support richer robot perception and autonomy in HRI.</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2017-06-01</td>
					</tr>
					<tr>
					<th>Language</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Short Title</th>
						<td>Autonomous human–robot proxemics</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>Springer Link</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://doi.org/10.1007/s10514-016-9572-2">https://doi.org/10.1007/s10514-016-9572-2</a></td>
					</tr>
					<tr>
					<th>Accessed</th>
						<td>4/4/2019, 10:34:59 AM</td>
					</tr>
					<tr>
					<th>Volume</th>
						<td>41</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>1189-1201</td>
					</tr>
					<tr>
					<th>Publication</th>
						<td>Autonomous Robots</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.1007/s10514-016-9572-2">10.1007/s10514-016-9572-2</a></td>
					</tr>
					<tr>
					<th>Issue</th>
						<td>5</td>
					</tr>
					<tr>
					<th>Journal Abbr</th>
						<td>Auton Robot</td>
					</tr>
					<tr>
					<th>ISSN</th>
						<td>1573-7527</td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Tags:</h3>
				<ul class="tags">
					<li>Proxemics</li>
					<li>Goal state estimation</li>
					<li>Human–robot interaction</li>
					<li>Interaction potential</li>
					<li>Path-planning</li>
					<li>Social signals</li>
				</ul>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_JIJS2SNR">Mead-2016-929.pdf					</li>
				</ul>
			</li>


			<li id="item_N9JFCK2E" class="item journalArticle">
			<h2>Human Trajectory Prediction using Spatially aware Deep Attention Models</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Journal Article</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Daksh Varshneya</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>G. Srinivasaraghavan</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>Trajectory Prediction of dynamic objects is a widely studied 
topic in the field of artificial intelligence. Thanks to a large number 
of applications like predicting abnormal events, navigation system for 
the blind, etc. there have been many approaches to attempt learning 
patterns of motion directly from data using a wide variety of techniques
 ranging from hand-crafted features to sophisticated deep learning 
models for unsupervised feature learning. All these approaches have been
 limited by problems like inefficient features in the case of hand 
crafted features, large error propagation across the predicted 
trajectory and no information of static artefacts around the dynamic 
moving objects. We propose an end to end deep learning model to learn 
the motion patterns of humans using different navigational modes 
directly from data using the much popular sequence to sequence model 
coupled with a soft attention mechanism. We also propose a novel 
approach to model the static artefacts in a scene and using these to 
predict the dynamic trajectories. The proposed method, tested on 
trajectories of pedestrians, consistently outperforms previously 
proposed state of the art approaches on a variety of large scale data 
sets. We also show how our architecture can be naturally extended to 
handle multiple modes of movement (say pedestrians, skaters, bikers and 
buses) simultaneously.</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2017-05-26</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>arXiv.org</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="http://arxiv.org/abs/1705.09436">http://arxiv.org/abs/1705.09436</a></td>
					</tr>
					<tr>
					<th>Accessed</th>
						<td>10/29/2019, 2:15:56 PM</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>arXiv: 1705.09436</td>
					</tr>
					<tr>
					<th>Publication</th>
						<td>arXiv:1705.09436 [cs]</td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Tags:</h3>
				<ul class="tags">
					<li>Computer Science - Artificial Intelligence</li>
					<li>Computer Science - Machine Learning</li>
				</ul>
				<h3 class="notes">Notes:</h3>
				<ul class="notes">
					<li id="item_TQ6GWN5M">
<p class="plaintext">Comment: 10 pages, 5 figures, Submitted to 31st Conference on Neural Information Processing Systems (NIPS 2017)</p>
					</li>
				</ul>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_Q4MREN2F">arXiv Fulltext PDF					</li>
					<li id="item_4F74DYRP">arXiv.org Snapshot					</li>
				</ul>
			</li>


			<li id="item_6KJKBBNJ" class="item journalArticle">
			<h2>Robot social-aware navigation framework to accompany people walking side-by-side</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Journal Article</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Gonzalo Ferrer</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Anaís Garrell Zulueta</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Fernando Herrero Cotarelo</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Alberto Sanfeliu</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>We present a novel robot social-aware navigation framework to 
walk side-by-side with people in crowded urban areas in a safety and 
natural way. The new system includes the following key issues: to 
propose a new robot social-aware navigation model to accompany a person;
 to extend the Social Force Model, “Extended Social-Force Model”, to 
consider the person and robot’s interactions; to use a human predictor 
to estimate the destination of the person the robot is walking with; and
 to interactively learning the parameters of the social-aware navigation
 model using multimodal human feedback. Finally, a quantitative metric 
based on people’s personal spaces and comfortableness criteria, is 
introduced in order to evaluate quantitatively the performance of the 
robot’s task. The validation of the model is accomplished throughout an 
extensive set of simulations and real-life experiments. In addition, a 
volunteers’ survey is used to measure the acceptability of our robot 
companion’s behavior.</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2017-04-01</td>
					</tr>
					<tr>
					<th>Language</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>Springer Link</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://doi.org/10.1007/s10514-016-9584-y">https://doi.org/10.1007/s10514-016-9584-y</a></td>
					</tr>
					<tr>
					<th>Accessed</th>
						<td>4/4/2019, 3:04:04 PM</td>
					</tr>
					<tr>
					<th>Volume</th>
						<td>41</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>775-793</td>
					</tr>
					<tr>
					<th>Publication</th>
						<td>Autonomous Robots</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.1007/s10514-016-9584-y">10.1007/s10514-016-9584-y</a></td>
					</tr>
					<tr>
					<th>Issue</th>
						<td>4</td>
					</tr>
					<tr>
					<th>Journal Abbr</th>
						<td>Auton Robot</td>
					</tr>
					<tr>
					<th>ISSN</th>
						<td>1573-7527</td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Tags:</h3>
				<ul class="tags">
					<li>Service robots</li>
					<li>Human–robot interaction</li>
					<li>Robot companion</li>
					<li>Urban robot navigation</li>
				</ul>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_F9AWJAYH">Submitted Version					</li>
				</ul>
			</li>


			<li id="item_RDMM7GMW" class="item journalArticle">
			<h2>Socially Aware Motion Planning with Deep Reinforcement Learning</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Journal Article</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Yu Fan Chen</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Michael Everett</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Miao Liu</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Jonathan P. How</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>For robotic vehicles to navigate safely and efﬁciently in 
pedestrian-rich environments, it is important to model subtle human 
behaviors and navigation rules (e.g., passing on the right). However, 
while instinctive to humans, socially compliant navigation is still 
difﬁcult to quantify due to the stochasticity in people’s behaviors. 
Existing works are mostly focused on using feature-matching techniques 
to describe and imitate human paths, but often do not generalize well 
since the feature values can vary from person to person, and even run to
 run. This work notes that while it is challenging to directly specify 
the details of what to do (precise mechanisms of human navigation), it 
is straightforward to specify what not to do (violations of social 
norms). Speciﬁcally, using deep reinforcement learning, this work 
develops a time-efﬁcient navigation policy that respects common social 
norms. The proposed method is shown to enable fully autonomous 
navigation of a robotic vehicle moving at human walking speed in an 
environment with many pedestrians.</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2017-03-26</td>
					</tr>
					<tr>
					<th>Language</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>arXiv.org</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="http://arxiv.org/abs/1703.08862">http://arxiv.org/abs/1703.08862</a></td>
					</tr>
					<tr>
					<th>Accessed</th>
						<td>4/2/2019, 4:49:49 PM</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>arXiv: 1703.08862</td>
					</tr>
					<tr>
					<th>Publication</th>
						<td>arXiv:1703.08862 [cs]</td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Tags:</h3>
				<ul class="tags">
					<li>Computer Science - Artificial Intelligence</li>
					<li>Computer Science - Robotics</li>
					<li>Computer Science - Human-Computer Interaction</li>
				</ul>
				<h3 class="notes">Notes:</h3>
				<ul class="notes">
					<li id="item_VBIZTT2L">
<p class="plaintext">Comment: 8 pages</p>
					</li>
				</ul>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_LGF387CF">Chen et al. - 2017 - Socially Aware Motion Planning with Deep Reinforce.pdf					</li>
				</ul>
			</li>


			<li id="item_7N3VSRQJ" class="item bookSection">
			<h2>Chapter 9 - Learning to Predict Human Behavior in Crowded Scenes</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Book Section</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Alexandre Alahi</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Vignesh Ramanathan</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Kratarth Goel</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Alexandre Robicquet</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Amir A. Sadeghian</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Li Fei-Fei</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Silvio Savarese</td>
					</tr>
					<tr>
						<th class="editor">Editor</th>
						<td>Vittorio Murino</td>
					</tr>
					<tr>
						<th class="editor">Editor</th>
						<td>Marco Cristani</td>
					</tr>
					<tr>
						<th class="editor">Editor</th>
						<td>Shishir Shah</td>
					</tr>
					<tr>
						<th class="editor">Editor</th>
						<td>Silvio Savarese</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>Pedestrians follow different trajectories to avoid obstacles 
and accommodate fellow pedestrians. Any autonomous vehicle navigating 
such a scene should be able to foresee the future positions of 
pedestrians and accordingly adjust its path to avoid collisions. This 
problem of trajectory prediction can be viewed as a sequence generation 
task, where we are interested in predicting the future trajectory of 
people based on their past positions. Following the recent success of 
Recurrent Neural Network (RNN) models for sequence prediction tasks, we 
propose an LSTM model which can learn general human movement and predict
 their future trajectories. This is in contrast to traditional 
approaches which use hand-crafted functions such as Social Forces. We 
demonstrate the performance of our method on several public datasets. 
Our model outperforms state-of-the-art methods on some of these 
datasets. We also analyze the trajectories predicted by our model to 
demonstrate the motion behavior learned by our model. Moreover, we 
introduce a new characterization that describes the “social sensitivity”
 at which two targets interact. We use this characterization to define 
“navigation styles” and improve both forecasting models and 
state-of-the-art multi-target tracking – whereby the learned forecasting
 models help the data association step.</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>January 1, 2017</td>
					</tr>
					<tr>
					<th>Language</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>ScienceDirect</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="http://www.sciencedirect.com/science/article/pii/B9780128092767000114">http://www.sciencedirect.com/science/article/pii/B9780128092767000114</a></td>
					</tr>
					<tr>
					<th>Accessed</th>
						<td>10/29/2019, 2:16:13 PM</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>DOI: 10.1016/B978-0-12-809276-7.00011-4</td>
					</tr>
					<tr>
					<th>Publisher</th>
						<td>Academic Press</td>
					</tr>
					<tr>
					<th>ISBN</th>
						<td>978-0-12-809276-7</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>183-207</td>
					</tr>
					<tr>
					<th>Book Title</th>
						<td>Group and Crowd Behavior for Computer Vision</td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Tags:</h3>
				<ul class="tags">
					<li>Human interaction</li>
					<li>Social forces</li>
					<li>Social LSTM</li>
					<li>Social sensitivity</li>
					<li>Trajectory prediction</li>
				</ul>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_X246PULN">ScienceDirect Snapshot					</li>
					<li id="item_4INL3NAD">Submitted Version					</li>
				</ul>
			</li>


			<li id="item_8CW6Q27Z" class="item conferencePaper">
			<h2>Robot’s Workspace Enhancement with Dynamic Human Presence for Socially-Aware Navigation</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Conference Paper</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Ioannis Kostavelis</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Andreas Kargakos</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Dimitrios Giakoumis</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Dimitrios Tzovaras</td>
					</tr>
					<tr>
						<th class="editor">Editor</th>
						<td>Ming Liu</td>
					</tr>
					<tr>
						<th class="editor">Editor</th>
						<td>Haoyao Chen</td>
					</tr>
					<tr>
						<th class="editor">Editor</th>
						<td>Markus Vincze</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>The incorporation of service robots in human populated 
environments gives rise to the adaptation of cruise strategies that 
allow robots to move in a natural, secure and ordinary manner among 
their cohabitants. Therefore, robots should firstly apprehend their 
space similarly with the people and, secondly, should adopt human motion
 anticipation strategies in their planning mechanism. The paper at hand 
introduces a closed-loop human oriented robot navigation strategy, where
 on-board a moving robot, multimodal human detection and tracking 
methods are deployed to predict human motion intention in the shared 
workspace. The human occupied space is probabilistically constrained 
following the proxemics theory. The impact of human presence in the 
commonly shared space is imprinted to the robot’s navigation behaviour 
after undergoing a social filtering step based on the inferred walking 
pattern. The proposed method has been integrated with a robotic platform
 and extensively evaluated in terms of socially acceptable behaviour in 
real-life experiments exhibiting increased navigation capacity in human 
populated environments.</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2017</td>
					</tr>
					<tr>
					<th>Language</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>Springer Link</td>
					</tr>
					<tr>
					<th>Place</th>
						<td>Cham</td>
					</tr>
					<tr>
					<th>Publisher</th>
						<td>Springer International Publishing</td>
					</tr>
					<tr>
					<th>ISBN</th>
						<td>978-3-319-68345-4</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>279-288</td>
					</tr>
					<tr>
					<th>Series</th>
						<td>Lecture Notes in Computer Science</td>
					</tr>
					<tr>
					<th>Proceedings Title</th>
						<td>Computer Vision Systems</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.1007/978-3-319-68345-4_25">10.1007/978-3-319-68345-4_25</a></td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Tags:</h3>
				<ul class="tags">
					<li>Human motion intension prediction</li>
					<li>Leg and human skeleton tracker</li>
					<li>Robot navigation</li>
					<li>Robot path planning</li>
					<li>Social costmap</li>
				</ul>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_CPVWNXN7">Springer Full Text PDF					</li>
				</ul>
			</li>


			<li id="item_Z6CY49KW" class="item journalArticle">
			<h2>Robot navigation in large-scale social maps: An action recognition approach</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Journal Article</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Konstantinos Charalampous</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Ioannis Kostavelis</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Antonios Gasteratos</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>As robots tend to establish their presence in every day human 
environments the necessity for them to attain socially acceptable 
behavior is a condition sine qua non. Consequently, robots need to learn
 and react appropriately, should they be able to share the same space 
with people and to reconcile their operation to man’s activity. This 
work proposes an integrated robot framework that allows navigation in a 
human populated environment. This is the first work that employs the 
performed actions of individuals so as to re-plan and design a 
collision-free and at the same time a socially acceptable trajectory. 
Expandability is another feature of the suggested mapping module since 
it is capable of incorporating an unconstrained number of actions and 
subsequently responses, according to the needs of the task in hand and 
the environment in which the robot operates. Moreover, the paper 
addresses the integration of the proposed mapping module with the rest 
of the robot framework in order to operate in a seamless fashion. The 
generic design of this architecture allows the replacement of modules 
with other similar ones, thus providing adaptability with respect to the
 environment and so on. The method utilizes off-line constructed 3D 
metric maps organized in terms of a topological graph. During its 
perambulation the robot is ample to detect humans while it exploits deep
 learning strategies to recognize their activities. The memorized 
actions are seamlessly associated with specific rules –deriving from the
 proxemics theory– and are organized in an efficient manner to be 
recalled during robot’s navigation. Moreover, the paper exhibits the 
differences of the robot navigation in inhabited and uninhabited 
environments and demonstrates the alteration of the robot’s trajectory 
with respect to the recognized actions and poses of the individuals. The
 system has been evaluated on a robot able to acquire RGB-D data in 
domestic environments. The human detection and the action recognition 
modules exhibited remarkable performance, the human detection one was 
flawless about its decision while the action recognition one confused 
actions regarding the number of individuals that participate in them. 
Last, the robot navigation component was proved capable of extracting 
safe trajectories in human populated environments.</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>December 30, 2016</td>
					</tr>
					<tr>
					<th>Language</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Short Title</th>
						<td>Robot navigation in large-scale social maps</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>ScienceDirect</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="http://www.sciencedirect.com/science/article/pii/S0957417416305103">http://www.sciencedirect.com/science/article/pii/S0957417416305103</a></td>
					</tr>
					<tr>
					<th>Accessed</th>
						<td>11/4/2019, 11:26:47 AM</td>
					</tr>
					<tr>
					<th>Volume</th>
						<td>66</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>261-273</td>
					</tr>
					<tr>
					<th>Publication</th>
						<td>Expert Systems with Applications</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.1016/j.eswa.2016.09.026">10.1016/j.eswa.2016.09.026</a></td>
					</tr>
					<tr>
					<th>Journal Abbr</th>
						<td>Expert Systems with Applications</td>
					</tr>
					<tr>
					<th>ISSN</th>
						<td>0957-4174</td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Tags:</h3>
				<ul class="tags">
					<li>Proxemics</li>
					<li>Robot navigation</li>
					<li>Action recognition</li>
					<li>Human environments</li>
					<li>Social mapping</li>
				</ul>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_V6WYU7EE">ScienceDirect Full Text PDF					</li>
					<li id="item_D86KMH3V">ScienceDirect Snapshot					</li>
				</ul>
			</li>


			<li id="item_9KRVZBLN" class="item journalArticle">
			<h2>A Review of Social-Aware Navigation Frameworks for Service Robot in Dynamic Human Environments</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Journal Article</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>S. F. Chik</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>C. F. Yeong</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>E. L. M. Su</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>T. Y. Lim</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Y. Subramaniam</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>P. J. H. Chin</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>The emergence of service robot into human daily life in the 
past years has opened up various challenges including human-robot 
interaction, joint-goal achievement and machine learning. Social-aware 
navigation also gains vast research attention in enhancing the social 
capabilities of service robots. Human motions are stochastic and social 
conventions are very complex. Sophisticated approaches are needed for a 
robot to abide to these social rules and perform obstacle avoidance. To 
maintain the level of social comfort and achieve a given task, the robot
 navigation is now no longer a search for a shortest collision-free 
path, but a multi-objective problem that requires a unified social-aware
 navigation framework. A careful selection of navigation components 
including global planner, local planner, the prediction model and a 
suitable robot platform is also required to offer an effective 
navigation amidst the dynamic human environment. Hence, this review 
paper aims to offer insights for service robot implementation by 
highlighting four varieties of navigation frameworks, various navigation
 components and different robot platforms.</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2016/12/01</td>
					</tr>
					<tr>
					<th>Language</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>journal.utem.edu.my</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="http://journal.utem.edu.my/index.php/jtec/article/view/1408">http://journal.utem.edu.my/index.php/jtec/article/view/1408</a></td>
					</tr>
					<tr>
					<th>Accessed</th>
						<td>11/4/2019, 10:38:18 AM</td>
					</tr>
					<tr>
					<th>Rights</th>
						<td>TRANSFER OF COPYRIGHT AGREEMENT   The manuscript is herewith 
submitted for publication in the Journal of Telecommunication, 
Electronic and Computer Engineering (JTEC). It has not been published 
before, and it is not under consideration for publication in any other 
journals. It contains no material that is scandalous, obscene, libelous 
or otherwise contrary to law. When the manuscript is accepted for 
publication, I, as the author, hereby agree to transfer to JTEC, all 
rights including those pertaining to electronic forms and transmissions,
 under existing copyright laws, except for the following, which the 
author(s) specifically retain(s):   All proprietary right other than 
copyright, such as patent rights  The right to make further copies of 
all or part of the published article for my use in classroom teaching  
The right to reuse all or part of this manuscript in a compilation of my
 own works or in a textbook of which I am the author; and  The right to 
make copies of the published work for internal distribution within the 
institution that employs me   I agree that copies made under these 
circumstances will continue to carry the copyright notice that appears 
in the original published work. I agree to inform my co-authors, if any,
 of the above terms. I certify that I have obtained written permission 
for the use of text, tables, and/or illustrations from any copyrighted 
source(s), and I agree to supply such written permission(s) to JTEC upon
 request.</td>
					</tr>
					<tr>
					<th>Volume</th>
						<td>8</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>41-50-50</td>
					</tr>
					<tr>
					<th>Publication</th>
						<td>Journal of Telecommunication, Electronic and Computer Engineering (JTEC)</td>
					</tr>
					<tr>
					<th>Issue</th>
						<td>11</td>
					</tr>
					<tr>
					<th>ISSN</th>
						<td>2289-8131</td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Tags:</h3>
				<ul class="tags">
					<li>Navigation Framework</li>
					<li>Path Planner</li>
					<li>Review</li>
					<li>Social-Aware</li>
				</ul>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_II3YKALW">Snapshot					</li>
					<li id="item_E3WNHQQB">Full Text PDF					</li>
				</ul>
			</li>


			<li id="item_TZMXHGZ7" class="item journalArticle">
			<h2>Social-aware drone navigation using social force model</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Journal Article</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Garza Elizondo</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Luis Alberto</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2016-10-07</td>
					</tr>
					<tr>
					<th>Language</th>
						<td>eng</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>upcommons.upc.edu</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://upcommons.upc.edu/handle/2117/104437">https://upcommons.upc.edu/handle/2117/104437</a></td>
					</tr>
					<tr>
					<th>Accessed</th>
						<td>11/4/2019, 12:52:58 PM</td>
					</tr>
					<tr>
					<th>Rights</th>
						<td>Open Access</td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Tags:</h3>
				<ul class="tags">
					<li>Collision avoidance</li>
					<li>Social navigation</li>
					<li>Àrees temàtiques de la UPC::Informàtica</li>
					<li>Avions no tripulats</li>
					<li>Drone aircraft</li>
					<li>Human-Drone Interaction</li>
					<li>Interacció Humà-Drone</li>
					<li>Navegació Social</li>
					<li>Prevenció de col·lisions</li>
				</ul>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_UMDVMRLR">Snapshot					</li>
					<li id="item_CJTG32R3">Full Text PDF					</li>
				</ul>
			</li>


			<li id="item_ULJ56TJU" class="item conferencePaper">
			<h2>HI Robot: Human intention-aware robot planning for safe and efficient navigation in crowds</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Conference Paper</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Chonhyon Park</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Jan Ondřej</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Max Gilbert</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Kyle Freeman</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Carol O'Sullivan</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>We present an algorithmic framework for the early 
classification of human intentions, and use it to accurately predict 
future human motions when planning the path of a robot in an environment
 that is shared with humans. During an off-line learning phase, a 
classifier that can recognize when a human intends to interact with the 
robot is trained. At runtime, this trained classifier allows us to 
recognize humans who intend to interact with, or obstruct, the robot in 
some way. We validate our approach using both recorded and simulated 
data in an environment in which some humans intentionally obstruct the 
robot. Our classifier identifies these potential blockers, thus allowing
 the robot to safely and efficiently navigate the environment by 
minimizing the chances of being blocked.</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>October 2016</td>
					</tr>
					<tr>
					<th>Short Title</th>
						<td>HI Robot</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>IEEE Xplore</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>ISSN: 2153-0866</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>3320-3326</td>
					</tr>
					<tr>
					<th>Proceedings Title</th>
						<td>2016 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</td>
					</tr>
					<tr>
					<th>Conference Name</th>
						<td>2016 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.1109/IROS.2016.7759511">10.1109/IROS.2016.7759511</a></td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Tags:</h3>
				<ul class="tags">
					<li>Trajectory</li>
					<li>mobile robots</li>
					<li>Navigation</li>
					<li>path planning</li>
					<li>Planning</li>
					<li>Robot sensing systems</li>
					<li>Computational modeling</li>
					<li>Service robots</li>
					<li>HI robot</li>
					<li>human intention-aware robot planning</li>
					<li>off-line learning phase</li>
				</ul>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_NVMFMAEB">IEEE Xplore Abstract Record					</li>
					<li id="item_4SXMPLKI">Park et al. - 2016 - HI Robot Human intention-aware robot planning for.pdf					</li>
				</ul>
			</li>


			<li id="item_V2BXVLNI" class="item conferencePaper">
			<h2>Mobile robot navigation for human-robot social interaction</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Conference Paper</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Pakpoom Patompak</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Sungmoon Jeong</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Nak Young Chong</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Itthisek Nilkhamhang</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>Human social interactions are believed to be described by a 
mathematical model called the Social Force Model (SFM). A variety of 
mobile robot research has often used the SFM to generate an appropriate 
navigation behavior. However, to create a mobile robot that moves around
 in a human-populated environment in a socially acceptable way, it 
should be stressed that the social conventions are strictly obeyed. This
 paper proposes an extended SFM between humans and robots, called the 
Social Relationship Model (SRM), to enable mobile robots to generate 
navigation paths in a human-like manner. Simulation results show notable
 advantages of SRM over the Transition based Rapidly Random Tree (T-RRT)
 path planning algorithm. The proposed method ensures a socially 
acceptable robot path, one of the most important issues for human-robot 
symbiosis.</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>October 2016</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>IEEE Xplore</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>1298-1303</td>
					</tr>
					<tr>
					<th>Proceedings Title</th>
						<td>2016 16th International Conference on Control, Automation and Systems (ICCAS)</td>
					</tr>
					<tr>
					<th>Conference Name</th>
						<td>2016 16th International Conference on Control, Automation and Systems (ICCAS)</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.1109/ICCAS.2016.7832481">10.1109/ICCAS.2016.7832481</a></td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Tags:</h3>
				<ul class="tags">
					<li>Collision avoidance</li>
					<li>mobile robots</li>
					<li>Navigation</li>
					<li>path planning</li>
					<li>Mobile robots</li>
					<li>human-robot interaction</li>
					<li>service robots</li>
					<li>Force</li>
					<li>Mathematical model</li>
					<li>SFM</li>
					<li>social force model</li>
					<li>mobile robot navigation</li>
					<li>trees (mathematics)</li>
					<li>human-populated environment</li>
					<li>human-robot social interaction</li>
					<li>Human-Robot Symbiosis</li>
					<li>Mobile Robot Navigation</li>
					<li>Social Force Model</li>
					<li>social relationship model</li>
					<li>Social Relationship Model</li>
					<li>SRM</li>
					<li>Symbiosis</li>
					<li>T-RRT path planning algorithm</li>
					<li>transition based rapidly random tree</li>
				</ul>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_WD985NU7">IEEE Xplore Abstract Record					</li>
					<li id="item_8DGI2GHI">Patompak et al. - 2016 - Mobile robot navigation for human-robot social int.pdf					</li>
				</ul>
			</li>


			<li id="item_MA48BEF5" class="item conferencePaper">
			<h2>Incorporating perception uncertainty in human-aware navigation: A comparative study</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Conference Paper</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Z. Talebpour</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>D. Viswanathan</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>R. Ventura</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>G. Englebienne</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>A. Martinoli</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>In this work, we present a novel approach to human-aware 
navigation by probabilistically modelling the uncertainty of perception 
for a social robotic system and investigating its effect on the overall 
social navigation performance. The model of the social costmap around a 
person has been extended to consider this new uncertainty factor, which 
has been widely neglected despite playing an important role in 
situations with noisy perception. A social path planner based on the 
fast marching method has been augmented to account for the uncertainty 
in the positions of people. The effectiveness of the proposed approach 
has been tested in extensive experiments carried out with real robots 
and in simulation. Real experiments have been conducted, given noisy 
perception, in the presence of single/multiple, static/dynamic humans. 
Results show how this approach has been able to achieve trajectories 
that are able to keep a more appropriate social distance to the people, 
compared to those of the basic navigation approach, and the human-aware 
navigation approach which relies solely on perfect perception, when the 
complexity of the environment increases. Accounting for uncertainty of 
perception is shown to result in smoother trajectories with lower jerk 
that are more natural from the point of view of humans.</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>August 2016</td>
					</tr>
					<tr>
					<th>Short Title</th>
						<td>Incorporating perception uncertainty in human-aware navigation</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>IEEE Xplore</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>570-577</td>
					</tr>
					<tr>
					<th>Proceedings Title</th>
						<td>2016 25th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN)</td>
					</tr>
					<tr>
					<th>Conference Name</th>
						<td>2016 25th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN)</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.1109/ROMAN.2016.7745175">10.1109/ROMAN.2016.7745175</a></td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Tags:</h3>
				<ul class="tags">
					<li>mobile robots</li>
					<li>Navigation</li>
					<li>path planning</li>
					<li>Robots</li>
					<li>trajectory control</li>
					<li>human-aware navigation</li>
					<li>human-robot interaction</li>
					<li>navigation</li>
					<li>Computational modeling</li>
					<li>Detectors</li>
					<li>dynamic humans</li>
					<li>fast marching method</li>
					<li>noisy perception</li>
					<li>perception uncertainty</li>
					<li>Probabilistic logic</li>
					<li>probabilistic modelling</li>
					<li>probability</li>
					<li>Proposals</li>
					<li>social costmap</li>
					<li>social navigation performance</li>
					<li>social path planner</li>
					<li>social robotic system</li>
					<li>static humans</li>
					<li>trajectories</li>
					<li>uncertain systems</li>
					<li>Uncertainty</li>
					<li>uncertainty factor</li>
				</ul>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_VYFQBHIE">Submitted Version					</li>
					<li id="item_VUTRN8KT">IEEE Xplore Abstract Record					</li>
				</ul>
			</li>


			<li id="item_WJ8FFBGI" class="item conferencePaper">
			<h2>Qualitative constraints for human-aware robot navigation using Velocity Costmaps</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Conference Paper</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Christian Dondrup</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Marc Hanheide</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>In this work, we propose the combination of a state-of-the-art
 sampling-based local planner with so-called Velocity Costmaps to 
achieve human-aware robot navigation. Instead of introducing humans as 
“special obstacles” into the representation of the environment, we 
restrict the sample space of a “Dynamic Window Approach” local planner 
to only allow trajectories based on a qualitative description of the 
future unfolding of the encounter. To achieve this, we use a Bayesian 
temporal model based on a Qualitative Trajectory Calculus to represent 
the mutual navigation intent of human and robot, and translate these 
descriptors into sample space constraints for trajectory generation. We 
show how to learn these models from demonstration and evaluate our 
approach against standard Gaussian cost models in simulation and in 
real-world using a non-holonomic mobile robot. Our experiments show that
 our approach exceeds the performance and safety of the Gaussian models 
in pass-by and path crossing situations.</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>8/2016</td>
					</tr>
					<tr>
					<th>Language</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>DOI.org (Crossref)</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="http://ieeexplore.ieee.org/document/7745177/">http://ieeexplore.ieee.org/document/7745177/</a></td>
					</tr>
					<tr>
					<th>Accessed</th>
						<td>11/4/2019, 11:36:42 AM</td>
					</tr>
					<tr>
					<th>Place</th>
						<td>New York, NY, USA</td>
					</tr>
					<tr>
					<th>Publisher</th>
						<td>IEEE</td>
					</tr>
					<tr>
					<th>ISBN</th>
						<td>978-1-5090-3929-6</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>586-592</td>
					</tr>
					<tr>
					<th>Proceedings Title</th>
						<td>2016 25th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN)</td>
					</tr>
					<tr>
					<th>Conference Name</th>
						<td>2016 25th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN)</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.1109/ROMAN.2016.7745177">10.1109/ROMAN.2016.7745177</a></td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_9KFKJVRK">Dondrup and Hanheide - 2016 - Qualitative constraints for human-aware robot navi.pdf					</li>
				</ul>
			</li>


			<li id="item_RZ5BESB9" class="item journalArticle">
			<h2>Efficient and Robust Pedestrian Detection using Deep Learning for Human-Aware Navigation</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Journal Article</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Andre Mateus</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>David Ribeiro</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Pedro Miraldo</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Jacinto C. Nascimento</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>This paper addresses the problem of Human-Aware Navigation 
(HAN), using multi camera sensors to implement a vision-based person 
tracking system. The main contributions of this paper are as follows: a 
novel and efﬁcient Deep Learning person detection and a standardization 
of human-aware constraints. In the ﬁrst stage of the approach, we 
propose to cascade the Aggregate Channel Features (ACF) detector with a 
deep Convolutional Neural Network (CNN) to achieve fast and accurate 
Pedestrian Detection (PD). Regarding the human awareness (that can be 
deﬁned as constraints associated with the robot’s motion), we use a 
mixture of asymmetric Gaussian functions, to deﬁne the cost functions 
associated to each constraint. Both methods proposed herein are 
evaluated individually to measure the impact of each of the components. 
The ﬁnal solution (including both the proposed pedestrian detection and 
the human-aware constraints) is tested in a typical domestic indoor 
scenario, in four distinct experiments. The results show that the robot 
is able to cope with human-aware constraints, deﬁned after common 
proxemics and social rules.</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2016-07-15</td>
					</tr>
					<tr>
					<th>Language</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>arXiv.org</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="http://arxiv.org/abs/1607.04441">http://arxiv.org/abs/1607.04441</a></td>
					</tr>
					<tr>
					<th>Accessed</th>
						<td>4/2/2019, 4:49:23 PM</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>arXiv: 1607.04441</td>
					</tr>
					<tr>
					<th>Publication</th>
						<td>arXiv:1607.04441 [cs]</td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Tags:</h3>
				<ul class="tags">
					<li>Computer Science - Computer Vision and Pattern Recognition</li>
					<li>Computer Science - Robotics</li>
				</ul>
				<h3 class="notes">Notes:</h3>
				<ul class="notes">
					<li id="item_XBKP7DJE">
<div><p>Comment: Accepted in Robotics and Autonomous Systems</p></div>
					</li>
				</ul>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_5NLJAF3W">Mateus et al. - 2016 - Efficient and Robust Pedestrian Detection using De.pdf					</li>
				</ul>
			</li>


			<li id="item_82P2DXRE" class="item journalArticle">
			<h2>A Real-Time Deep Learning Pedestrian Detector for Robot Navigation</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Journal Article</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>David Ribeiro</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Andre Mateus</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Pedro Miraldo</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Jacinto C. Nascimento</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>A real-time Deep Learning based method for Pedestrian 
Detection (PD) is applied to the Human-Aware robot navigation problem. 
The pedestrian detector combines the Aggregate Channel Features (ACF) 
detector with a deep Convolutional Neural Network (CNN) in order to 
obtain fast and accurate performance. Our solution is ﬁrstly evaluated 
using a set of real images taken from onboard and offboard cameras and, 
then, it is validated in a typical robot navigation environment with 
pedestrians (two distinct experiments are conducted). The results on 
both tests show that our pedestrian detector is robust and fast enough 
to be used on robot navigation applications.</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2016-07-15</td>
					</tr>
					<tr>
					<th>Language</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>arXiv.org</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="http://arxiv.org/abs/1607.04436">http://arxiv.org/abs/1607.04436</a></td>
					</tr>
					<tr>
					<th>Accessed</th>
						<td>4/2/2019, 4:49:20 PM</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>arXiv: 1607.04436</td>
					</tr>
					<tr>
					<th>Publication</th>
						<td>arXiv:1607.04436 [cs]</td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Tags:</h3>
				<ul class="tags">
					<li>Computer Science - Computer Vision and Pattern Recognition</li>
					<li>Computer Science - Robotics</li>
				</ul>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_4PHIAXY7">Ribeiro et al. - 2016 - A Real-Time Deep Learning Pedestrian Detector for .pdf					</li>
				</ul>
			</li>


			<li id="item_BF434DEF" class="item conferencePaper">
			<h2>Towards culturally aware robot navigation</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Conference Paper</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Xuan Tung Truong</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Yong Sheng Ou</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Trung-Dung Ngo</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>When we look towards the world of humans and robots 
harmonically working together in a social environment, the robots should
 behave in cultural norms. A culturally aware robot navigation is highly
 expected to enable mobile service robots to politely and respectfully 
navigate among humans in human-robot shared workspaces. In this paper, 
we present a foundation of culturally aware robot navigation for mobile 
service robots in a social environment. The culturally aware robot 
navigation system is developed by integrating extended personal spaces 
representing individual states and social interaction spaces 
representing human-robot interactions and human groups. The culturally 
aware robot navigation plays the role of human-aware decision making 
upon the conventional robot navigation system to ensure that a mobile 
service robot is capable of detecting and identifying social contexts 
and situations to culturally navigate in human appearances. Simulation 
results illustrate our methodological approach.</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>June 2016</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>IEEE Xplore</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>63-69</td>
					</tr>
					<tr>
					<th>Proceedings Title</th>
						<td>2016 IEEE International Conference on Real-time Computing and Robotics (RCAR)</td>
					</tr>
					<tr>
					<th>Conference Name</th>
						<td>2016 IEEE International Conference on Real-time Computing and Robotics (RCAR)</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.1109/RCAR.2016.7784002">10.1109/RCAR.2016.7784002</a></td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Tags:</h3>
				<ul class="tags">
					<li>mobile robots</li>
					<li>Navigation</li>
					<li>path planning</li>
					<li>Robot kinematics</li>
					<li>Mobile robots</li>
					<li>human-robot interaction</li>
					<li>service robots</li>
					<li>Robot sensing systems</li>
					<li>mobile service robots</li>
					<li>decision making</li>
					<li>Cultural differences</li>
					<li>culturally aware robot navigation</li>
					<li>extended personal spaces</li>
					<li>human-aware decision making</li>
					<li>human-robot interactions</li>
					<li>human-robot shared workspaces</li>
					<li>Social groups</li>
					<li>social interaction spaces</li>
				</ul>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_RTZ7RPKN">IEEE Xplore Abstract Record					</li>
					<li id="item_JME8E7SY">Truong et al. - 2016 - Towards culturally aware robot navigation.pdf					</li>
				</ul>
			</li>


			<li id="item_BIU7TQL8" class="item conferencePaper">
			<h2>Social LSTM: Human Trajectory Prediction in Crowded Spaces</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Conference Paper</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Alexandre Alahi</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Kratarth Goel</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Vignesh Ramanathan</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Alexandre Robicquet</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Li Fei-Fei</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Silvio Savarese</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>Pedestrians follow different trajectories to avoid obstacles 
and accommodate fellow pedestrians. Any autonomous vehicle navigating 
such a scene should be able to foresee the future positions of 
pedestrians and accordingly adjust its path to avoid collisions. This 
problem of trajectory prediction can be viewed as a sequence generation 
task, where we are interested in predicting the future trajectory of 
people based on their past positions. Following the recent success of 
Recurrent Neural Network (RNN) models for sequence prediction tasks, we 
propose an LSTM model which can learn general human movement and predict
 their future trajectories. This is in contrast to traditional 
approaches which use hand-crafted functions such as Social forces. We 
demonstrate the performance of our method on several public datasets. 
Our model outperforms state-of-the-art methods on some of these datasets
 . We also analyze the trajectories predicted by our model to 
demonstrate the motion behaviour learned by our model.</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>6/2016</td>
					</tr>
					<tr>
					<th>Language</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Short Title</th>
						<td>Social LSTM</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>DOI.org (Crossref)</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="http://ieeexplore.ieee.org/document/7780479/">http://ieeexplore.ieee.org/document/7780479/</a></td>
					</tr>
					<tr>
					<th>Accessed</th>
						<td>10/29/2019, 10:57:34 AM</td>
					</tr>
					<tr>
					<th>Place</th>
						<td>Las Vegas, NV, USA</td>
					</tr>
					<tr>
					<th>Publisher</th>
						<td>IEEE</td>
					</tr>
					<tr>
					<th>ISBN</th>
						<td>978-1-4673-8851-1</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>961-971</td>
					</tr>
					<tr>
					<th>Proceedings Title</th>
						<td>2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</td>
					</tr>
					<tr>
					<th>Conference Name</th>
						<td>2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.1109/CVPR.2016.110">10.1109/CVPR.2016.110</a></td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_P2IMZJER">Alahi et al. - 2016 - Social LSTM Human Trajectory Prediction in Crowde.pdf					</li>
				</ul>
			</li>


			<li id="item_EI24DZES" class="item conferencePaper">
			<h2>Adaptive control for robot navigation in human environments based on social force model</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Conference Paper</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Chen Wang</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Yanan Li</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Shuzhi Sam Ge</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Tong Heng Lee</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>In this paper, we introduce a novel control scheme based on 
the social force model for robots navigating in human environments. 
Social proxemics potential ﬁeld is constructed based on the theory of 
proxemics and used to generate social interaction force for design of 
robot motion control. A combined kinematic/dynamic control is proposed 
to make the robot follow the target social force model, in the presence 
of kinematic velocity constraints. Under the proposed framework, given a
 speciﬁc social convention, robot is able to generate and modify its 
path smoothly without violating the proxemics constraints. The validity 
of the proposed method is veriﬁed through experimental studies using the
 V-rep platform.</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>5/2016</td>
					</tr>
					<tr>
					<th>Language</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>DOI.org (Crossref)</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="http://ieeexplore.ieee.org/document/7487791/">http://ieeexplore.ieee.org/document/7487791/</a></td>
					</tr>
					<tr>
					<th>Accessed</th>
						<td>11/4/2019, 11:28:20 AM</td>
					</tr>
					<tr>
					<th>Place</th>
						<td>Stockholm, Sweden</td>
					</tr>
					<tr>
					<th>Publisher</th>
						<td>IEEE</td>
					</tr>
					<tr>
					<th>ISBN</th>
						<td>978-1-4673-8026-3</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>5690-5695</td>
					</tr>
					<tr>
					<th>Proceedings Title</th>
						<td>2016 IEEE International Conference on Robotics and Automation (ICRA)</td>
					</tr>
					<tr>
					<th>Conference Name</th>
						<td>2016 IEEE International Conference on Robotics and Automation (ICRA)</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.1109/ICRA.2016.7487791">10.1109/ICRA.2016.7487791</a></td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_WDLCXNAM">Wang et al. - 2016 - Adaptive control for robot navigation in human env.pdf					</li>
				</ul>
			</li>


			<li id="item_TUBR6XNT" class="item journalArticle">
			<h2>Forecasting Social Navigation in Crowded Complex Scenes</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Journal Article</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Alexandre Robicquet</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Alexandre Alahi</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Amir Sadeghian</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Bryan Anenberg</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>John Doherty</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Eli Wu</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Silvio Savarese</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>When humans navigate a crowed space such as a university 
campus or the sidewalks of a busy street, they follow common sense rules
 based on social etiquette. In this paper, we argue that in order to 
enable the design of new algorithms that can take fully advantage of 
these rules to better solve tasks such as target tracking or trajectory 
forecasting, we need to have access to better data in the first place. 
To that end, we contribute the very first large scale dataset (to the 
best of our knowledge) that collects images and videos of various types 
of targets (not just pedestrians, but also bikers, skateboarders, cars, 
buses, golf carts) that navigate in a real-world outdoor environment 
such as a university campus. We present an extensive evaluation where 
different methods for trajectory forecasting are evaluated and compared.
 Moreover, we present a new algorithm for trajectory prediction that 
exploits the complexity of our new dataset and allows to: i) incorporate
 inter-class interactions into trajectory prediction models (e.g, 
pedestrian vs bike) as opposed to just intra-class interactions (e.g., 
pedestrian vs pedestrian); ii) model the degree to which the social 
forces are regulating an interaction. We call the latter "social 
sensitivity"and it captures the sensitivity to which a target is 
responding to a certain interaction. An extensive experimental 
evaluation demonstrates the effectiveness of our novel approach.</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2016-01-05</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>arXiv.org</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="http://arxiv.org/abs/1601.00998">http://arxiv.org/abs/1601.00998</a></td>
					</tr>
					<tr>
					<th>Accessed</th>
						<td>11/4/2019, 1:02:59 PM</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>arXiv: 1601.00998</td>
					</tr>
					<tr>
					<th>Publication</th>
						<td>arXiv:1601.00998 [cs]</td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Tags:</h3>
				<ul class="tags">
					<li>Computer Science - Computer Vision and Pattern Recognition</li>
					<li>Computer Science - Robotics</li>
					<li>Computer Science - Social and Information Networks</li>
				</ul>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_82FHY7CH">arXiv Fulltext PDF					</li>
					<li id="item_2DBZVI2V">arXiv.org Snapshot					</li>
				</ul>
			</li>


			<li id="item_395GNS57" class="item conferencePaper">
			<h2>Human Aware Robot Navigation in Semantically Annotated Domestic Environments</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Conference Paper</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Ioannis Kostavelis</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Dimitrios Giakoumis</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Sotiris Malassiotis</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Dimitrios Tzovaras</td>
					</tr>
					<tr>
						<th class="editor">Editor</th>
						<td>Margherita Antona</td>
					</tr>
					<tr>
						<th class="editor">Editor</th>
						<td>Constantine Stephanidis</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>In the near future, the seamless human robot cohabitation can 
be achieved as long as the robots to be released in the market attain 
socially acceptable behavior. Therefore, robots need to learn and react 
appropriately, should they be able to share the same space with people 
and to adapt their operation to human’s activity. The goal of this work 
is to introduce a human aware global path planning solution for robot 
navigation that considers the humans presence in a domestic environment.
 Towards this direction, hierarchical semantic maps are built upon 
metric maps where the human presence is modelled using frequently 
visited standing positions considering also the proxemics theory. During
 the human’s perambulation within the domestic environment the most 
probable humans pathways are calculated and modeled with sequential, yet
 descending Gaussian kernel’s. This way, the robot reacts with safety 
when operating in a domestic environment taking into consideration the 
human presence and the physical obstacles. The method has been evaluated
 on a simulated environment, yet on realistic acquired data modeling a 
real house space and exhibited remarkable performance.</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2016</td>
					</tr>
					<tr>
					<th>Language</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>Springer Link</td>
					</tr>
					<tr>
					<th>Place</th>
						<td>Cham</td>
					</tr>
					<tr>
					<th>Publisher</th>
						<td>Springer International Publishing</td>
					</tr>
					<tr>
					<th>ISBN</th>
						<td>978-3-319-40244-4</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>414-423</td>
					</tr>
					<tr>
					<th>Series</th>
						<td>Lecture Notes in Computer Science</td>
					</tr>
					<tr>
					<th>Proceedings Title</th>
						<td>Universal Access in Human-Computer Interaction. Interaction Techniques and Environments</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.1007/978-3-319-40244-4_40">10.1007/978-3-319-40244-4_40</a></td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Tags:</h3>
				<ul class="tags">
					<li>Human robot cohabitation</li>
					<li>Metric mapping</li>
					<li>Path planning</li>
					<li>Safe navigation</li>
					<li>Semantic mapping</li>
				</ul>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_5L5BWQG4">Springer Full Text PDF					</li>
				</ul>
			</li>


			<li id="item_RXFW6CSY" class="item conferencePaper">
			<h2>Bayes Estimator Human Intention Classifier Human Trajectory 
Regression Bayes Estimator Human Intention Classifier Human Trajectory 
Regression Bayes Estimator Human Intention Classifier Human Trajectory 
Regression</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Conference Paper</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Chonhyon Park</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Jan Ondrej</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Max Gilbert</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Kyle Freeman</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Carol O’Sullivan</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>We present an algorithmic framework for the early 
classification of human intentions, and use it to accurately predict 
future human motions when planning the path of a robot in an environment
 that is shared with humans. During an off-line learning phase, a 
classifier that can recognize when a human intends to interact with the 
robot is trained. At runtime, this trained classifier allows us to 
recognize humans who intend to interact with, or obstruct, the robot in 
some way. We validate our approach using both recorded and simulated 
data in an environment in which some humans intentionally obstruct the 
robot. Our classifier identifies these potential blockers, thus allowing
 the robot to safely and efficiently navigate the environment by 
minimizing the chances of being blocked.</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2016</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>Semantic Scholar</td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Tags:</h3>
				<ul class="tags">
					<li>Automated planning and scheduling</li>
					<li>Behavior</li>
					<li>Benchmark (computing)</li>
					<li>Blocking (computing)</li>
					<li>Intentionally blank page</li>
					<li>Linear classifier</li>
					<li>Motion</li>
					<li>Non-blocking algorithm</li>
					<li>Online and offline</li>
				</ul>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_2EJHHTFV">Full Text PDF					</li>
					<li id="item_95ZZBYXA">Semantic Scholar Link					</li>
				</ul>
			</li>


			<li id="item_VVTWP32Y" class="item conferencePaper">
			<h2>Interactive Navigation of Mobile Robots Based on Human’s Emotion</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Conference Paper</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Rui Jiang</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Shuzhi Sam Ge</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Nagacharan Teja Tangirala</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Tong Heng Lee</td>
					</tr>
					<tr>
						<th class="editor">Editor</th>
						<td>Arvin Agah</td>
					</tr>
					<tr>
						<th class="editor">Editor</th>
						<td>John-John Cabibihan</td>
					</tr>
					<tr>
						<th class="editor">Editor</th>
						<td>Ayanna M. Howard</td>
					</tr>
					<tr>
						<th class="editor">Editor</th>
						<td>Miguel A. Salichs</td>
					</tr>
					<tr>
						<th class="editor">Editor</th>
						<td>Hongsheng He</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>In this paper, an interactive navigation approach based on 
human’s emotion is proposed for mobile robot obstacle avoidance. By 
assuming human’s obstacle avoidance behavior is related to emotion, the 
variable artificial potential field is implemented to generate different
 obstacle avoidance behaviors when the robot encounters humans with 
attractive emotions and repulsive emotions. A virtual emotional barrier 
is added outside the physical barrier for human obstacles with repulsive
 emotions such that the robot tends to leave more personal space for 
them. Simulations on MATLAB and experiments on an ROS-based TurtleBot 2 
robot have been conducted to verify the effectiveness of the proposed 
scheme.</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2016</td>
					</tr>
					<tr>
					<th>Language</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>Springer Link</td>
					</tr>
					<tr>
					<th>Place</th>
						<td>Cham</td>
					</tr>
					<tr>
					<th>Publisher</th>
						<td>Springer International Publishing</td>
					</tr>
					<tr>
					<th>ISBN</th>
						<td>978-3-319-47437-3</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>243-252</td>
					</tr>
					<tr>
					<th>Series</th>
						<td>Lecture Notes in Computer Science</td>
					</tr>
					<tr>
					<th>Proceedings Title</th>
						<td>Social Robotics</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.1007/978-3-319-47437-3_24">10.1007/978-3-319-47437-3_24</a></td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Tags:</h3>
				<ul class="tags">
					<li>Artificial potential field</li>
					<li>Human’s emotion</li>
					<li>Mobile robot navigation</li>
					<li>Obstacle avoidance</li>
				</ul>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_8KXM45FG">Springer Full Text PDF					</li>
				</ul>
			</li>


			<li id="item_IQ3W78CB" class="item bookSection">
			<h2>SPENCER: A Socially Aware Service Robot for Passenger Guidance and Help in Busy Airports</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Book Section</td>
					</tr>
					<tr>
						<th class="editor">Editor</th>
						<td>David S. Wettergreen</td>
					</tr>
					<tr>
						<th class="editor">Editor</th>
						<td>Timothy D. Barfoot</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Rudolph Triebel</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Kai Arras</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Rachid Alami</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Lucas Beyer</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Stefan Breuers</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Raja Chatila</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Mohamed Chetouani</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Daniel Cremers</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Vanessa Evers</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Michelangelo Fiore</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Hayley Hung</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Omar A. Islas Ramírez</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Michiel Joosse</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Harmish Khambhaita</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Tomasz Kucner</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Bastian Leibe</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Achim J. Lilienthal</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Timm Linder</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Manja Lohse</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Martin Magnusson</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Billy Okal</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Luigi Palmieri</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Umer Rafi</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Marieke van Rooij</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Lu Zhang</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>We present an ample description of a socially compliant mobile
 robotic platform, which is developed in the EU-funded project SPENCER. 
The purpose of this robot is to assist, inform and guide passengers in 
large and busy airports. One particular aim is to bring travellers of 
connecting ﬂights conveniently and efﬁciently from their arrival gate to
 the passport control. The uniqueness of the project stems from the 
strong demand of service robots for this application with a large 
potential impact for the aviation industry on one side, and on the other
 side from the scientiﬁc advancements in social robotics, brought 
forward and achieved in SPENCER. The main contributions of SPENCER are 
novel methods to perceive, learn, and model human social behavior and to
 use this knowledge to plan appropriate actions in realtime for mobile 
platforms. In this paper, we describe how the project advances the ﬁelds
 of detection and tracking of individuals and groups, recognition of 
human social relations and activities, normative human behavior 
learning, socially-aware task and motion planning, learning socially 
annotated maps, and conducting empirical experiments to assess 
socio-psychological effects of normative robot behaviors.</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2016</td>
					</tr>
					<tr>
					<th>Language</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Short Title</th>
						<td>SPENCER</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>DOI.org (Crossref)</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="http://link.springer.com/10.1007/978-3-319-27702-8_40">http://link.springer.com/10.1007/978-3-319-27702-8_40</a></td>
					</tr>
					<tr>
					<th>Accessed</th>
						<td>11/4/2019, 11:35:02 AM</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>DOI: 10.1007/978-3-319-27702-8_40</td>
					</tr>
					<tr>
					<th>Volume</th>
						<td>113</td>
					</tr>
					<tr>
					<th>Place</th>
						<td>Cham</td>
					</tr>
					<tr>
					<th>Publisher</th>
						<td>Springer International Publishing</td>
					</tr>
					<tr>
					<th>ISBN</th>
						<td>978-3-319-27700-4 978-3-319-27702-8</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>607-622</td>
					</tr>
					<tr>
					<th>Book Title</th>
						<td>Field and Service Robotics</td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_85FKJTJZ">Triebel et al. - 2016 - SPENCER A Socially Aware Service Robot for Passen.pdf					</li>
				</ul>
			</li>


			<li id="item_69ZA3TUJ" class="item conferencePaper">
			<h2>On-board human-aware navigation for indoor resource-constrained robots: A case-study with the ranger</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Conference Paper</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Zeynab Talebpour</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Iñaki Navarro</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Alcherio Martinoli</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>Introducing simple robotic platforms into domestic 
environments is faced with the challenge of social acceptability. 
Therefore human-aware navigation is a must for robots operating in 
environments shared with human users. In this work, we focus on the 
human-aware navigation problem in a structured environment for a robot 
with limited sensing and constrained maneuvering called Ranger. The 
Ranger is a simple domestic robotic platform designed for interacting 
with children. The system combines person detection and tracking - which
 is the result of fusing laser-scan and depth-image based detectors 
provided by an RGB-D camera -, basic autonomous navigation and the 
concept of personal space. We rely only on the on-board sensors for 
mapping, localization, human tracking, and navigation. Systematic 
experiments are carried out with a real robot in the presence of a human
 in order to compare our human-aware navigation with a non human-aware 
simple approach. The results show that human-aware navigation is able to
 achieve trajectories which are respecting the personal spaces of the 
human and are thus more acceptable for the users.</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>December 2015</td>
					</tr>
					<tr>
					<th>Short Title</th>
						<td>On-board human-aware navigation for indoor resource-constrained robots</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>IEEE Xplore</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>63-68</td>
					</tr>
					<tr>
					<th>Proceedings Title</th>
						<td>2015 IEEE/SICE International Symposium on System Integration (SII)</td>
					</tr>
					<tr>
					<th>Conference Name</th>
						<td>2015 IEEE/SICE International Symposium on System Integration (SII)</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.1109/SII.2015.7404955">10.1109/SII.2015.7404955</a></td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Tags:</h3>
				<ul class="tags">
					<li>Cameras</li>
					<li>mobile robots</li>
					<li>Navigation</li>
					<li>path planning</li>
					<li>Mobile robots</li>
					<li>autonomous personal space navigation</li>
					<li>cameras</li>
					<li>children robotic interaction</li>
					<li>constrained maneuvering</li>
					<li>depth-image based detectors</li>
					<li>domestic environments</li>
					<li>domestic robotic platform</li>
					<li>human-aware navigation</li>
					<li>human-aware navigation problem</li>
					<li>human-robot interaction</li>
					<li>image colour analysis</li>
					<li>image sensors</li>
					<li>indoor navigation</li>
					<li>indoor resource-constrained robots</li>
					<li>laser-scan based detectors</li>
					<li>object detection</li>
					<li>on-board human-aware navigation</li>
					<li>on-board sensors</li>
					<li>person detection</li>
					<li>person tracking</li>
					<li>Ranger</li>
					<li>RGB-D camera</li>
					<li>robot vision</li>
					<li>Robot vision systems</li>
					<li>service robots</li>
				</ul>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_CBU5GAT2">Submitted Version					</li>
					<li id="item_8LSATHQS">IEEE Xplore Abstract Record					</li>
				</ul>
			</li>


			<li id="item_768VK5KR" class="item conferencePaper">
			<h2>Socially Acceptable Robot Navigation in the Presence of Humans</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Conference Paper</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Phelipe A.A. Vasconcelos</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Henrique N.S. Pereira</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Douglas G. Macharet</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Erickson R. Nascimento</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>Considering the widespread use of mobile robots in different 
parts of society, it is important to provide them with the capability to
 behave in a socially acceptable manner. Therefore, a research topic of 
great importance recently has been the study of Human-Robot Interaction 
(HRI). In this work we propose a methodology to dynamically adapt the 
robot’s behavior during its navigation considering a possible encounter 
with humans in the environment. The method is divided into two basic 
steps. The ﬁrst one is based upon Computer Vision techniques and 
executes the recognition and analysis of the scene, considering 
characteristics such as the presence of humans, quantity, and distance 
to the robot. Considering the information from the previous stage, the 
methodology decides whether the navigation should undergo some 
modiﬁcation. Among the possible adaptation are changing the current 
trajectory and reduction in speed. Different trials on a real-world 
scenario were executed, providing a thorough evaluation and validation 
of the methodology.</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>10/2015</td>
					</tr>
					<tr>
					<th>Language</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>DOI.org (Crossref)</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="http://ieeexplore.ieee.org/document/7402169/">http://ieeexplore.ieee.org/document/7402169/</a></td>
					</tr>
					<tr>
					<th>Accessed</th>
						<td>11/4/2019, 12:57:01 PM</td>
					</tr>
					<tr>
					<th>Place</th>
						<td>Uberlandia, Brazil</td>
					</tr>
					<tr>
					<th>Publisher</th>
						<td>IEEE</td>
					</tr>
					<tr>
					<th>ISBN</th>
						<td>978-1-4673-7129-2</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>222-227</td>
					</tr>
					<tr>
					<th>Proceedings Title</th>
						<td>2015 12th Latin American Robotics Symposium and 2015 3rd Brazilian Symposium on Robotics (LARS-SBR)</td>
					</tr>
					<tr>
					<th>Conference Name</th>
						<td>2015 12th Latin American Robotics Symposium (LARS) and 2015 3rd Brazilian Symposium on Robotics (LARS-SBR)</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.1109/LARS-SBR.2015.14">10.1109/LARS-SBR.2015.14</a></td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_K2846EQ9">Vasconcelos et al. - 2015 - Socially Acceptable Robot Navigation in the Presen.pdf					</li>
				</ul>
			</li>


			<li id="item_CYED6DWE" class="item conferencePaper">
			<h2>Show me your moves! Conveying navigation intention of a mobile robot to humans</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Conference Paper</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Alyxander David May</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Christian Dondrup</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Marc Hanheide</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>When humans and mobile robots share the same space, one of 
their challenges is to navigate around each other and manage their 
mutual navigational intents. While humans have developed excellent 
skills in inferring their counterpart's intentions via a number of 
implicit and non-verbal cues, making navigation also in crowds an ease, 
this kind of effective and efficient communication often falls short in 
human-robot encounters. In this paper, two alternative approaches to 
convey navigational intent of a mobile robot to humans in a shared 
environment are proposed and analysed. The first is utilising 
anthropomorphic features of the mobile robot to realise an implicit 
joint attention using gaze to represent the direction of navigational 
intent. In the second approach, a more technical design adopting the 
semantics of car's turn indicators, has been implemented. The paper 
compares both approaches with each other and against a control behaviour
 without any communication of intent. Both approaches show statistically
 significant differences in comparison to the control behaviour. 
However, the second approach using indicators has shown as being more 
effective in conveying the intent and also has a higher positive impact 
on the comfort of the humans encountering the robot.</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>Sep. 2015</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>IEEE Xplore</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>1-6</td>
					</tr>
					<tr>
					<th>Proceedings Title</th>
						<td>2015 European Conference on Mobile Robots (ECMR)</td>
					</tr>
					<tr>
					<th>Conference Name</th>
						<td>2015 European Conference on Mobile Robots (ECMR)</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.1109/ECMR.2015.7324049">10.1109/ECMR.2015.7324049</a></td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Tags:</h3>
				<ul class="tags">
					<li>mobile robots</li>
					<li>Navigation</li>
					<li>Mobile robots</li>
					<li>human-robot interaction</li>
					<li>humans</li>
					<li>Magnetic heads</li>
					<li>mobile robot</li>
					<li>navigation</li>
					<li>navigation intention</li>
					<li>navigational intent</li>
					<li>nonverbal cues</li>
					<li>Robot sensing systems</li>
					<li>Semantics</li>
					<li>Visualization</li>
				</ul>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_X8G854AG">IEEE Xplore Abstract Record					</li>
					<li id="item_4522WGPH">May et al. - 2015 - Show me your moves! Conveying navigation intention.pdf					</li>
				</ul>
			</li>


			<li id="item_PA7HLQA3" class="item conferencePaper">
			<h2>Time dependent planning on a layered social cost map for human-aware robot navigation</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Conference Paper</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>M. Kollmitz</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>K. Hsiao</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>J. Gaa</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>W. Burgard</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>As robots make their way into our everyday lives, new 
behavioral concepts are needed to assure their acceptance as interaction
 partners. In the presence of humans, robots are required to take safety
 as well as human comfort into account. This paper presents a novel, 
planning-based approach for social robot navigation. It uses predicted 
human trajectories and a social cost function to plan collision-free 
paths that take human comfort into account. It furthermore employs time 
dependent, kinodynamic path planning to reason about human motion over 
time and to account for the kinematic and dynamic constraints of a 
robot. Our approach generates paths that exhibit properties similar to 
those used in human-human interaction, such as waiting for a human to 
pass before continuing along an intended path, avoiding getting too 
close to another human's personal space, and moving out of the way when 
blocking a human's path. In extensive experiments carried out with real 
robots and in simulation we demonstrate the performance of our approach.</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>Sep. 2015</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>IEEE Xplore</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>1-6</td>
					</tr>
					<tr>
					<th>Proceedings Title</th>
						<td>2015 European Conference on Mobile Robots (ECMR)</td>
					</tr>
					<tr>
					<th>Conference Name</th>
						<td>2015 European Conference on Mobile Robots (ECMR)</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.1109/ECMR.2015.7324184">10.1109/ECMR.2015.7324184</a></td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Tags:</h3>
				<ul class="tags">
					<li>human trajectory prediction</li>
					<li>Trajectory</li>
					<li>collision avoidance</li>
					<li>Collision avoidance</li>
					<li>mobile robots</li>
					<li>Navigation</li>
					<li>Robots</li>
					<li>behavioral concepts</li>
					<li>collision-free path planning</li>
					<li>Cost function</li>
					<li>dynamic constraints</li>
					<li>human-aware robot navigation</li>
					<li>kinematic constraints</li>
					<li>kinodynamic path planning</li>
					<li>layered social cost map</li>
					<li>Planning</li>
					<li>robot dynamics</li>
					<li>robot kinematics</li>
					<li>social cost function</li>
					<li>social robot navigation</li>
					<li>Standards</li>
					<li>time dependent planning</li>
				</ul>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_B8FWWL2U">Kollmitz et al. - 2015 - Time dependent planning on a layered social cost m.pdf					</li>
					<li id="item_245P7CQS">IEEE Xplore Abstract Record					</li>
				</ul>
			</li>


			<li id="item_J23XXUZE" class="item conferencePaper">
			<h2>Using contact-based inducement for efficient navigation in a congested environment</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Conference Paper</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Moondeep C. Shrestha</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Yosuke Nohisa</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Alexander Schmitz</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Shouichi Hayakawa</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Erika Uno</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Yuta Yokoyama</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Hayato Yanagawa</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Keung Or</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Shigeki Sugano</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>As robots progressively continue to enter human lives, it 
becomes important for robots to navigate safely and efficiently in 
crowded environments. In fact, efficient navigation in crowded areas is 
an important prerequisite for successful coexistence between humans and 
robots. In this paper, we explore an unconventional idea wherein a robot
 tries to achieve a more efficient navigation by influencing an 
obstructing human to move away by means of contact. First, preliminary 
human reaction experiments were conducted wherein we established that we
 can successfully induce a human to move in a desired direction. 
Following this result, we have proposed a novel motion planning approach
 which considers inducement by contact. The system is then verified 
through simulation and real experiments. The results show us that the 
proposed method can be utilized for safer and more efficient navigation 
in a crowded, but relatively static environment.</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>August 2015</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>IEEE Xplore</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>456-461</td>
					</tr>
					<tr>
					<th>Proceedings Title</th>
						<td>2015 24th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN)</td>
					</tr>
					<tr>
					<th>Conference Name</th>
						<td>2015 24th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN)</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.1109/ROMAN.2015.7333673">10.1109/ROMAN.2015.7333673</a></td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Tags:</h3>
				<ul class="tags">
					<li>Trajectory</li>
					<li>mobile robots</li>
					<li>Navigation</li>
					<li>path planning</li>
					<li>Mobile robots</li>
					<li>human-robot interaction</li>
					<li>Planning</li>
					<li>Robot sensing systems</li>
					<li>crowded environments</li>
					<li>Force</li>
					<li>congested environment navigation</li>
					<li>contact-based inducement</li>
					<li>crowded area navigation</li>
					<li>human reaction experiments</li>
					<li>motion planning approach</li>
					<li>safe robot navigation</li>
				</ul>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_ULZUZKWV">Shrestha et al. - 2015 - Using contact-based inducement for efficient navig.pdf					</li>
					<li id="item_26GZNKPI">IEEE Xplore Abstract Record					</li>
				</ul>
			</li>


			<li id="item_MBGW6SPS" class="item journalArticle">
			<h2>A review on indoor human aware autonomous mobile robot navigation
 through a dynamic environment survey of different path planning 
algorithm and methods</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Journal Article</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Rahul Pol</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Murugan Mahalingam</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>Practical realistic environment for path and continuous motion
 planning problems normally consist of numerous working areas such as in
 indoor application consist of number of bedrooms, hallways, multiple 
doorways with many static and dynamic obstacle in between. 
Disintegration of such environment into small areas, or regions shows 
impact on the quality of adaptive path planning in dynamic environment. 
Many algorithms are developed for solving problems involving narrow 
passages and multiple regions with optimal solution. Autonomous mobile 
robot system must have sense of balance of its potential, steadfastness 
and sturdiness issue with task and the final goals while generating and 
executing an adaptive as well as effective strategy with optimal 
solution. Navigation algorithms approaching to a certain maturity in the
 field of autonomous mobile robot, so most of research is now focused 
more advance task like adaptive path planning and navigation through 
dynamic environments. Adaptive path planning and navigation needs to set
 learning rate, rules for classifying spaces and defining proposed 
library parameters. The aim of this survey is to informing the progress 
of human sentient manipulation planner.</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>July 6, 2015</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>ResearchGate</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>1339-1344</td>
					</tr>
					<tr>
					<th>Publication</th>
						<td>2015 International Conference on Industrial Instrumentation and Control, ICIC 2015</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.1109/IIC.2015.7150956">10.1109/IIC.2015.7150956</a></td>
					</tr>
					<tr>
					<th>Journal Abbr</th>
						<td>2015 International Conference on Industrial Instrumentation and Control, ICIC 2015</td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_MDRHMP8N">ResearchGate Link					</li>
					<li id="item_6WYNSJDG">Full Text PDF					</li>
				</ul>
			</li>


			<li id="item_DNK2C3VC" class="item conferencePaper">
			<h2>Human-robot co-navigation using anticipatory indicators of human walking motion</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Conference Paper</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Vaibhav V. Unhelkar</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Claudia Perez-D'Arpino</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Leia Stirling</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Julie A. Shah</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>Mobile, interactive robots that operate in humancentric 
environments need the capability to safely and efﬁciently navigate 
around humans. This requires the ability to sense and predict human 
motion trajectories and to plan around them. In this paper, we present a
 study that supports the existence of statistically signiﬁcant 
biomechanical turn indicators of human walking motions. Further, we 
demonstrate the effectiveness of these turn indicators as features in 
the prediction of human motion trajectories. Human motion capture data 
is collected with predeﬁned goals to train and test a prediction 
algorithm. Use of anticipatory features results in improved performance 
of the prediction algorithm. Lastly, we demonstrate the closedloop 
performance of the prediction algorithm using an existing algorithm for 
motion planning within dynamic environments. The anticipatory indicators
 of human walking motion can be used with different prediction and/or 
planning algorithms for robotics; the chosen planning and prediction 
algorithm demonstrates one such implementation for human-robot 
conavigation.</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>5/2015</td>
					</tr>
					<tr>
					<th>Language</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>DOI.org (Crossref)</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="http://ieeexplore.ieee.org/document/7140067/">http://ieeexplore.ieee.org/document/7140067/</a></td>
					</tr>
					<tr>
					<th>Accessed</th>
						<td>11/4/2019, 11:18:22 AM</td>
					</tr>
					<tr>
					<th>Place</th>
						<td>Seattle, WA, USA</td>
					</tr>
					<tr>
					<th>Publisher</th>
						<td>IEEE</td>
					</tr>
					<tr>
					<th>ISBN</th>
						<td>978-1-4799-6923-4</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>6183-6190</td>
					</tr>
					<tr>
					<th>Proceedings Title</th>
						<td>2015 IEEE International Conference on Robotics and Automation (ICRA)</td>
					</tr>
					<tr>
					<th>Conference Name</th>
						<td>2015 IEEE International Conference on Robotics and Automation (ICRA)</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.1109/ICRA.2015.7140067">10.1109/ICRA.2015.7140067</a></td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_S95GYREP">Unhelkar et al. - 2015 - Human-robot co-navigation using anticipatory indic.pdf					</li>
				</ul>
			</li>


			<li id="item_BZDSVVEL" class="item journalArticle">
			<h2>From Proxemics Theory to Socially-Aware Navigation: A Survey</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Journal Article</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>J. Rios-Martinez</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>A. Spalanzani</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>C. Laugier</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>In the context of a growing interest in modelling human 
behavior to increase the robots’ social abilities, this article presents
 a survey related to socially-aware robot navigation. It presents a 
review from sociological concepts to social robotics and human-aware 
navigation. Social cues, signals and proxemics are discussed. Socially 
aware behavior in terms of navigation is tackled also. Finally, recent 
robotic experiments focusing on the way social conventions and robotics 
must be linked is presented.</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2015-04-01</td>
					</tr>
					<tr>
					<th>Language</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Short Title</th>
						<td>From Proxemics Theory to Socially-Aware Navigation</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>Springer Link</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://doi.org/10.1007/s12369-014-0251-1">https://doi.org/10.1007/s12369-014-0251-1</a></td>
					</tr>
					<tr>
					<th>Accessed</th>
						<td>4/4/2019, 10:33:08 AM</td>
					</tr>
					<tr>
					<th>Volume</th>
						<td>7</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>137-153</td>
					</tr>
					<tr>
					<th>Publication</th>
						<td>International Journal of Social Robotics</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.1007/s12369-014-0251-1">10.1007/s12369-014-0251-1</a></td>
					</tr>
					<tr>
					<th>Issue</th>
						<td>2</td>
					</tr>
					<tr>
					<th>Journal Abbr</th>
						<td>Int J of Soc Robotics</td>
					</tr>
					<tr>
					<th>ISSN</th>
						<td>1875-4805</td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Tags:</h3>
				<ul class="tags">
					<li>Human-aware navigation</li>
					<li>Proxemics</li>
					<li>Socially-aware navigation</li>
				</ul>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_I6L8ASTR">Full Text					</li>
				</ul>
			</li>


			<li id="item_EZ2A3Z93" class="item journalArticle">
			<h2>Robot navigation in dense human crowds: Statistical models and experimental studies of human–robot cooperation</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Journal Article</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Pete Trautman</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Jeremy Ma</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Richard M. Murray</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Andreas Krause</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>We consider the problem of navigating a mobile robot through 
dense human crowds. We begin by exploring a fundamental impediment to 
classical motion planning algorithms called the ‘‘freezing robot 
problem’’: once the environment surpasses a certain level of dynamic 
complexity, the planner decides that all forward paths are unsafe, and 
the robot freezes in place (or performs unnecessary maneuvers) to avoid 
collisions. We argue that this problem can be avoided if the robot 
anticipates human cooperation, and accordingly we develop interacting 
Gaussian processes, a prediction density that captures cooperative 
collision avoidance, and a ‘‘multiple goal’’ extension that models the 
goal-driven nature of human decision making. We validate this model with
 an empirical study of robot navigation in dense human crowds (488 
runs), specifically testing how cooperation models effect navigation 
performance. The multiple goal interacting Gaussian processes algorithm 
performs comparably with human teleoperators in crowd densities nearing 
0.8 humans/m2, while a state-of-theart non-cooperative planner exhibits 
unsafe behavior more than three times as often as the multiple goal 
extension, and twice as often as the basic interacting Gaussian process 
approach. Furthermore, a reactive planner based on the widely used 
dynamic window approach proves insufficient for crowd densities above 
0.55 people/m2. We also show that our noncooperative planner or our 
reactive planner capture the salient characteristics of nearly any 
dynamic navigation algorithm. Based on these experimental results and 
theoretical observations, we conclude that a cooperation model is 
critical for safe and efficient robot navigation in dense human crowds.</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>03/2015</td>
					</tr>
					<tr>
					<th>Language</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Short Title</th>
						<td>Robot navigation in dense human crowds</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>DOI.org (Crossref)</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="http://journals.sagepub.com/doi/10.1177/0278364914557874">http://journals.sagepub.com/doi/10.1177/0278364914557874</a></td>
					</tr>
					<tr>
					<th>Accessed</th>
						<td>11/4/2019, 11:20:27 AM</td>
					</tr>
					<tr>
					<th>Volume</th>
						<td>34</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>335-356</td>
					</tr>
					<tr>
					<th>Publication</th>
						<td>The International Journal of Robotics Research</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.1177/0278364914557874">10.1177/0278364914557874</a></td>
					</tr>
					<tr>
					<th>Issue</th>
						<td>3</td>
					</tr>
					<tr>
					<th>Journal Abbr</th>
						<td>The International Journal of Robotics Research</td>
					</tr>
					<tr>
					<th>ISSN</th>
						<td>0278-3649, 1741-3176</td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_REYK6SAZ">Trautman et al. - 2015 - Robot navigation in dense human crowds Statistica.pdf					</li>
				</ul>
			</li>


			<li id="item_N58LTC4M" class="item conferencePaper">
			<h2>Drone &amp; me: an exploration into natural human-drone interaction</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Conference Paper</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Jessica R. Cauchard</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Jane L. E</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Kevin Y. Zhai</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>James A. Landay</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>Personal drones are becoming popular. It is challenging to 
design how to interact with these flying robots. We present a 
Wizard-of-Oz (WoZ) elicitation study that informs how to naturally 
interact with drones. Results show strong agreement between participants
 for many interaction techniques, as when gesturing for the drone to 
stop. We discovered that people interact with drones as with a person or
 a pet, using interpersonal gestures, such as beckoning the drone 
closer. We detail the interaction metaphors observed and offer design 
insights for human-drone interactions.</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2015</td>
					</tr>
					<tr>
					<th>Language</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Short Title</th>
						<td>Drone &amp; me</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>DOI.org (Crossref)</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="http://dl.acm.org/citation.cfm?doid=2750858.2805823">http://dl.acm.org/citation.cfm?doid=2750858.2805823</a></td>
					</tr>
					<tr>
					<th>Accessed</th>
						<td>11/30/2021, 3:42:23 PM</td>
					</tr>
					<tr>
					<th>Place</th>
						<td>Osaka, Japan</td>
					</tr>
					<tr>
					<th>Publisher</th>
						<td>ACM Press</td>
					</tr>
					<tr>
					<th>ISBN</th>
						<td>978-1-4503-3574-4</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>361-365</td>
					</tr>
					<tr>
					<th>Proceedings Title</th>
						<td>Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing - UbiComp '15</td>
					</tr>
					<tr>
					<th>Conference Name</th>
						<td>the 2015 ACM International Joint Conference</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.1145/2750858.2805823">10.1145/2750858.2805823</a></td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_THMBL9HP">Cauchard et al. - 2015 - Drone &amp; me an exploration into natural human-dron.pdf					</li>
				</ul>
			</li>


			<li id="item_GQPBPCDZ" class="item conferencePaper">
			<h2>Safe Predictive Mobile Robot Navigation in Aware Environments:</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Conference Paper</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Michael Arndt</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Karsten Berns</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2015</td>
					</tr>
					<tr>
					<th>Language</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Short Title</th>
						<td>Safe Predictive Mobile Robot Navigation in Aware Environments</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>DOI.org (Crossref)</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="http://www.scitepress.org/DigitalLibrary/Link.aspx?doi=10.5220/0005509500150023">http://www.scitepress.org/DigitalLibrary/Link.aspx?doi=10.5220/0005509500150023</a></td>
					</tr>
					<tr>
					<th>Accessed</th>
						<td>11/4/2019, 11:12:19 AM</td>
					</tr>
					<tr>
					<th>Place</th>
						<td>Colmar, Alsace, France</td>
					</tr>
					<tr>
					<th>Publisher</th>
						<td>SCITEPRESS - Science and and Technology Publications</td>
					</tr>
					<tr>
					<th>ISBN</th>
						<td>978-989-758-122-9 978-989-758-123-6</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>15-23</td>
					</tr>
					<tr>
					<th>Proceedings Title</th>
						<td>Proceedings of the 12th International Conference on Informatics in Control, Automation and Robotics</td>
					</tr>
					<tr>
					<th>Conference Name</th>
						<td>12th International Conference on Informatics in Control, Automation and Robotics</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.5220/0005509500150023">10.5220/0005509500150023</a></td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_6WPE6YKF">Arndt and Berns - 2015 - Safe Predictive Mobile Robot Navigation in Aware E.pdf					</li>
				</ul>
			</li>


			<li id="item_QWKB5VRX" class="item journalArticle">
			<h2>An Architecture for Navigation of Service Robots in 
Human-Populated Office-like Environments**This work was supported by 
Fundação de Amparo à Pesquisa do Estado de Minas Gerais (FAPEMIG). 
Arthur Araujo and Guilherme Pereira are supported by Conselho Nacional 
de Desenvolvimento Científico e Tecnologico (CNPq), Brazil.</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Journal Article</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Arthur R. Araujo</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Daniel D. Caminhas</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Guilherme A.S. Pereira</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2015</td>
					</tr>
					<tr>
					<th>Language</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>DOI.org (Crossref)</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://linkinghub.elsevier.com/retrieve/pii/S2405896315026567">https://linkinghub.elsevier.com/retrieve/pii/S2405896315026567</a></td>
					</tr>
					<tr>
					<th>Accessed</th>
						<td>11/4/2019, 11:25:15 AM</td>
					</tr>
					<tr>
					<th>Volume</th>
						<td>48</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>189-194</td>
					</tr>
					<tr>
					<th>Publication</th>
						<td>IFAC-PapersOnLine</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.1016/j.ifacol.2015.12.032">10.1016/j.ifacol.2015.12.032</a></td>
					</tr>
					<tr>
					<th>Issue</th>
						<td>19</td>
					</tr>
					<tr>
					<th>Journal Abbr</th>
						<td>IFAC-PapersOnLine</td>
					</tr>
					<tr>
					<th>ISSN</th>
						<td>24058963</td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Tags:</h3>
				<ul class="tags">
					<li>Robot Navigation</li>
					<li>Autonomous Mobile Robots</li>
					<li>Human-Aware Navigation</li>
					<li>Service Robotics</li>
				</ul>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_PWAXPRQY">Araujo et al. - 2015 - An Architecture for Navigation of Service Robots i.pdf					</li>
					<li id="item_TH6R5IM2">ScienceDirect Snapshot					</li>
				</ul>
			</li>


			<li id="item_K6KA2YCH" class="item conferencePaper">
			<h2>Dynamic social zone for human safety in human-robot shared workspaces</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Conference Paper</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Xuan-Tung Truong</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Voo Nyuk Yoong</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Trung-Dung Ngo</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>We propose an eﬀective human safety framework enabling a 
mobile service robot to navigate safely and socially in social 
environments. The proposed framework takes human states (position, 
orientation, motion and hand poses) and social interaction information 
relative to the robot into account to model extended personal space and 
social interaction space, respectively, the combination of which results
 in a dynamic social zone (DSZ). The DSZ-based human comfortable safety 
framework is able to estimate an approaching goal pose of the robot for a
 human or a group of humans, thus allowing the robot to not only avoid 
but also to approach a human or a group of humans in a socially 
acceptable manner. The DSZ is incorporated into the robots motion 
planning system comprising the D* planner technique and dynamic window 
approach (DWA) algorithm to generate motion control commands for the 
mobile robot. We verify the eﬀectiveness of the proposed method through 
simulation and experimental results under the newly proposed human 
comfortable safety indices.</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>11/2014</td>
					</tr>
					<tr>
					<th>Language</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>DOI.org (Crossref)</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="http://ieeexplore.ieee.org/document/7057375/">http://ieeexplore.ieee.org/document/7057375/</a></td>
					</tr>
					<tr>
					<th>Accessed</th>
						<td>11/4/2019, 11:23:31 AM</td>
					</tr>
					<tr>
					<th>Place</th>
						<td>Kuala Lumpur, Malaysia</td>
					</tr>
					<tr>
					<th>Publisher</th>
						<td>IEEE</td>
					</tr>
					<tr>
					<th>ISBN</th>
						<td>978-1-4799-5333-2</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>391-396</td>
					</tr>
					<tr>
					<th>Proceedings Title</th>
						<td>2014 11th International Conference on Ubiquitous Robots and Ambient Intelligence (URAI)</td>
					</tr>
					<tr>
					<th>Conference Name</th>
						<td>2014 11th International Conference on Ubiquitous Robots and Ambient Intelligence (URAI)</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.1109/URAI.2014.7057375">10.1109/URAI.2014.7057375</a></td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_NCTB7UXS">Truong et al. - 2014 - Dynamic social zone for human safety in human-robo.pdf					</li>
				</ul>
			</li>


			<li id="item_VFZY5JBQ" class="item conferencePaper">
			<h2>Proxemics models for human-aware navigation in robotics: 
Grounding interaction and personal space models in experimental data 
from psychology</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Conference Paper</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Marie-Lou Barnaud</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Nicolas Morgado</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Richard Palluel-Germain</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Julien Diard</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Anne Spalanzani</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>In order to navigate in a social environment, a robot must be 
aware of social spaces, which include proximity and interaction-based 
constraints. Previous models of interaction and personal spaces have 
been inspired by studies in social psychology but not systematically 
grounded and validated with respect to experimental data. We propose to 
implement personal and interaction space models in order to replicate a 
classical psychology experiment. Our robotic simulations can thus be 
compared with experimental data from humans. Thanks to this comparison, 
we first show the validity of our models, examine the necessity of the 
interaction and personal spaces and discuss their geometric shape. Our 
experiments suggest that human-like robotic behavior can be obtained by 
using only correctly calibrated personal spaces (i.e., without explicit 
representation of interaction spaces and therefore, without the need to 
detect interactions between humans in the environment).</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>September 2014</td>
					</tr>
					<tr>
					<th>Short Title</th>
						<td>Proxemics models for human-aware navigation in robotics</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>HAL Archives Ouvertes</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://hal.archives-ouvertes.fr/hal-01082517">https://hal.archives-ouvertes.fr/hal-01082517</a></td>
					</tr>
					<tr>
					<th>Accessed</th>
						<td>11/4/2019, 10:37:26 AM</td>
					</tr>
					<tr>
					<th>Place</th>
						<td>Chicago, United States</td>
					</tr>
					<tr>
					<th>Proceedings Title</th>
						<td>Proceedings of the 3rd IROS'2014 workshop “Assistance and Service Robotics in a Human Environment”</td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_HAVBUGY2">HAL PDF Full Text					</li>
				</ul>
			</li>


			<li id="item_JBIWYVNM" class="item conferencePaper">
			<h2>Inverse Reinforcement Learning algorithms and features for robot navigation in crowds: An experimental comparison</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Conference Paper</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>D. Vasquez</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>B. Okal</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>K. O. Arras</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>For mobile robots which operate in human populated 
environments, modeling social interactions is key to understand and 
reproduce people's behavior. A promising approach to this end is Inverse
 Reinforcement Learning (IRL) as it allows to model the factors that 
motivate people's actions instead of the actions themselves. A crucial 
design choice in IRL is the selection of features that encode the 
agent's context. In related work, features are typically chosen ad hoc 
without systematic evaluation of the alternatives and their actual 
impact on the robot's task. In this paper, we introduce a new software 
framework to systematically investigate the effect features and learning
 algorithms used in the literature. We also present results for the task
 of socially compliant robot navigation in crowds, evaluating two 
different IRL approaches and several feature sets in large-scale 
simulations. The results are benchmarked according to a proposed set of 
objective and subjective performance metrics.</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>Sep. 2014</td>
					</tr>
					<tr>
					<th>Short Title</th>
						<td>Inverse Reinforcement Learning algorithms and features for robot navigation in crowds</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>IEEE Xplore</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>1341-1346</td>
					</tr>
					<tr>
					<th>Proceedings Title</th>
						<td>2014 IEEE/RSJ International Conference on Intelligent Robots and Systems</td>
					</tr>
					<tr>
					<th>Conference Name</th>
						<td>2014 IEEE/RSJ International Conference on Intelligent Robots and Systems</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.1109/IROS.2014.6942731">10.1109/IROS.2014.6942731</a></td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Tags:</h3>
				<ul class="tags">
					<li>learning (artificial intelligence)</li>
					<li>mobile robots</li>
					<li>Navigation</li>
					<li>path planning</li>
					<li>Robots</li>
					<li>control engineering computing</li>
					<li>robot navigation</li>
					<li>Airports</li>
					<li>inverse reinforcement learning algorithm</li>
					<li>IRL approach</li>
					<li>objective performance metrics</li>
					<li>Silicon</li>
					<li>social interaction modeling</li>
					<li>software framework</li>
					<li>subjective performance metrics</li>
					<li>Tin</li>
					<li>Vectors</li>
					<li>Vehicles</li>
				</ul>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_ZQ5TPAD4">IEEE Xplore Abstract Record					</li>
					<li id="item_A7PRGQDG">Submitted Version					</li>
				</ul>
			</li>


			<li id="item_NRFDHVAQ" class="item conferencePaper">
			<h2>Robot local navigation with learned social cost functions</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Conference Paper</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Noé Pérez-Higueras</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Rafael Ramón-Vigo</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Fernando Caballero</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Luis Merino</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>Robot navigation in human environments is an active research 
area that poses serious challenges. Among them, human-awareness has gain
 lot of attention in the last years due to its important role in human 
safety and robot acceptance. The proposed robot navigation system 
extends state of the navigation schemes with some social skills in order
 to naturally integrate the robot motion in crowded areas. Learning has 
been proposed as a more principled way of estimating the insights of 
human social interactions. To do this, inverse reinforcement learning is
 used to derive social cost functions by observing persons walking 
through the streets. Our objective is to incorporate such costs into the
 robot navigation stack in order to “emulate” these human interactions. 
In order to alleviate the complexity, the system is focused on learning 
an adequate cost function to be applied at the local navigation level, 
thus providing direct low-level controls to the robot. The paper 
presents an analysis of the results in a robot navigating in challenging
 real scenarios, analyzing and comparing this approach with other 
algorithms.</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>Sep. 2014</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>IEEE Xplore</td>
					</tr>
					<tr>
					<th>Volume</th>
						<td>02</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>618-625</td>
					</tr>
					<tr>
					<th>Proceedings Title</th>
						<td>2014 11th International Conference on Informatics in Control, Automation and Robotics (ICINCO)</td>
					</tr>
					<tr>
					<th>Conference Name</th>
						<td>2014 11th International Conference on Informatics in Control, Automation and Robotics (ICINCO)</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.5220/0005120806180625">10.5220/0005120806180625</a></td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Tags:</h3>
				<ul class="tags">
					<li>Trajectory</li>
					<li>Navigation</li>
					<li>Cost function</li>
					<li>Planning</li>
					<li>Robot sensing systems</li>
					<li>Inverse Reinforcement Learning</li>
					<li>Lasers</li>
					<li>Learning from Demonstrations</li>
					<li>Robot Navigation</li>
					<li>Social Robots</li>
				</ul>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_T43NZY87">Pérez-Higueras et al. - 2014 - Robot Local Navigation with Learned Social Cost Fu.pdf					</li>
					<li id="item_2PESFQLW">IEEE Xplore Abstract Record					</li>
				</ul>
			</li>


			<li id="item_ESCULEWK" class="item conferencePaper">
			<h2>Evaluating directional cost models in navigation</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Conference Paper</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Thibault Kruse</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Alexandra Kirsch</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Harmish Khambhaita</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Rachid Alami</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>A common approach to social distancing in robot navigation are
 spatial cost functions around humans that cause the robot to prefer 
paths that do not come too close to humans. However, in unpredictably 
dynamic scenarios, following such paths may produce robot behavior that 
appears confused. The concept of directional costs in cost functions [9]
 is supposed to alleviate this problem without incurring the problem of 
combinatorial explosions using temporal planning. With directional cost 
functions, a robot attempts to solve spatial conﬂicts by adjusting the 
velocity instead of the path, where possible. To complement results from
 simulations, in this paper we describe a user study we conducted with a
 PR2 robot and human participants to evaluate the new cost function 
type. The study shows that the real robot behavior is similar to the 
observations in simulation, and that participants rate the robot 
behavior less confusing with the adapted cost model. The study also 
shows other important behavior cues that can inﬂuence motion legibility.</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2014</td>
					</tr>
					<tr>
					<th>Language</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>Crossref</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="http://dl.acm.org/citation.cfm?doid=2559636.2559662">http://dl.acm.org/citation.cfm?doid=2559636.2559662</a></td>
					</tr>
					<tr>
					<th>Accessed</th>
						<td>4/2/2019, 4:51:16 PM</td>
					</tr>
					<tr>
					<th>Place</th>
						<td>Bielefeld, Germany</td>
					</tr>
					<tr>
					<th>Publisher</th>
						<td>ACM Press</td>
					</tr>
					<tr>
					<th>ISBN</th>
						<td>978-1-4503-2658-2</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>350-357</td>
					</tr>
					<tr>
					<th>Proceedings Title</th>
						<td>Proceedings of the 2014 ACM/IEEE international conference on Human-robot interaction - HRI '14</td>
					</tr>
					<tr>
					<th>Conference Name</th>
						<td>the 2014 ACM/IEEE international conference</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.1145/2559636.2559662">10.1145/2559636.2559662</a></td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_5QPP8CGH">Kruse et al. - 2014 - Evaluating directional cost models in navigation.pdf					</li>
				</ul>
			</li>


			<li id="item_WH8I76MP" class="item journalArticle">
			<h2>Human-aware robot navigation: A survey</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Journal Article</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Thibault Kruse</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Amit Kumar Pandey</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Rachid Alami</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Alexandra Kirsch</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>Navigation is a basic skill for autonomous robots. In the last
 years human-robot interaction has become an important research ﬁeld 
that spans all of the robot capabilities including perception, 
reasoning, learning, manipulation and navigation. For navigation, the 
presence of humans requires novel approaches that take into account the 
constraints of human comfort as well as social rules. Besides these 
constraints, putting robots among humans opens new interaction 
possibilities for robots, also for navigation tasks, such as robot 
guides. This paper provides a survey of existing approaches to 
human-aware navigation and oﬀers a general classiﬁcation scheme for the 
presented methods.</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>12/2013</td>
					</tr>
					<tr>
					<th>Language</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Short Title</th>
						<td>Human-aware robot navigation</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>Crossref</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://linkinghub.elsevier.com/retrieve/pii/S0921889013001048">https://linkinghub.elsevier.com/retrieve/pii/S0921889013001048</a></td>
					</tr>
					<tr>
					<th>Accessed</th>
						<td>4/2/2019, 4:51:07 PM</td>
					</tr>
					<tr>
					<th>Volume</th>
						<td>61</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>1726-1743</td>
					</tr>
					<tr>
					<th>Publication</th>
						<td>Robotics and Autonomous Systems</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.1016/j.robot.2013.05.007">10.1016/j.robot.2013.05.007</a></td>
					</tr>
					<tr>
					<th>Issue</th>
						<td>12</td>
					</tr>
					<tr>
					<th>ISSN</th>
						<td>09218890</td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_LV9HDCNQ">Kruse et al. - 2013 - Human-aware robot navigation A survey.pdf					</li>
				</ul>
			</li>


			<li id="item_TKSL6JAJ" class="item conferencePaper">
			<h2>Robot companion: A social-force based approach with human awareness-navigation in crowded environments</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Conference Paper</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>G. Ferrer</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>A. Garrell</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>A. Sanfeliu</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>Robots accompanying humans is one of the core capacities every
 service robot deployed in urban settings should have. We present a 
novel robot companion approach based on the so-called Social Force Model
 (SFM). A new model of robot-person interaction is obtained using the 
SFM which is suited for our robots Tibi and Dabo. Additionally, we 
propose an interactive scheme for robot's human-awareness navigation 
using the SFM and prediction information. Moreover, we present a new 
metric to evaluate the robot companion performance based on vital spaces
 and comfortableness criteria. Also, a multimodal human feedback is 
proposed to enhance the behavior of the system. The validation of the 
model is accomplished throughout an extensive set of simulations and 
real-life experiments.</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>November 2013</td>
					</tr>
					<tr>
					<th>Short Title</th>
						<td>Robot companion</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>IEEE Xplore</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>1688-1694</td>
					</tr>
					<tr>
					<th>Proceedings Title</th>
						<td>2013 IEEE/RSJ International Conference on Intelligent Robots and Systems</td>
					</tr>
					<tr>
					<th>Conference Name</th>
						<td>2013 IEEE/RSJ International Conference on Intelligent Robots and Systems</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.1109/IROS.2013.6696576">10.1109/IROS.2013.6696576</a></td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Tags:</h3>
				<ul class="tags">
					<li>Trajectory</li>
					<li>Navigation</li>
					<li>control engineering computing</li>
					<li>Measurement</li>
					<li>human-robot interaction</li>
					<li>service robots</li>
					<li>Robot sensing systems</li>
					<li>comfortableness criteria</li>
					<li>crowded environments</li>
					<li>Dabo</li>
					<li>Force</li>
					<li>human awareness-navigation</li>
					<li>interactive scheme</li>
					<li>Mathematical model</li>
					<li>multimodal human feedback</li>
					<li>prediction information</li>
					<li>robot companion approach</li>
					<li>robot companion performance</li>
					<li>robot human-awareness navigation</li>
					<li>robot-person interaction</li>
					<li>service robot</li>
					<li>SFM</li>
					<li>social force model</li>
					<li>social-force based approach</li>
					<li>Tibi</li>
					<li>vital spaces</li>
				</ul>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_BR8VA4XI">Submitted Version					</li>
					<li id="item_5EFACUQ6">IEEE Xplore Abstract Record					</li>
				</ul>
			</li>


			<li id="item_U296VMP4" class="item conferencePaper">
			<h2>Towards more efficient navigation for robots and humans</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Conference Paper</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>David V. Lu</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>William D. Smart</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>Effective robot navigation in the presence of humans is hard. 
Not only do human obstacles move, they react to the movements of the 
robot according to instinct and social rules. In order to efﬁciently 
navigate around each other, both the robot and the human must move in a 
way that takes the other into account. Failure to do so can lead to a 
lowering of the perceived quality of the interaction and, more 
importantly, it can also delay one or both parties, causing them to be 
less efﬁcient in whatever task they are trying to achieve.</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>11/2013</td>
					</tr>
					<tr>
					<th>Language</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>DOI.org (Crossref)</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="http://ieeexplore.ieee.org/document/6696579/">http://ieeexplore.ieee.org/document/6696579/</a></td>
					</tr>
					<tr>
					<th>Accessed</th>
						<td>11/4/2019, 11:14:47 AM</td>
					</tr>
					<tr>
					<th>Place</th>
						<td>Tokyo</td>
					</tr>
					<tr>
					<th>Publisher</th>
						<td>IEEE</td>
					</tr>
					<tr>
					<th>ISBN</th>
						<td>978-1-4673-6358-7 978-1-4673-6357-0</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>1707-1713</td>
					</tr>
					<tr>
					<th>Proceedings Title</th>
						<td>2013 IEEE/RSJ International Conference on Intelligent Robots and Systems</td>
					</tr>
					<tr>
					<th>Conference Name</th>
						<td>2013 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2013)</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.1109/IROS.2013.6696579">10.1109/IROS.2013.6696579</a></td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_5AWES64J">Lu and Smart - 2013 - Towards more efficient navigation for robots and h.pdf					</li>
				</ul>
			</li>


			<li id="item_YZQ56YXH" class="item conferencePaper">
			<h2>Social-aware robot navigation in urban environments</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Conference Paper</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>G. Ferrer</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>A. Garrell</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>A. Sanfeliu</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>In this paper we present a novel robot navigation approach 
based on the so-called Social Force Model (SFM). First, we construct a 
graph map with a set of destinations that completely describe the 
navigation environment. Second, we propose a robot navigation algorithm,
 called social-aware navigation, which is mainly driven by the 
social-forces centered at the robot. Third, we use a MCMC 
Metropolis-Hastings algorithm in order to learn the parameters values of
 the method. Finally, the validation of the model is accomplished 
throughout an extensive set of simulations and real-life experiments.</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>Sep. 2013</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>IEEE Xplore</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>331-336</td>
					</tr>
					<tr>
					<th>Proceedings Title</th>
						<td>2013 European Conference on Mobile Robots</td>
					</tr>
					<tr>
					<th>Conference Name</th>
						<td>2013 European Conference on Mobile Robots</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.1109/ECMR.2013.6698863">10.1109/ECMR.2013.6698863</a></td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Tags:</h3>
				<ul class="tags">
					<li>Collision avoidance</li>
					<li>mobile robots</li>
					<li>Navigation</li>
					<li>path planning</li>
					<li>graph theory</li>
					<li>human-robot interaction</li>
					<li>Robot sensing systems</li>
					<li>Force</li>
					<li>SFM</li>
					<li>social force model</li>
					<li>Safety</li>
					<li>graph map</li>
					<li>MCMC Metropolis-Hastings algorithm</li>
					<li>parameter value learning</li>
					<li>social-aware robot navigation</li>
					<li>Urban areas</li>
					<li>urban environments</li>
				</ul>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_G8RWX68T">IEEE Xplore Abstract Record					</li>
					<li id="item_8JX6BYP4">Submitted Version					</li>
				</ul>
			</li>


			<li id="item_JG74LKM5" class="item conferencePaper">
			<h2>Comfortable approach distance with small Unmanned Aerial Vehicles</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Conference Paper</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Brittany A. Duncan</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Robin R. Murphy</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>This paper presents the ﬁrst known humansubject study of 
comfortable approach distance and height for human interaction with a 
small unmanned aerial vehicle (sUAV), ﬁnding no conclusive difference in
 comfort with a sUAV approaching a human at above head height or below 
head height. Understanding the amount, if any, of discomfort introduced 
by a sUAV ﬂying in close proximity to a human is critical for law 
enforcement, crowd control, entertainment, or ﬂying personal assistants.
 Previous work has focused on how humans interact with each other or 
with unmanned ground vehicles, and the experimental methods typically 
rely on the human participant to consciously express distress. The 
approach taken was to duplicate the experimental set up in human 
proxemics studies, while adding psychophysiological sensing, under the 
hypothesis that human-robot interaction will mirror human-human 
interaction. The 16 participant, within-subjects experiment did not 
conﬁrm this hypothesis. Instead a sUAV above height of a “tall” person 
in human experiments (2.13 m) did not produce statistically different 
heart rate variability nor cause the participant to stop the robot 
further away than for a sUAV at a “short” height (1.52 m). The lack of 
effect may be due to two possible confounds: i) duplicating prior human 
proxemics experiments did not capture how a sUAV would likely move or 
interact and ii) telling the participants that the robot could not hurt 
them. Despite possible confounding, the results raise the question of 
whether humanhuman psychological and physical distancing behavior 
transfers to human-aerial robot interactions.</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>08/2013</td>
					</tr>
					<tr>
					<th>Language</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>DOI.org (Crossref)</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="http://ieeexplore.ieee.org/document/6628409/">http://ieeexplore.ieee.org/document/6628409/</a></td>
					</tr>
					<tr>
					<th>Accessed</th>
						<td>11/30/2021, 3:35:55 PM</td>
					</tr>
					<tr>
					<th>Place</th>
						<td>Gyeongju</td>
					</tr>
					<tr>
					<th>Publisher</th>
						<td>IEEE</td>
					</tr>
					<tr>
					<th>ISBN</th>
						<td>978-1-4799-0509-6</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>786-792</td>
					</tr>
					<tr>
					<th>Proceedings Title</th>
						<td>2013 IEEE RO-MAN</td>
					</tr>
					<tr>
					<th>Conference Name</th>
						<td>2013 IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN)</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.1109/ROMAN.2013.6628409">10.1109/ROMAN.2013.6628409</a></td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_AU2PGVVL">Duncan and Murphy - 2013 - Comfortable approach distance with small Unmanned .pdf					</li>
				</ul>
			</li>


			<li id="item_N4UCYYXS" class="item conferencePaper">
			<h2>Human-friendly robot navigation in dynamic environments</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Conference Paper</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Jerome Guzzi</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Alessandro Giusti</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Luca M. Gambardella</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Guy Theraulaz</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Gianni A. Di Caro</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>The vision-based mechanisms that pedestrians in social groups 
use to navigate in dynamic environments, avoiding obstacles and each 
others, have been subject to a large amount of research in social 
anthropology and biological sciences. We build on recent results in 
these ﬁelds to develop a novel fully-distributed algorithm for robot 
local navigation, which implements the same heuristics for mutual 
avoidance adopted by humans. The resulting trajectories are 
human-friendly, because they can intuitively be predicted and 
interpreted by humans, making the algorithm suitable for the use on 
robots sharing navigation spaces with humans. The algorithm is 
computationally light and simple to implement. We study its efﬁciency 
and safety in presence of sensing uncertainty, and demonstrate its 
implementation on real robots. Through extensive quantitative 
simulations we explore various parameters of the system and demonstrate 
its good properties in scenarios of different complexity. When the 
algorithm is implemented on robot swarms, we could observe emergent 
collective behaviors similar to those observed in human crowds.</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>05/2013</td>
					</tr>
					<tr>
					<th>Language</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>DOI.org (Crossref)</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="http://ieeexplore.ieee.org/document/6630610/">http://ieeexplore.ieee.org/document/6630610/</a></td>
					</tr>
					<tr>
					<th>Accessed</th>
						<td>11/4/2019, 11:13:34 AM</td>
					</tr>
					<tr>
					<th>Place</th>
						<td>Karlsruhe, Germany</td>
					</tr>
					<tr>
					<th>Publisher</th>
						<td>IEEE</td>
					</tr>
					<tr>
					<th>ISBN</th>
						<td>978-1-4673-5643-5 978-1-4673-5641-1</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>423-430</td>
					</tr>
					<tr>
					<th>Proceedings Title</th>
						<td>2013 IEEE International Conference on Robotics and Automation</td>
					</tr>
					<tr>
					<th>Conference Name</th>
						<td>2013 IEEE International Conference on Robotics and Automation (ICRA)</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.1109/ICRA.2013.6630610">10.1109/ICRA.2013.6630610</a></td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_I76NS6AI">Guzzi et al. - 2013 - Human-friendly robot navigation in dynamic environ.pdf					</li>
				</ul>
			</li>


			<li id="item_DDCHTYFZ" class="item conferencePaper">
			<h2>Towards Legible Robot Navigation - How to Increase the Intend Expressiveness of Robot Navigation Behavior</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Conference Paper</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Christina Lichtenthäler</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Alexandra Kirsch</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>The work at hand addresses the question: How can we achieve 
legible robot navigation? To this end, we investigate current 
state-of-the-art assumptions and methods regarding legible robot 
navigation in order to propose key factors for the development of a 
legible robot navigation. We reviewed 18 articles regarding legible 
robot behavior and present the conclusions from our own research. We 
found three important factors for legible robot navigation: straight 
lines, stereo-typical motions and the use of additional gestures.</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2013</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>HAL Archives Ouvertes</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://hal.archives-ouvertes.fr/hal-01684307">https://hal.archives-ouvertes.fr/hal-01684307</a></td>
					</tr>
					<tr>
					<th>Accessed</th>
						<td>11/4/2019, 11:37:10 AM</td>
					</tr>
					<tr>
					<th>Place</th>
						<td>Bristol, United Kingdom</td>
					</tr>
					<tr>
					<th>Proceedings Title</th>
						<td>International Conference on Social Robotics - Workshop Embodied Communication of Goals and Intentions</td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Tags:</h3>
				<ul class="tags">
					<li>human-aware navigation</li>
					<li>intend expressive navigation</li>
					<li>legibility</li>
				</ul>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_FJ8WJ3Z5">HAL PDF Full Text					</li>
				</ul>
			</li>


			<li id="item_DKMS8VTB" class="item bookSection">
			<h2>Human Aware Navigation for Assistive Robotics</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Book Section</td>
					</tr>
					<tr>
						<th class="editor">Editor</th>
						<td>Jaydev P. Desai</td>
					</tr>
					<tr>
						<th class="editor">Editor</th>
						<td>Gregory Dudek</td>
					</tr>
					<tr>
						<th class="editor">Editor</th>
						<td>Oussama Khatib</td>
					</tr>
					<tr>
						<th class="editor">Editor</th>
						<td>Vijay Kumar</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Dizan Vasquez</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Procópio Stein</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Jorge Rios-Martinez</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Arturo Escobedo</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Anne Spalanzani</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Christian Laugier</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>Ensuring proper living conditions for an ever growing number 
of elderly people is a signiﬁcative challenge for many countries. The 
diﬃculty and cost of hiring and training specialized personnel has 
fostered research in assistive robotics as a viable alternative. In this
 context, an ideally suited and very relevant application is to 
transport people with reduced mobility. This may involve either 
autonomous or semiautonomous transportation devices such as cars and 
wheelchairs.</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2013</td>
					</tr>
					<tr>
					<th>Language</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>DOI.org (Crossref)</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="http://link.springer.com/10.1007/978-3-319-00065-7_31">http://link.springer.com/10.1007/978-3-319-00065-7_31</a></td>
					</tr>
					<tr>
					<th>Accessed</th>
						<td>11/4/2019, 11:33:57 AM</td>
					</tr>
					<tr>
					<th>Extra</th>
						<td>DOI: 10.1007/978-3-319-00065-7_31</td>
					</tr>
					<tr>
					<th>Volume</th>
						<td>88</td>
					</tr>
					<tr>
					<th>Place</th>
						<td>Heidelberg</td>
					</tr>
					<tr>
					<th>Publisher</th>
						<td>Springer International Publishing</td>
					</tr>
					<tr>
					<th>ISBN</th>
						<td>978-3-319-00064-0 978-3-319-00065-7</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>449-462</td>
					</tr>
					<tr>
					<th>Book Title</th>
						<td>Experimental Robotics</td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_2SKAWWH8">Vasquez et al. - 2013 - Human Aware Navigation for Assistive Robotics.pdf					</li>
				</ul>
			</li>


			<li id="item_HT5BSC5Z" class="item conferencePaper">
			<h2>Intention Driven Human Aware Navigation for Assisted Mobility</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Conference Paper</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Jorge Rios-Martinez</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Arturo Escobedo</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Anne Spalanzani</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Christian Laugier</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>Ensuring proper living conditions for an ever growing number 
of elderly people is an important challenge for many countries. The 
difficulty and cost of hiring and training specialized personnel has 
fostered research in assistive robotics as a viable alternative. In 
particular, this paper studies the case of a robotic wheelchair, 
specifically its autonomous navigation and user adapted control. 
Integration of a technique to interpret user intention using head 
movements and a human aware motion planner is presented. Test results 
exhibit emerging behavior showing a robotic wheelchair interpreting 
gesture commands and taking the user to his desired goal, respecting 
social conventions during its navigation.</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2012/10/12</td>
					</tr>
					<tr>
					<th>Language</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>hal.inria.fr</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://hal.inria.fr/hal-00757133/document">https://hal.inria.fr/hal-00757133/document</a></td>
					</tr>
					<tr>
					<th>Accessed</th>
						<td>4/4/2019, 10:44:06 AM</td>
					</tr>
					<tr>
					<th>Conference Name</th>
						<td>Workshop on Assistance and Service robotics in a human environment at IROS</td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_XQKY98QR">Full Text PDF					</li>
					<li id="item_F8R5ITZM">Snapshot					</li>
				</ul>
			</li>


			<li id="item_XEN7H8VL" class="item conferencePaper">
			<h2>Socially-aware robot navigation: A learning approach</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Conference Paper</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>M. Luber</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>L. Spinello</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>J. Silva</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>K. O. Arras</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>The ability to act in a socially-aware way is a key skill for 
robots that share a space with humans. In this paper we address the 
problem of socially-aware navigation among people that meets objective 
criteria such as travel time or path length as well as subjective 
criteria such as social comfort. Opposed to model-based approaches 
typically taken in related work, we pose the problem as an unsupervised 
learning problem. We learn a set of dynamic motion prototypes from 
observations of relative motion behavior of humans found in publicly 
available surveillance data sets. The learned motion prototypes are then
 used to compute dynamic cost maps for path planning using an any-angle 
A* algorithm. In the evaluation we demonstrate that the learned 
behaviors are better in reproducing human relative motion in both 
criteria than a Proxemics-based baseline method.</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>October 2012</td>
					</tr>
					<tr>
					<th>Short Title</th>
						<td>Socially-aware robot navigation</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>IEEE Xplore</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>902-907</td>
					</tr>
					<tr>
					<th>Proceedings Title</th>
						<td>2012 IEEE/RSJ International Conference on Intelligent Robots and Systems</td>
					</tr>
					<tr>
					<th>Conference Name</th>
						<td>2012 IEEE/RSJ International Conference on Intelligent Robots and Systems</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.1109/IROS.2012.6385716">10.1109/IROS.2012.6385716</a></td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Tags:</h3>
				<ul class="tags">
					<li>Dynamics</li>
					<li>mobile robots</li>
					<li>Robots</li>
					<li>Humans</li>
					<li>any-angle A* algorithm</li>
					<li>Computational modeling</li>
					<li>Context</li>
					<li>dynamic motion prototypes</li>
					<li>Heuristic algorithms</li>
					<li>learning approach</li>
					<li>path length</li>
					<li>Prototypes</li>
					<li>Proxemics-based baseline method</li>
					<li>social sciences</li>
					<li>socially-aware robot navigation</li>
					<li>travel time</li>
					<li>unsupervised learning</li>
					<li>unsupervised learning problem</li>
				</ul>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_B5T8A8YT">IEEE Xplore Abstract Record					</li>
					<li id="item_29JPQWYC">Submitted Version					</li>
				</ul>
			</li>


			<li id="item_EW4K9NEU" class="item conferencePaper">
			<h2>Increasing perceived value between human and robots — Measuring legibility in human aware navigation</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Conference Paper</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>C. Lichtenthäler</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>T. Lorenz</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>M. Karg</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>A. Kirsch</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>Robots will more and more enter our daily life. In order to 
increase their acceptance it is necessary that their movements and 
behavior are predictable. With our present experiment we assess the 
acceptance of autonomous robots in human working and living 
environments. As a specific indicator we define legibility as an 
important prerequisite for user acceptance. In a simulator study 
participants rated the navigation behavior of a robot with regard to 
several aspects of legibility. Results show that Human Aware Navigation 
is a method to increase the perceived value of robot navigation 
behavior.</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>May 2012</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>IEEE Xplore</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>89-94</td>
					</tr>
					<tr>
					<th>Proceedings Title</th>
						<td>2012 IEEE Workshop on Advanced Robotics and its Social Impacts (ARSO)</td>
					</tr>
					<tr>
					<th>Conference Name</th>
						<td>2012 IEEE Workshop on Advanced Robotics and its Social Impacts (ARSO)</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.1109/ARSO.2012.6213405">10.1109/ARSO.2012.6213405</a></td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Tags:</h3>
				<ul class="tags">
					<li>Trajectory</li>
					<li>Navigation</li>
					<li>path planning</li>
					<li>Robots</li>
					<li>human-robot interaction</li>
					<li>Humans</li>
					<li>Safety</li>
					<li>autonomous robot acceptance</li>
					<li>human aware navigation method</li>
					<li>human-robot perceived value</li>
					<li>legibility measurement</li>
					<li>Observers</li>
					<li>Reliability</li>
					<li>robot navigation behavior</li>
					<li>user acceptance</li>
				</ul>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_PU7GTCMP">Submitted Version					</li>
				</ul>
			</li>


			<li id="item_LVP9JXSK" class="item conferencePaper">
			<h2>Understanding human interaction for probabilistic autonomous navigation using Risk-RRT approach</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Conference Paper</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>J. Rios-Martinez</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>A. Spalanzani</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>C. Laugier</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>With the growing demand of personal assistance to mobility and
 mobile service robotics, robot navigation systems must be ¿aware¿ of 
the social conventions followed by people. They must respect proximity 
constraints but also respect people interacting. For example, they may 
not break interaction between people talking, unless the occupants want 
to take part in the conversation. In this case, they must be able to 
join the group using a socially adapted behavior. This paper proposes a 
risk-based navigation method including both the traditional notion of 
risk of collision and the notion of risk of disturbance. Results exhibit
 new emerging behavior showing how a robot takes into account social 
conventions in its navigation strategy.</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>Sep. 2011</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>IEEE Xplore</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>2014-2019</td>
					</tr>
					<tr>
					<th>Proceedings Title</th>
						<td>2011 IEEE/RSJ International Conference on Intelligent Robots and Systems</td>
					</tr>
					<tr>
					<th>Conference Name</th>
						<td>2011 IEEE/RSJ International Conference on Intelligent Robots and Systems</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.1109/IROS.2011.6094496">10.1109/IROS.2011.6094496</a></td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Tags:</h3>
				<ul class="tags">
					<li>Trajectory</li>
					<li>Collision avoidance</li>
					<li>mobile robots</li>
					<li>Navigation</li>
					<li>path planning</li>
					<li>Mobile robots</li>
					<li>human-robot interaction</li>
					<li>Proxemics</li>
					<li>Humans</li>
					<li>social conventions</li>
					<li>Gaussian processes</li>
					<li>probability</li>
					<li>collision risk</li>
					<li>disturbance risk</li>
					<li>Human aware navigation</li>
					<li>human interaction</li>
					<li>mobile service robotics</li>
					<li>personal assistance</li>
					<li>probabilistic autonomous navigation</li>
					<li>risk assessment</li>
					<li>risk management</li>
					<li>risk-based navigation method</li>
					<li>Risk-RRT approach</li>
					<li>robot navigation systems</li>
				</ul>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_NZV6FYTM">Full Text					</li>
					<li id="item_ACCU4V7P">IEEE Xplore Abstract Record					</li>
				</ul>
			</li>


			<li id="item_KQMQB7WU" class="item conferencePaper">
			<h2>People-aware navigation for goal-oriented behavior involving a human partner</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Conference Paper</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>D. Feil-Seifer</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>M. Matarić</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>In order to facilitate effective autonomous interaction 
behavior for human-robot interaction the robot should be able to execute
 goal-oriented behavior while reacting to sensor feedback related to the
 people with which it is interacting. Prior work has demonstrated that 
autonomously sensed distance-based features can be used to correctly 
detect user state. We wish to demonstrate that such models can also be 
used to weight action selection as well. This paper considers the 
problem of moving to a goal along with a partner, demonstrating that a 
learned model can be used to weight trajectories of a navigation system 
for autonomous movement. This paper presents a realization of a 
person-aware navigation system which requires no ad-hoc parameter 
tuning, and no input other than a small set of training examples. This 
system is validated using an in-lab demonstration of people-aware 
navigation using the described system.</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>August 2011</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>IEEE Xplore</td>
					</tr>
					<tr>
					<th>Volume</th>
						<td>2</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>1-6</td>
					</tr>
					<tr>
					<th>Proceedings Title</th>
						<td>2011 IEEE International Conference on Development and Learning (ICDL)</td>
					</tr>
					<tr>
					<th>Conference Name</th>
						<td>2011 IEEE International Conference on Development and Learning (ICDL)</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.1109/DEVLRN.2011.6037331">10.1109/DEVLRN.2011.6037331</a></td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Tags:</h3>
				<ul class="tags">
					<li>mobile robots</li>
					<li>path planning</li>
					<li>Robots</li>
					<li>humanoid robots</li>
					<li>human-robot interaction</li>
					<li>action selection</li>
					<li>autonomous interaction behavior</li>
					<li>autonomous movement</li>
					<li>feedback</li>
					<li>goal-oriented behavior</li>
					<li>human partner</li>
					<li>people-aware navigation</li>
					<li>person-aware navigation system</li>
					<li>sensor feedback</li>
					<li>Variable speed drives</li>
				</ul>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_ES2NZQH3">IEEE Xplore Abstract Record					</li>
					<li id="item_DUBW5P44">Submitted Version					</li>
				</ul>
			</li>


			<li id="item_9WC5VUMS" class="item conferencePaper">
			<h2>Planning human-aware motions using a sampling-based costmap planner</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Conference Paper</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Jim Mainprice</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>E. Akin Sisbot</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Leonard Jaillet</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Juan Cortes</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Rachid Alami</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Thierry Simeon</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>This paper addresses the motion planning problem while 
considering Human-Robot Interaction (HRI) constraints. The proposed 
planner generates collision-free paths that are acceptable and legible 
to the human. The method extends our previous work on human-aware path 
planning to cluttered environments. A randomized cost-based exploration 
method provides an initial path that is relevant with respect to HRI and
 workspace constraints. The quality of the path is further improved with
 a local path-optimization method. Simulation results on mobile 
manipulators in the presence of humans demonstrate the overall efﬁcacy 
of the approach.</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>05/2011</td>
					</tr>
					<tr>
					<th>Language</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>Crossref</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="http://ieeexplore.ieee.org/document/5980048/">http://ieeexplore.ieee.org/document/5980048/</a></td>
					</tr>
					<tr>
					<th>Accessed</th>
						<td>4/2/2019, 4:53:04 PM</td>
					</tr>
					<tr>
					<th>Place</th>
						<td>Shanghai, China</td>
					</tr>
					<tr>
					<th>Publisher</th>
						<td>IEEE</td>
					</tr>
					<tr>
					<th>ISBN</th>
						<td>978-1-61284-386-5</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>5012-5017</td>
					</tr>
					<tr>
					<th>Proceedings Title</th>
						<td>2011 IEEE International Conference on Robotics and Automation</td>
					</tr>
					<tr>
					<th>Conference Name</th>
						<td>2011 IEEE International Conference on Robotics and Automation (ICRA)</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.1109/ICRA.2011.5980048">10.1109/ICRA.2011.5980048</a></td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_6Q48HV2V">Mainprice et al. - 2011 - Planning human-aware motions using a sampling-base.pdf					</li>
				</ul>
			</li>


			<li id="item_WJ9YTRGT" class="item conferencePaper">
			<h2>Adaptive human aware navigation based on motion pattern analysis</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Conference Paper</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>S. Tranberg Hansen</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>M. Svenstrup</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>H. J. Andersen</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>T. Bak</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>Respecting people's social spaces is an important prerequisite
 for acceptable and natural robot navigation in human environments. In 
this paper, we describe an adaptive system for mobile robot navigation 
based on estimates of whether a person seeks to interact with the robot 
or not. The estimates are based on run-time motion pattern analysis 
compared to stored experience in a database. Using a potential field 
centered around the person, the robot positions itself at the most 
appropriate place relative to the person and the interaction status. The
 system is validated through qualitative tests in a real world setting. 
The results demonstrate that the system is able to learn to navigate 
based on past interaction experiences, and to adapt to different 
behaviors over time.</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>Sep. 2009</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>IEEE Xplore</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>927-932</td>
					</tr>
					<tr>
					<th>Proceedings Title</th>
						<td>RO-MAN 2009 - The 18th IEEE International Symposium on Robot and Human Interactive Communication</td>
					</tr>
					<tr>
					<th>Conference Name</th>
						<td>RO-MAN 2009 - The 18th IEEE International Symposium on Robot and Human Interactive Communication</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.1109/ROMAN.2009.5326212">10.1109/ROMAN.2009.5326212</a></td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Tags:</h3>
				<ul class="tags">
					<li>mobile robots</li>
					<li>Navigation</li>
					<li>path planning</li>
					<li>Mobile robots</li>
					<li>robot vision</li>
					<li>adaptive human aware navigation</li>
					<li>Adaptive systems</li>
					<li>Databases</li>
					<li>Humans</li>
					<li>mobile robot navigation</li>
					<li>Motion analysis</li>
					<li>motion estimation</li>
					<li>Motion estimation</li>
					<li>motion pattern analysis</li>
					<li>Orbital robotics</li>
					<li>Pattern analysis</li>
					<li>run-time motion pattern analysis</li>
					<li>Runtime</li>
				</ul>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_FACR5GPY">IEEE Xplore Abstract Record					</li>
					<li id="item_EH7IA7W5">Full Text					</li>
				</ul>
			</li>


			<li id="item_XT3TCRBP" class="item conferencePaper">
			<h2>You’ll never walk alone: modeling social behavior for multi-target tracking</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Conference Paper</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>S. Pellegrini</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>A. Ess</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>K. Schindler</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>L. Van Gool</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>Object tracking typically relies on a dynamic model to predict
 the object’s location from its past trajectory. In crowded scenarios a 
strong dynamic model is particularly important, because more accurate 
predictions allow for smaller search regions, which greatly simplifies 
data association. Traditional dynamic models predict the location for 
each target solely based on its own history, without tak-ing into 
account the remaining scene objects. Collisions are resolved only when 
they happen. Such an approach ignores important aspects of human 
behavior: people are driven by their future destination, take into 
account their environment, anticipate collisions, and adjust their 
trajec-tories at an early stage in order to avoid them. In this work, we
 introduce a model of dynamic social behavior, inspired by models 
developed for crowd simulation. The model is trained with videos 
recorded from birds-eye view at busy locations, and applied as a motion 
model for multi-people tracking from a vehicle-mounted camera. 
Experiments on real sequences show that accounting for social 
interactions and scene knowledge improves tracking performance, 
especially during occlusions.</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2009</td>
					</tr>
					<tr>
					<th>Short Title</th>
						<td>You’ll never walk alone</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>CiteSeer</td>
					</tr>
					<tr>
					<th>Proceedings Title</th>
						<td>In Int. Conf. on Computer Vision (iccv</td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_VRZMXZQ8">Citeseer - Full Text PDF					</li>
					<li id="item_PWWIUVMS">Citeseer - Snapshot					</li>
				</ul>
			</li>


			<li id="item_BDIJSPEL" class="item journalArticle">
			<h2>A Human Aware Mobile Robot Motion Planner</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Journal Article</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>E.A. Sisbot</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>L.F. Marin-Urias</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>R. Alami</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>T. Simeon</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>Robot navigation in the presence of humans raises new issues 
for motion planning and control when the humans must be taken explicitly
 into account. We claim that a humanaware motion planner must not only 
provide safe robot paths, but also synthesize good, socially acceptable 
and legible paths.</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>10/2007</td>
					</tr>
					<tr>
					<th>Language</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>Crossref</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="http://ieeexplore.ieee.org/document/4339546/">http://ieeexplore.ieee.org/document/4339546/</a></td>
					</tr>
					<tr>
					<th>Accessed</th>
						<td>4/2/2019, 4:50:45 PM</td>
					</tr>
					<tr>
					<th>Volume</th>
						<td>23</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>874-883</td>
					</tr>
					<tr>
					<th>Publication</th>
						<td>IEEE Transactions on Robotics</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.1109/TRO.2007.904911">10.1109/TRO.2007.904911</a></td>
					</tr>
					<tr>
					<th>Issue</th>
						<td>5</td>
					</tr>
					<tr>
					<th>ISSN</th>
						<td>1552-3098</td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_9S5KFKBG">Sisbot et al. - 2007 - A Human Aware Mobile Robot Motion Planner.pdf					</li>
				</ul>
			</li>


			<li id="item_SX85CXRY" class="item journalArticle">
			<h2>Methodology &amp; Themes of Human-Robot Interaction: A Growing Research Field</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Journal Article</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Kerstin Dautenhahn</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>This article discusses challenges of Human-Robot Interaction, 
which is a highly inter- and multidisciplinary area. Themes that are 
important in current research in this lively and growing field are 
identified and selected work relevant to these themes is discussed.</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>March 1, 2007</td>
					</tr>
					<tr>
					<th>Language</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Short Title</th>
						<td>Methodology &amp; Themes of Human-Robot Interaction</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>SAGE Journals</td>
					</tr>
					<tr>
					<th>URL</th>
						<td><a href="https://doi.org/10.5772/5702">https://doi.org/10.5772/5702</a></td>
					</tr>
					<tr>
					<th>Accessed</th>
						<td>4/4/2019, 10:42:52 AM</td>
					</tr>
					<tr>
					<th>Volume</th>
						<td>4</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>15</td>
					</tr>
					<tr>
					<th>Publication</th>
						<td>International Journal of Advanced Robotic Systems</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.5772/5702">10.5772/5702</a></td>
					</tr>
					<tr>
					<th>Issue</th>
						<td>1</td>
					</tr>
					<tr>
					<th>Journal Abbr</th>
						<td>International Journal of Advanced Robotic Systems</td>
					</tr>
					<tr>
					<th>ISSN</th>
						<td>1729-8814</td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_DI9GMNQ3">SAGE PDF Full Text					</li>
				</ul>
			</li>


			<li id="item_CYB4KIFU" class="item conferencePaper">
			<h2>Let’s Come Together — Social Navigation Behaviors of Virtual and Real Humans</h2>
				<table>
					<tbody><tr>
						<th>Type</th>
						<td>Conference Paper</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Matthias Rehm</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Elisabeth André</td>
					</tr>
					<tr>
						<th class="author">Author</th>
						<td>Michael Nischt</td>
					</tr>
					<tr>
						<th class="editor">Editor</th>
						<td>Mark Maybury</td>
					</tr>
					<tr>
						<th class="editor">Editor</th>
						<td>Oliviero Stock</td>
					</tr>
					<tr>
						<th class="editor">Editor</th>
						<td>Wolfgang Wahlster</td>
					</tr>
					<tr>
					<th>Abstract</th>
						<td>In this paper, we present a game-like scenario that is based 
on a model of social group dynamics inspired by theories from the social
 sciences. The model is augmented by a model of proxemics that simulates
 the role of distance and spatial orientation in human-human 
communication. By means of proxemics, a group of human participants may 
signal other humans whether they welcome new group members to join or 
not. In this paper, we describe the results of an experiment we 
conducted to shed light on the question of how humans respond to such 
cues when shown by virtual humans.</td>
					</tr>
					<tr>
					<th>Date</th>
						<td>2005</td>
					</tr>
					<tr>
					<th>Language</th>
						<td>en</td>
					</tr>
					<tr>
					<th>Library Catalog</th>
						<td>Springer Link</td>
					</tr>
					<tr>
					<th>Place</th>
						<td>Berlin, Heidelberg</td>
					</tr>
					<tr>
					<th>Publisher</th>
						<td>Springer</td>
					</tr>
					<tr>
					<th>ISBN</th>
						<td>978-3-540-31651-0</td>
					</tr>
					<tr>
					<th>Pages</th>
						<td>124-133</td>
					</tr>
					<tr>
					<th>Series</th>
						<td>Lecture Notes in Computer Science</td>
					</tr>
					<tr>
					<th>Proceedings Title</th>
						<td>Intelligent Technologies for Interactive Entertainment</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.1007/11590323_13">10.1007/11590323_13</a></td>
					</tr>
					<tr>
					<th>Date Added</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
					<tr>
					<th>Modified</th>
						<td>12/1/2021, 5:15:48 PM</td>
					</tr>
				</tbody></table>
				<h3 class="tags">Tags:</h3>
				<ul class="tags">
					<li>Social Force Model</li>
					<li>Real Human</li>
					<li>Social Distance</li>
					<li>Virtual Agent</li>
					<li>Virtual Human</li>
				</ul>
				<h3 class="attachments">Attachments</h3>
				<ul class="attachments">
					<li id="item_48CIJ7C4">Springer Full Text PDF					</li>
				</ul>
			</li>

		</ul>
	
</body></html>